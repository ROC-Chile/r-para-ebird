[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curso ROC: Análisis de datos de eBird utilizando R",
    "section": "",
    "text": "Introducción\nEsta página contiene el material utilizado durante el Curso Roc: Análisis de datos de eBird utilizando R.\nEl curso consta de 4 módulos:\n1. Introducción al entorno R en el contexto de eBird\n2. Buenas prácticas para el uso de datos de eBird: introduction to the eBird Basic Dataset (EBD), challenges associated with using eBird data for analysis, and best practices for preparing eBird data for modeling.\n3. Modelamiento de distribución y abundancia relativa: tasas de encuentro, abundancia relativa y ejemplos y aplicaciones prácticas usando distribución y abundancia.\n4. Usos y aplicaciones de productos Estados y Tendencias: descarga de productos de Estados y Tendencias, carga de datos en R y su uso para una variedad de aplicaciones.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#sec-intro-setup",
    "href": "index.html#sec-intro-setup",
    "title": "Curso ROC: Análisis de datos de eBird en R",
    "section": "Setup",
    "text": "Setup\nThis workshop is intended to be interactive. All examples are written in the R programming language, and the instructor will work through the examples in real time, while the attendees are encouraged following along by writing the same code. To ensure we can avoid any unnecessary delays, please follow these setup instructions prior to the workshop:\n\nCreate an eBird account if you don’t already have one and request access to the raw eBird data and/or the eBird Status data products depending on which workshops you’re attending:\n\nBest Practices for Using eBird Data: request access to the eBird Basic Dataset.\neBird Status and Trends: request access to the eBird Status data products\n\nDownload and install the latest version of R. You must have R version 4.0.0 or newer to follow along with this workshop\nDownload and install the latest version of RStudio. RStudio is not required for this workshop; however, the instructors will be using it and you may find it easier to following along if you’re working in the same environment.\nThe lessons in this workshop use a variety of R packages. To install all the necessary packages, run the following code\n\n\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nremotes::install_github(\"ebird/ebird-best-practices\")\n\n\nEnsure all packages are updated to their most recent versions by clicking on the Update button on the Packages tab in RStudio.\nDownload the data package for the workshop you are attending:\n\nBest Practices for Using eBird Data\neBird Status and Trends",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#sec-intro-tidyverse",
    "href": "index.html#sec-intro-tidyverse",
    "title": "Curso ROC: Análisis de datos de eBird en R",
    "section": "Tidyverse",
    "text": "Tidyverse\nThroughout this workshop, we use packages from the Tidyverse, an opinionated collection of R packages designed for data science. Packages such as ggplot2, for data visualization, and dplyr, for data manipulation, are two of the most well known Tidyverse packages; however, there are many more. We’ll try to explain any functions as they come up; however, for a good general resource on working with data in R using the Tidyverse see the free online book R for Data Science by Hadley Wickham.\nThe one piece of the Tidyverse that we will cover up front is the pipe operator %&gt;%. The pipe takes the expression to the left of it and “pipes” it into the first argument of the expression on the right.\n\nlibrary(dplyr)\n\n# without pipe\nmean(1:10)\n#&gt; [1] 5.5\n\n# with pipe\n1:10 %&gt;% mean()\n#&gt; [1] 5.5\n\nThe pipe can code significantly more readable by avoiding nested function calls, reducing the need for intermediate variables, and making sequential operations read left-to-right. For example, to add a new variable to a data frame, then summarize using a grouping variable, the following are equivalent:\n\n# intermediate variables\nmtcars_kg &lt;- mutate(mtcars, wt_kg = 454 * wt)\nmtcars_grouped &lt;- group_by(mtcars_kg, cyl)\nsummarize(mtcars_grouped, wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n# nested function calls\nsummarize(\n  group_by(\n    mutate(mtcars, wt_kg = 454 * wt),\n    cyl\n  ),\n  wt_kg = mean(wt_kg)\n)\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n# pipes\nmtcars %&gt;% \n  mutate(wt_kg = 454 * wt) %&gt;% \n  group_by(cyl) %&gt;% \n  summarize(wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n\n\n\n\n\n\nExercise\n\n\n\nRewrite the following code using pipes:\n\nset.seed(1)\nround(log(runif(10, min = 0.5)), 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nset.seed(1)\nrunif(10, min = 0.5) %&gt;% \n  log() %&gt;% \n  round(digits = 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "ebird.html#sec-ebird-intro",
    "href": "ebird.html#sec-ebird-intro",
    "title": "1  Best Practices for using eBird Data",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\neBird data are collected and organized around the concept of a checklist, representing observations from a single birding event, such as a 1 km walk through a park or 15 minutes observing bird feeders in your backyard. All eBird checklists contains a list of species observed and the location and time of the observations. For a subset of checklists, the observer will also provide counts of the number of individuals seen of each species, specify the amount of effort expended while collecting these data, and confirm that they are submitting a complete checklist of all the birds they were able to identify. The data provided by the checklists such as these are often referred to as semi-structured citizen science data. Importantly, complete checklists enable data users to infer counts of zero individuals for the species that were not reported. If checklists are not complete, it’s not possible to ascertain whether the absence of a species on a list was a non-detection or the result of a participant not recording the species.\nLet’s compare two eBird checklists: an incidental observation with missing counts and a complete traveling count. Both checklists can be useful, but only the second checklist provides the type of semi-structured data required for more rigorous applications."
  },
  {
    "objectID": "ebird.html#sec-ebird-download",
    "href": "ebird.html#sec-ebird-download",
    "title": "1  Best Practices for using eBird Data",
    "section": "1.2 Downloading data",
    "text": "1.2 Downloading data\neBird data are released as two tab-separated text files: the eBird Basic Dataset (EBD) containing observation data and the Sampling Event Data (SED) containing checklist data. These files are released monthly and contain all validated bird sightings in the eBird database at the time of release. In the EBD, each row corresponds to the sighting of a single species on a checklist, including the count and any other species-level information (e.g. age, sex, species comments, etc.). In the SED, each row corresponds to a checklist, including the date, time, location, effort (e.g. distance traveled, time spent, etc.), and any additional checklist-level information (e.g. whether this is a complete checklist or not).\nIn this workshop, we’ll use Fork-tailed Flycatcher observations from Rio Grande do Sul, Brazil as an example. We’ll start by downloading the corresponding eBird observation (EBD) and checklist (SED) data by visiting the eBird Basic Dataset download page and filling out the Custom Download form to request Fork-tailed Flycatcher observations from Rio Grande do Sul. Make sure you check the box “Include sampling event data”, which will include the SED in the data download in addition to the EBD.\n\n\n\n\n\n\n\nTip\n\n\n\nThe eBird database contains a massive amount of data! When requesting eBird data to download it’s important to narrow the request to as small a subset of the data as possible. For example, if we request all Fork-tailed Flycatcher observations globally, the dataset may be too large to work with in R. Instead, we’ve only requested data for a single state in Brazil.\n\n\nOnce the data are ready, you will receive an email with a download link. The downloaded data will be in a compressed .zip format, and should be unarchived. The resulting directory will contain a two text files: one for the EBD (e.g. ebd_BR-RS_fotfly_smp_relJun-2023.txt) containing all the Fork-tailed flycatcher observations from Rio Grande do Sul, and one for the SED (e.g. ebd_BR-RS_fotfly_smp_relJun-2023_sampling.txt) containing all checklists from Rio Grande do Sul, The relJune-2023 component of the file name describes which version of the EBD this dataset came from; in this case it’s the June 2023 release.\nIf you would prefer to directly download the exact dataset used in this workshop, download the data package for this workshop."
  },
  {
    "objectID": "ebird.html#sec-ebird-import",
    "href": "ebird.html#sec-ebird-import",
    "title": "2  Best Practices for using eBird Data",
    "section": "2.2 Importar datos de eBird en R",
    "text": "2.2 Importar datos de eBird en R\nLa clase anterior aprendimos a descargar datos desde eBird, obteniendo dos archivos de texto separados por tabulaciones, uno para el EBD (datos de observación) y uno para el SED (datos de lista). Ahora, iniciaremos un nuevo proyecto de RStudio y agregaremos los dos archivos de texto descargados en el subdirectorio data/ del directorio del proyecto.\nEl paquete de R auk está diseñado específicamente para trabajar con datos de eBird. Incluye las funciones read_ebd() and read_sampling() para importar el EBD y SED, respectivamente, en R.\nPrimero vamos a importar los datos de listas (SED).\n\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(sf)\n\nf_sed &lt;- \"data/ebd_CL-LL_chutap1_smp_relSep-2025_sampling.txt\" # aquí debemos ajustar el nombre del archivo si trabajaremos con una descarga personal\nchecklists &lt;- read_sampling(f_sed, unique = FALSE) # leemos el archivo y generamos un objeto que contenga toda la información de las listas\nglimpse(checklists) # vemos un resumen rápido del objeto generado con la base de datos\n#&gt; Rows: 135,787\n#&gt; Columns: 33\n#&gt; $ last_edited_date          &lt;chr&gt; \"2023-03-08 18:35:28.525811\", \"2023-03-08 18…\n#&gt; $ country                   &lt;chr&gt; \"Chile\", \"Chile\", \"Chile\", \"Chile\", \"Chile\",…\n#&gt; $ country_code              &lt;chr&gt; \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"C…\n#&gt; $ state                     &lt;chr&gt; \"Los Lagos\", \"Los Lagos\", \"Los Lagos\", \"Los …\n#&gt; $ state_code                &lt;chr&gt; \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\",…\n#&gt; $ county                    &lt;chr&gt; \"Puerto Montt\", \"Curaco de Vélez\", \"Puerto V…\n#&gt; $ county_code               &lt;chr&gt; \"CL-LL-OMO\", \"CL-LL-CUR\", \"CL-LL-OVA\", \"CL-L…\n#&gt; $ iba_code                  &lt;chr&gt; NA, \"BIRDLIFE_26907\", NA, NA, NA, NA, NA, NA…\n#&gt; $ bcr_code                  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ usfws_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ atlas_block               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ locality                  &lt;chr&gt; \"piedra azul\", \"Curaco de Vélez--Humedales d…\n#&gt; $ locality_id               &lt;chr&gt; \"L19884201\", \"L20235644\", \"L20552704\", \"L205…\n#&gt; $ locality_type             &lt;chr&gt; \"P\", \"H\", \"P\", \"P\", \"P\", \"H\", \"H\", \"H\", \"H\",…\n#&gt; $ latitude                  &lt;dbl&gt; -41.5, -42.4, -41.3, -42.9, -41.2, -41.3, -4…\n#&gt; $ longitude                 &lt;dbl&gt; -72.8, -73.6, -72.9, -73.6, -74.1, -73.1, -7…\n#&gt; $ observation_date          &lt;date&gt; 2019-08-15, 2019-01-24, 2019-02-16, 2019-02…\n#&gt; $ time_observations_started &lt;chr&gt; \"08:00:00\", \"10:00:00\", \"17:08:00\", \"10:04:0…\n#&gt; $ observer_id               &lt;chr&gt; \"obsr2818200\", \"obsr1166222\", \"obsr279749\", …\n#&gt; $ observer_orcid_id         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ sampling_event_identifier &lt;chr&gt; \"S114001497\", \"S118804608\", \"S116936975\", \"S…\n#&gt; $ observation_type          &lt;chr&gt; \"Stationary\", \"Traveling\", \"Stationary\", \"St…\n#&gt; $ protocol_name             &lt;chr&gt; \"Stationary\", \"Traveling\", \"Stationary\", \"St…\n#&gt; $ protocol_code             &lt;chr&gt; \"P21\", \"P22\", \"P21\", \"P21\", \"P20\", \"P22\", \"P…\n#&gt; $ project_names             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ project_identifiers       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ duration_minutes          &lt;int&gt; 480, 60, 5, 10, NA, 46, 36, 39, 12, 38, 124,…\n#&gt; $ effort_distance_km        &lt;dbl&gt; NA, 1.000, NA, NA, NA, 0.253, 1.350, 0.270, …\n#&gt; $ effort_area_ha            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ number_observers          &lt;int&gt; 1, 1, 1, 1, NA, 4, 5, 4, 4, 4, 7, 3, 7, 4, 3…\n#&gt; $ all_species_reported      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, T…\n#&gt; $ group_identifier          &lt;chr&gt; NA, NA, NA, NA, NA, \"G4267503\", \"G4594512\", …\n#&gt; $ checklist_comments        &lt;chr&gt; \"observada desde mi ventan en carretera aust…\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTómate un tiempo para explorar las variables en el conjunto de datos de listas. Si no estás seguro acerca de alguna de las variables, puedes consultar el documento pdf de metadatos que viene con la descarga de datos (eBird_BaeBird_Basic_Dataset_Metadata_v1.16.pdf) o con la versión en español que puedes encontrar en la carpeta drive del curso (Manual-de-uso-base-de-datos-eBird-Chile-version-agosto-2025.pdf).\n\n\nPara algunas aplicaciones, solo se requieren los datos de listas. Por ejemplo, los datos de listas se pueden usar para investigar la distribución espacial y temporal de datos eBird dentro de una región. Este conjunto de datos también puede ser útil para explorar cuánta variación hay en las variables de esfuerzo de observación e identificar listas que tienen baja precisión espacial o temporal.\n\n\n\n\n\n\nEjercicio\n\n\n\nRealiza un histograma que muestre la distribución de las distancias recorridas en las listas (checklist) con protocolo “con desplazamiento”.\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nCasi el 90% de las listas tienen menos de 10 km de longitud; sin embargo, algunas listas alcanzan hasta los 80 km en distancia. Las listas de verificación con largas distancias de viaje tienen una presición espacial menor, por lo que no suelen usarse en ciertos análisis y por lo tanto se eliminan antes de este.\n\nchecklists_traveling &lt;- filter(checklists, protocol_name == \"Traveling\") #Aquí filtramos por el tipo de protocolo, en este caso, \"con desplazamiento\"\nggplot(checklists_traveling) +  # objeto con datos que queremos graficar\n  aes(x = effort_distance_km) + # variable que queremos en el eje x (distancia recorrida)\n  geom_histogram(binwidth = 5) + # ancho de los intervalos del histograma\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma) + # ajustamos el eje y para que comience en 0 y formateamos los números con separador de miles\n  labs(x = \"Distance traveled [km]\", # etiqueta del eje x\n       y = \"# of eBird checklists\", # etiqueta del eje y\n       title = \"Distribución de la distancia recorrida en las listas de eBird\") # título del gráfico\n#&gt; Warning: Removed 71 rows containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\nPosiblemente notaron que en el ejercicio anterior les apareció la advertencia “Removed 71 rows containing non-finite outside the scale range (stat_bin()).”. Este aviso nos indica que 71 filas de nuestra base de datos no fueron consideradas para el histograma porque el valor de effort_distance_km es no finito (NA, NaN o Inf). Esto no es grave, podemos revisar que ocurre con esas listas y corregir en caso de que sea necesario.\nAhora, importemos los datos de observación (EBD).\n\nf_ebd &lt;- \"data/ebd_CL-LL_chutap1_smp_relSep-2025.txt\" #Aquí debemos ajustar el nombre del archivo si trabajaremos con una descarga personal\nobservations &lt;- read_ebd(f_ebd, unique = FALSE, rollup = FALSE) # leemos el archivo y generamos un objeto que contenga toda la información de las observaciones\nglimpse(observations) # resumen rápido del objeto generado\n#&gt; Rows: 21,792\n#&gt; Columns: 52\n#&gt; $ global_unique_identifier   &lt;chr&gt; \"URN:CornellLabOfOrnithology:EBIRD:OBS22384…\n#&gt; $ last_edited_date           &lt;chr&gt; \"2024-10-14 12:41:13.045987\", \"2023-03-08 1…\n#&gt; $ taxonomic_order            &lt;int&gt; 14232, 14232, 14232, 14232, 14232, 14232, 1…\n#&gt; $ category                   &lt;chr&gt; \"species\", \"species\", \"species\", \"species\",…\n#&gt; $ taxon_concept_id           &lt;chr&gt; \"avibase-23178B5E\", \"avibase-23178B5E\", \"av…\n#&gt; $ common_name                &lt;chr&gt; \"Chucao Tapaculo\", \"Chucao Tapaculo\", \"Chuc…\n#&gt; $ scientific_name            &lt;chr&gt; \"Scelorchilus rubecula\", \"Scelorchilus rube…\n#&gt; $ subspecies_common_name     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ subspecies_scientific_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ exotic_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ observation_count          &lt;chr&gt; \"2\", \"1\", \"1\", \"1\", \"2\", \"4\", \"1\", \"3\", \"1\"…\n#&gt; $ breeding_code              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ breeding_category          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ behavior_code              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ age_sex                    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ country                    &lt;chr&gt; \"Chile\", \"Chile\", \"Chile\", \"Chile\", \"Chile\"…\n#&gt; $ country_code               &lt;chr&gt; \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"…\n#&gt; $ state                      &lt;chr&gt; \"Los Lagos\", \"Los Lagos\", \"Los Lagos\", \"Los…\n#&gt; $ state_code                 &lt;chr&gt; \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\"…\n#&gt; $ county                     &lt;chr&gt; \"Ancud\", \"Ancud\", \"Ancud\", \"Ancud\", \"Ancud\"…\n#&gt; $ county_code                &lt;chr&gt; \"CL-LL-ANC\", \"CL-LL-ANC\", \"CL-LL-ANC\", \"CL-…\n#&gt; $ iba_code                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ bcr_code                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ usfws_code                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ atlas_block                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ locality                   &lt;chr&gt; \"Chiloe Island, first year, Rodrigo's\", \"Ch…\n#&gt; $ locality_id                &lt;chr&gt; \"L2501072\", \"L2501072\", \"L2501072\", \"L25010…\n#&gt; $ locality_type              &lt;chr&gt; \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\"…\n#&gt; $ latitude                   &lt;dbl&gt; -41.9, -41.9, -41.9, -41.9, -41.9, -41.9, -…\n#&gt; $ longitude                  &lt;dbl&gt; -73.5, -73.5, -73.5, -73.5, -73.5, -73.5, -…\n#&gt; $ observation_date           &lt;date&gt; 1994-10-25, 1994-11-08, 1994-11-26, 1994-1…\n#&gt; $ time_observations_started  &lt;chr&gt; \"07:30:00\", \"07:30:00\", \"07:30:00\", \"07:30:…\n#&gt; $ observer_id                &lt;chr&gt; \"obsr213338\", \"obsr213338\", \"obsr213338\", \"…\n#&gt; $ observer_orcid_id          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ sampling_event_identifier  &lt;chr&gt; \"S16187694\", \"S16187936\", \"S16188333\", \"S16…\n#&gt; $ observation_type           &lt;chr&gt; \"Traveling\", \"Traveling\", \"Traveling\", \"Tra…\n#&gt; $ protocol_name              &lt;chr&gt; \"Traveling\", \"Traveling\", \"Traveling\", \"Tra…\n#&gt; $ protocol_code              &lt;chr&gt; \"P22\", \"P22\", \"P22\", \"P22\", \"P22\", \"P22\", \"…\n#&gt; $ project_names              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ project_identifiers        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ duration_minutes           &lt;int&gt; 120, 240, 180, 300, 240, 300, 240, 300, 10,…\n#&gt; $ effort_distance_km         &lt;dbl&gt; 8.05, 8.05, 6.44, 8.05, 8.05, 8.05, 32.19, …\n#&gt; $ effort_area_ha             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ number_observers           &lt;int&gt; 2, 2, 3, 2, 2, 2, 6, 2, 1, 2, 1, 3, 1, 3, 3…\n#&gt; $ all_species_reported       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#&gt; $ group_identifier           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ has_media                  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n#&gt; $ approved                   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#&gt; $ reviewed                   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n#&gt; $ reason                     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ checklist_comments         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ species_comments           &lt;chr&gt; \"courtship\", \"first nest! Chucao in & out, …\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTómate un tiempo para explorar las variables en el conjunto de datos de observación. Observa que el EBD duplica muchas de las variables a nivel de lista del SED.\n\n\nCuando leemos los datos en R, usamos unique = FALSE y rollup = FALSE. Por defecto, las funciones de lectura en el paquete auk realizan dos pasos importantes de preprocesamiento: combinar listas compartidas duplicadas y consolidación taxonómica. Intencionalmente desactivamos esta funcionalidad con fines demostrativos.\n\n2.2.1 Listas compartidas\neBird permite a los usuarios compartir listas de verificación con otros observadores de su grupo, por ejemplo, esta lista es compartida por 10 observadores. Estas listas se pueden identificar mirando la variable group_identifier, que asigna un ID que conecta todas las listas del grupo.\n\nchecklists %&gt;%  # colocamos el objeto con el que queremos trabajar, en este caso la base de datos de los listados\n  filter(!is.na(group_identifier)) %&gt;% # filtramos para quedarnos solo con las filas que presenten un ID de grupo \n  arrange(group_identifier) %&gt;% # ordenamos las filas filtradas de menor a mayor, esto facilita la observación \n  select(sampling_event_identifier, group_identifier) # seleccionamos solo las columnas 'sampling_event_identifier' y 'group_identifier' para reducir la información a lo que necesitamos\n#&gt; # A tibble: 59,623 × 2\n#&gt;   sampling_event_identifier group_identifier\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;           \n#&gt; 1 S133813900                G10000814       \n#&gt; 2 S133813899                G10000814       \n#&gt; 3 S133818644                G10001020       \n#&gt; 4 S133818643                G10001020       \n#&gt; 5 S133827106                G10001448       \n#&gt; 6 S133962903                G10001448       \n#&gt; # ℹ 59,617 more rows\n\nLas listas con el mismo group_identifier proporcionan información duplicada sobre el mismo evento de observación de aves en la base de datos. Para la mayoría de los análisis, es importante contraer estas listas de verificación compartidas en una sola lista de verificación. Esto se puede lograr con la función auk_unique(), que conserva solo una copia independiente de cada lista.\n\nchecklists_unique &lt;- auk_unique(checklists, checklists_only = TRUE) # generamos un nuevo objeto que contenga solo una copia independiente de cada lista\nnrow(checklists) # número de filas en el objeto original\n#&gt; [1] 135787\nnrow(checklists_unique) # número de filas en el nuevo objeto\n#&gt; [1] 99730\n\nObserve que se creó una nueva variable, checklist_id, que toma el valor de group_identifier para listas compartidas y de sampling_event_identifier para listas no compartidas.\n\nhead(checklists_unique$checklist_id) # vemos los primeros seis valores de la columna checklist_id\n#&gt; [1] \"S114001497\" \"S118804608\" \"S116936975\" \"S116936842\" \"S116974914\"\n#&gt; [6] \"S53230567\"\ntail(checklists_unique$checklist_id) # vemos los ultimos seis valores de la columna checklist_id\n#&gt; [1] \"G7616152\" \"G7628777\" \"G7626514\" \"G7634837\" \"G7636811\" \"G7637068\"\n\n\n\n\n\n\n\nTip\n\n\n\n¿Tienes curiosidad por saber qué listas y observadores contribuyeron a una lista compartida después de que se haya colapsado? El sample_event_identifier y el observador_id contienen listas separadas por comas de todas las listas y observadores que contribuyeron a las listas compartidas.\n\nchecklists_unique %&gt;% # del objeto que no contiene duplicado\n  filter(checklist_id == \"G10045560\") %&gt;% # filtramos las filas que correspondan a las listas del grupo \"G10045560\"\n  select(checklist_id, group_identifier, sampling_event_identifier, observer_id) \n#&gt; # A tibble: 1 × 4\n#&gt;   checklist_id group_identifier sampling_event_identifier            observer_id\n#&gt;   &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;                                &lt;chr&gt;      \n#&gt; 1 G10045560    G10045560        S134565230,S134565692,S134660967,S1… obsr199389…\n# seleccionamos solo las columnas que nos interesan para saber que listas y observadores contribuyeron en la observación \n\n\n\n\n\n2.2.2 Rollup taxonómico\nLas observaciones de eBird se pueden hacer a niveles por debajo de especie (por ejemplo, subespecie) o por encima de especie (por ejemplo, un ave que fue identificada como un pato, pero no se pudo determinar la especie); sin embargo, para la mayoría de los usos querremos observaciones a nivel de especie. Esto es especialmente cierto si queremos producir datos de detección/no detección a partir de listas completas, porque “completo” solo aplica a nivel de especie.\n\n\n\n\n\n\nTip\n\n\n\nEn el conjunto de datos de ejemplo utilizado para este curso, estos problemas taxonómicos no se aplican. Hemos solicitado observaciones de chucao, por lo que no hemos recibido ninguna observación de taxones por encima de la especie, ni tampoco subespecies. Sin embargo, en muchas otras situaciones, estos problemas taxonómicos pueden ser importantes. Por ejemplo, esta lista tiene 1 tijeral común y 1 tijeral común (aegithaloides). auk_rollup() combina las dos observaciones en una sola observación de tijeral común.\n\n\nLa función auk_rollup() elimina todas las observaciones no identificables a nivel de especie y consolida todas las observaciones reportadas por debajo de especie al nivel de especie.\nPara este ejercicio trabajaremos con el tijeral, por lo que antes de realizar el rollup debemos cargar la base de datos del tijeral en Chile (ebd_CL_pmtspi1_smp_relSep-2025.txt).\n\nft_ebd &lt;- \"data/ebd_CL_pmtspi1_smp_relSep-2025.txt\"\ntijeral &lt;- read_ebd(ft_ebd, unique = FALSE, rollup = FALSE) \n\nobservations_rollup &lt;- auk_rollup(tijeral)\n# uno de los ejemplos, revisamos la lista antes del rollup y comparamos con como queda la información luego del rollup. \ntijeral %&gt;% \n  filter(sampling_event_identifier == \"S109437960\") %&gt;% \n  select(sampling_event_identifier, common_name, subspecies_common_name, \n         observation_count)\n#&gt; # A tibble: 2 × 4\n#&gt;   sampling_event_identifier common_name subspecies_common_name observation_count\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;                  &lt;chr&gt;            \n#&gt; 1 S109437960                Plain-mant… Plain-mantled Tit-Spi… 1                \n#&gt; 2 S109437960                Plain-mant… &lt;NA&gt;                   1\nobservations_rollup %&gt;% \n  filter(sampling_event_identifier == \"S109437960\") %&gt;% \n  select(sampling_event_identifier, common_name,\n         observation_count)\n#&gt; # A tibble: 1 × 3\n#&gt;   sampling_event_identifier common_name                 observation_count\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;                       &lt;chr&gt;            \n#&gt; 1 S109437960                Plain-mantled Tit-Spinetail 2\n\n\n\n\n\n\n\nTip\n\n\n\nSi múltiples taxones en una sola lista se consolidan a la misma especie, auk_rollup() intenta combinarlos inteligentemente. Si cada observación tiene un conteo, esos conteos se suman, pero si alguna de las observaciones carece de conteo (es decir, el conteo es “X”) la observación combinada también recibe una “X”. En la lista de ejemplo del Tip anterior, con dos taxones consolidándose a tijeral común, auk_rollup() suma los dos conteos para obtener 2 tijeral común (1 + 1).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebird.html#sec-ebird-zf",
    "href": "ebird.html#sec-ebird-zf",
    "title": "2  Best Practices for using eBird Data",
    "section": "2.3 Generación de datos de detección/no detección",
    "text": "2.3 Generación de datos de detección/no detección\nLas listas completas de eBird son extremadamente valiosas porque, para todas las especies que no fueron reportadas, podemos inferir conteos de 0. Esto nos permite convertir datos de solo presencia a datos de detección/no detección, lo que nos permite realizar análisis mucho más robustos. Ten en cuenta que no usamos el término presencia/ausencia, porque una no detección no necesariamente implica que la especie estuvo ausente, solo que el observador no la detectó e identificó.\nNos referimos al proceso de producir datos de detección/no detección como “llenar con ceros” los datos de eBird (zero-filling), porque estamos llenando los ceros faltantes. Leeremos los datos de eBird en R nuevamente, y filtraremos solo las listas completas. Luego, usaremos la función auk_zerofill() para generar datos de detección/no detección. Ten en cuenta que las listas compartidas se combinan y la consolidación taxonómica se realiza por defecto al usar las funciones read_*() de auk.\n\n# importamos los datos de los listados (SED) \nchecklists &lt;- read_sampling(f_sed) %&gt;% \n  # seleccionamos solo los listados completos\n  filter(all_species_reported)\n# importamos los datos de observación (EBD)\nobservations &lt;- read_ebd(f_ebd) %&gt;% \n  # seleccionamos solo los listados completos\n  filter(all_species_reported)\n# uso de la función zero-fill para generar los datos de detección/no detección\nzf &lt;- auk_zerofill(observations, checklists, collapse = TRUE)\nglimpse(zf)\n#&gt; Rows: 80,577\n#&gt; Columns: 41\n#&gt; $ checklist_id              &lt;chr&gt; \"S114001497\", \"S118804608\", \"S116936975\", \"S…\n#&gt; $ last_edited_date          &lt;chr&gt; \"2023-03-08 18:35:28.525811\", \"2023-03-08 18…\n#&gt; $ country                   &lt;chr&gt; \"Chile\", \"Chile\", \"Chile\", \"Chile\", \"Chile\",…\n#&gt; $ country_code              &lt;chr&gt; \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"CL\", \"C…\n#&gt; $ state                     &lt;chr&gt; \"Los Lagos\", \"Los Lagos\", \"Los Lagos\", \"Los …\n#&gt; $ state_code                &lt;chr&gt; \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\", \"CL-LL\",…\n#&gt; $ county                    &lt;chr&gt; \"Puerto Montt\", \"Curaco de Vélez\", \"Puerto V…\n#&gt; $ county_code               &lt;chr&gt; \"CL-LL-OMO\", \"CL-LL-CUR\", \"CL-LL-OVA\", \"CL-L…\n#&gt; $ iba_code                  &lt;chr&gt; NA, \"BIRDLIFE_26907\", NA, NA, NA, NA, NA, NA…\n#&gt; $ bcr_code                  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ usfws_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ atlas_block               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ locality                  &lt;chr&gt; \"piedra azul\", \"Curaco de Vélez--Humedales d…\n#&gt; $ locality_id               &lt;chr&gt; \"L19884201\", \"L20235644\", \"L20552704\", \"L205…\n#&gt; $ locality_type             &lt;chr&gt; \"P\", \"H\", \"P\", \"P\", \"H\", \"H\", \"H\", \"H\", \"H\",…\n#&gt; $ latitude                  &lt;dbl&gt; -41.5, -42.4, -41.3, -42.9, -41.3, -41.3, -4…\n#&gt; $ longitude                 &lt;dbl&gt; -72.8, -73.6, -72.9, -73.6, -73.1, -73.1, -7…\n#&gt; $ observation_date          &lt;date&gt; 2019-08-15, 2019-01-24, 2019-02-16, 2019-02…\n#&gt; $ time_observations_started &lt;chr&gt; \"08:00:00\", \"10:00:00\", \"17:08:00\", \"10:04:0…\n#&gt; $ observer_id               &lt;chr&gt; \"obsr2818200\", \"obsr1166222\", \"obsr279749\", …\n#&gt; $ observer_orcid_id         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ sampling_event_identifier &lt;chr&gt; \"S114001497\", \"S118804608\", \"S116936975\", \"S…\n#&gt; $ observation_type          &lt;chr&gt; \"Stationary\", \"Traveling\", \"Stationary\", \"St…\n#&gt; $ protocol_name             &lt;chr&gt; \"Stationary\", \"Traveling\", \"Stationary\", \"St…\n#&gt; $ protocol_code             &lt;chr&gt; \"P21\", \"P22\", \"P21\", \"P21\", \"P62\", \"P22\", \"P…\n#&gt; $ project_names             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ project_identifiers       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ duration_minutes          &lt;int&gt; 480, 60, 5, 10, NA, 19, 22, 30, 23, 132, 2, …\n#&gt; $ effort_distance_km        &lt;dbl&gt; NA, 1.000, NA, NA, NA, 0.308, 1.850, NA, 3.2…\n#&gt; $ effort_area_ha            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ number_observers          &lt;int&gt; 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,…\n#&gt; $ all_species_reported      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n#&gt; $ group_identifier          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ checklist_comments        &lt;chr&gt; \"observada desde mi ventan en carretera aust…\n#&gt; $ scientific_name           &lt;chr&gt; \"Scelorchilus rubecula\", \"Scelorchilus rubec…\n#&gt; $ breeding_code             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ breeding_category         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ behavior_code             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ age_sex                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ observation_count         &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\",…\n#&gt; $ species_observed          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n\nLa variable observation_count tiene conteos verdaderos así como también “X”, estas indican que la especie fue detectada pero no se contó el número de individuos. auk_zerofill() agrega una nueva columna binaria, species_observed, indicando si la especie fue detectada o no.\n\nselect(zf, observation_count, species_observed) %&gt;% \n  head(10) # observamos los primero 10 valores de las columnas con conteos y si se detectó la especie o no\n#&gt; # A tibble: 10 × 2\n#&gt;   observation_count species_observed\n#&gt;   &lt;chr&gt;             &lt;lgl&gt;           \n#&gt; 1 0                 FALSE           \n#&gt; 2 0                 FALSE           \n#&gt; 3 0                 FALSE           \n#&gt; 4 0                 FALSE           \n#&gt; 5 0                 FALSE           \n#&gt; 6 0                 FALSE           \n#&gt; # ℹ 4 more rows\n\nConvirtamos las “X” en NAs y transformemos observation_count en una variable entera.\n\nzf$observation_count &lt;- if_else(zf$observation_count == \"X\", \n                                NA_character_, zf$observation_count) %&gt;% \n  as.integer()\nselect(zf, observation_count, species_observed) %&gt;% \n  head(10)\n#&gt; # A tibble: 10 × 2\n#&gt;   observation_count species_observed\n#&gt;               &lt;int&gt; &lt;lgl&gt;           \n#&gt; 1                 0 FALSE           \n#&gt; 2                 0 FALSE           \n#&gt; 3                 0 FALSE           \n#&gt; 4                 0 FALSE           \n#&gt; 5                 0 FALSE           \n#&gt; 6                 0 FALSE           \n#&gt; # ℹ 4 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebird.html#sec-ebird-filtering",
    "href": "ebird.html#sec-ebird-filtering",
    "title": "2  Best Practices for using eBird Data",
    "section": "2.4 Filtrado de datos",
    "text": "2.4 Filtrado de datos\nAhora que tienes un conjunto de datos de detección/no detección, es probable que quieras hacer algo con él. Por ejemplo, puedes querer hacer un mapa, identificar áreas prioritarias para una especie o entrenar un modelo de distribución de especies. Independientemente de la aplicación específica, es probable que primero se requiera algún filtrado de los datos. Algunas de las formas en que puedes querer filtrar los datos de eBird incluyen:\n\nFiltrado temporal: filtrar los datos a un rango específico de años o a una época específica del año.\nFiltrado espacial: filtrar los datos para enfocarse en una región específica, por ejemplo, un área protegida.\nAumento de la precisión: algunas listas de eBird son bastante largas en distancia o duración, lo que lleva a imprecisión espacial o temporal. Al eliminar listas más largas podemos aumentar la precisión espacial del conjunto de datos.\nReducción de la variación en el esfuerzo: a diferencia de los estudios científicos estructurados, los datos se pueden enviar a eBird usando una variedad de protocolos y hay una variación significativa en el esfuerzo entre listas en el conjunto de datos de eBird. La variación en el protocolo y el esfuerzo conduce a variación en la detectabilidad (más esfuerzo generalmente conduce a mayor detectabilidad). Podemos elegir imponer más estructura en el conjunto de datos de eBird filtrando para reducir la variación en protocolo y esfuerzo.\n\nEl filtrado específico que apliques dependerá de cómo pretendas usar los datos de eBird. Sin embargo, para este ejemplo, filtremos los datos de eBird solo a listas con desplazamiento y estacionarias de 2013-2025 que sean de menos de 6 horas de duración y 10 km de longitud.\n\nzf_filtered &lt;- zf %&gt;% \n  filter(year(observation_date) &gt;= 2013, year(observation_date) &lt;= 2025, # filtramos por años de interés\n         observation_type %in% c(\"Traveling\", \"Stationary\"), # filtramos por tipo de observación\n         duration_minutes &lt; 6 * 60, # filtramos listas que tengan una duración menor a 6 horas\n         effort_distance_km &lt; 10 | observation_type == \"Stationary\") # filtramos listas con distancias recorridas menores a 10 km\nnrow(zf)\n#&gt; [1] 80577\nnrow(zf_filtered)\n#&gt; [1] 75362\n\nRedujimos el número de listas en 5,215 pero las listas restantes son de mayor calidad.\nFinalmente, muchas de las columnas en este data frame son innecesarias o redundantes, así que seleccionaremos solo las columnas que necesitamos.\n\nchecklists_zf &lt;- zf_filtered %&gt;% \n  select(checklist_id, \n         latitude, longitude,\n         observation_date, time_observations_started,\n         observation_type,\n         duration_minutes, effort_distance_km, number_observers,\n         observation_count, species_observed)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebird.html#sec-ebird-applications",
    "href": "ebird.html#sec-ebird-applications",
    "title": "2  Best Practices for using eBird Data",
    "section": "2.5 Aplicaciones",
    "text": "2.5 Aplicaciones\n\n2.5.1 Frecuencia de detección\nLo más simple que podemos hacer con estas observaciones de eBird es estimar la frecuencia de detección del chucao en la región de Los Lagos. Esta es la proporción de listas de eBird en la región que detectaron la especie. species_observed es una columna binaria TRUE/FALSE que indica si se detectó la especie y R trata TRUE como 1 y FALSE como 0, por lo que podemos tomar el promedio de esta columna para obtener la frecuencia de detección.\n\nmean(checklists_zf$species_observed)\n#&gt; [1] 0.168\n\nEntonces, el chucao es bastante común dentro de esta región, con un 0.17% de las listas detectando la especie. La frecuencia de detección se puede usar para comparar la prevalencia de una especie entre regiones o a lo largo del tiempo. Veamos cómo cambia la frecuencia de detección a lo largo de los meses del año.\n\nmonthly_detection &lt;- checklists_zf %&gt;% \n  mutate(month = month(observation_date)) %&gt;% \n  group_by(month) %&gt;% \n  summarize(detection_frequency = mean(species_observed))\n\n# plot monthly detection frequency\nggplot(monthly_detection) +\n  aes(x = month, y = detection_frequency) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:12) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Mes del año\",\n       y = \"Frecuencia de detección\",\n       title = \"Frecuencia de detección mensual del chucao\",\n       subtitle = \"Los Lagos, Chile\")\n\n\n\n\n\n\n\n\nBasándose en este gráfico, el chucao parece ser más detectado entre diciembre y marzo.\n\n\n\n\n\n\nEjercicio\n\n\n\nUsa una técnica similar para calcular y graficar el número mensual de listas de eBird en Los Lagos. ¿Hay diferencias entre los meses? Si es así, ¿qué nos dice esto sobre el uso del número de detecciones a partir de datos de solo presencia como una medida de prevalencia?\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nExiste una variabilidad en el envío de listas por mes, con menos del doble de listas en enero comparado con junio. Si examináramos el número mensual de detecciones utilizando únicamente datos de presencia, esperaríamos más detecciones en los meses con mayor cantidad de listas, incluso si la prevalencia del chucao permanece constante.\n\nmonthly_checklists &lt;- count(checklists_zf, month = month(observation_date))\n\n# plot monthly number of checklists\nggplot(monthly_checklists) +\n  aes(x = month, y = n) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:12) +\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma) +\n  labs(x = \"Mes del año\",\n       y = \"Número de listados en eBird\",\n       title = \"Listados mensuales subidos a eBird en Los Lagos\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Conversión a formato espacial {#sec-ebird-appli = ions-spatial}\nMuchas aplicaciones de datos de eBird requieren convertir los datos en un formato explícitamente espacial, por ejemplo, para hacer un mapa o filtrar las observaciones solo a aquellas dentro de un polígono para un área protegida. El paquete de R sf se puede usar para representar puntos, líneas y polígonos espaciales en R. Podemos convertir el data frame de las listas a un objeto sf usando la latitud y longitud.\n\nchecklists_sf &lt;- st_as_sf(checklists_zf, coords = c(\"longitude\", \"latitude\"),\n                          # 4326 is the code for an unprojected lon/lat\n                          # coordiante reference system\n                          crs = 4326)\nprint(checklists_sf)\n#&gt; Simple feature collection with 75362 features and 9 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -75.3 ymin: -43.8 xmax: -71.7 ymax: -40.2\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 75,362 × 10\n#&gt;   checklist_id observation_date time_observations_started observation_type\n#&gt; * &lt;chr&gt;        &lt;date&gt;           &lt;chr&gt;                     &lt;chr&gt;           \n#&gt; 1 S118804608   2019-01-24       10:00:00                  Traveling       \n#&gt; 2 S116936975   2019-02-16       17:08:00                  Stationary      \n#&gt; 3 S116936842   2019-02-13       10:04:00                  Stationary      \n#&gt; 4 S59435786    2019-09-01       15:09:00                  Traveling       \n#&gt; 5 S58442786    2019-07-25       13:47:00                  Traveling       \n#&gt; 6 S62449405    2019-12-18       16:40:00                  Stationary      \n#&gt; # ℹ 75,356 more rows\n#&gt; # ℹ 6 more variables: duration_minutes &lt;int&gt;, effort_distance_km &lt;dbl&gt;,\n#&gt; #   number_observers &lt;int&gt;, observation_count &lt;int&gt;, species_observed &lt;lgl&gt;,\n#&gt; #   geometry &lt;POINT [°]&gt;\n\nImagina que solo estamos interesados en observaciones dentro de 50 km de Dalcahue, Chile. Podemos usar sf para generar un círculo de radio 50 km centrado en Dalcahue, y luego filtrar las observaciones que caen dentro del círculo.\n\n# Asignamos las coordenadas de nuestro punto de interés, en este caso las coordenadas de Dalcahue\ndalcahue_point &lt;- st_sfc(st_point(c(-73.6473, -42.3796)), crs = 4326)\n\n# Generamos un circulo a partir del punto con un buffer de 50 km\ndalcahue_circle &lt;- st_buffer(dalcahue_point, dist = 50000)\n\n# Filtramos los registros que caen dentro del área\nchecklists_dalcahue &lt;- checklists_sf[dalcahue_circle, ]\n\nAhora podríamos, por ejemplo, calcular la frecuencia de detección en el área alrededor de Dalcahue.\n\nmean(checklists_dalcahue$species_observed)\n#&gt; [1] 0.205\n\nFinalmente, en muchos casos, puede ser más conveniente trabajar con datos de eBird fuera de R en un SIG como QGIS, un programa gratuito y de código abierto. Podemos exportar las observaciones de chucao a un GeoPackage usando sf.\n\nwrite_sf(checklists_sf, \"data/chutap1-ebird_CL-LL.gpkg\",\n         layer = \"chucao_observations\")\n\n\n\n\n\n\n\nTip\n\n\n\nEl GeoPackage es una alternativa moderna y de código abierto en formato shapefile para almacenar datos espaciales. Los GeoPackages evitan muchos de los problemas y limitaciones asociados con los shapefiles, y son mucho más eficientes que los shapefiles. La documentación en línea de ArcGIS proporciona instrucciones sobre cómo abrir un GeoPackage en ArcGIS.\n\n\n\n\n2.5.3 Mapeo\nAhora que tenemos los datos en formato espacial, podemos producir un mapa de los datos de detección/no detección del chucao. Para mapas complejos y altamente personalizados, recomendamos usar un SIG como QGIS que está específicamente diseñado para cartografía. Sin embargo, es posible hacer un mapa rápido y simple en R.\nComenzaremos cargando polígonos que definen las fronteras de países y estados, que proporcionarán información contextual para nuestro mapa. Estos polígonos provienen de Natural Earth, una excelente fuente de datos espaciales globales sin atribución. El paquete de R rnaturaleart proporciona acceso a datos de Natural Earth dentro de R; sin embargo, por conveniencia hemos preparado las capas necesarias la clase pasada y además están para descarga en el archivo data/gis-data.gpkg incluido en los archivos para el curso. Proyectaremos todo a una proyección de área igual centrada en la región de Los Lagos, Chile.\n\ncrs &lt;- st_crs(\"+proj=laea +lat_0=-41 +lon_0=-72.5\")\n\n# Polígonos de Natural Earth\nne_land &lt;- read_sf(\"data/gis-data-chile.gpkg\", \"chile_territorio\") %&gt;% \n  st_transform(crs = crs)\nne_country_lines &lt;- read_sf(\"data/gis-data-chile.gpkg\", \"chile_fronteras\") %&gt;% \n  st_transform(crs = crs)\nrgds_boundary &lt;- read_sf(\"data/gis-data-chile.gpkg\", \"chile_regiones\") %&gt;% \n  filter(region == \"Los Lagos\") %&gt;% \n  st_transform(crs = crs)\n\n# transform ebird data to equal area projection\nchecklists_proj &lt;- st_transform(checklists_sf, crs = crs)\n\nAhora podemos hacer un mapa de observaciones de chucao en Los Lagos. Construimos el mapa en capas, primero creando un mapa base con los polígonos de Natural Earth, luego graficando los datos de detección y no detección de eBird encima. Al construir un mapa en capas como este, a menudo es útil primero graficar una versión en blanco del conjunto de datos principal que pretendes mapear para definir la extensión espacial del mapa, luego superponer todo lo demás, finalizando con graficar los datos una segunda vez para que aparezcan como la capa superior.\n\n# Configuramos los márgenes del gráfico (reducidos para maximizar espacio del mapa)\npar(mar = c(0.25, 0.25, 2, 0.25))\n\n# Cresmos un gráfico en blanco que define la extensión espacial del mapa. Esto establece los límites del área que queremos mostrar\nplot(st_geometry(checklists_proj), col = NA)\n\n# Agregamos las capas de contexto geográfico (de fondo hacia adelante)\n\n# 1. Territorio de Chile (gris claro de fondo)\nplot(ne_land, \n     col = \"#eeeeee\",      # color gris claro para el territorio\n     border = \"#888888\",   # borde gris oscuro\n     lwd = 0.5,           # grosor de línea delgado\n     add = TRUE)          # agregar a gráfico existente\n\n# 2. Región de Los Lagos (gris medio para destacarla)\nplot(rgds_boundary, \n     col = \"#cccccc\",     # color gris medio\n     border = NA,         # sin borde \n     add = TRUE)         # agregar a gráfico existente\n\n# 3. Fronteras internacionales (líneas negras)\nplot(ne_country_lines, \n     col = \"#000000\",     # color negro para  fronteras\n     lwd = 1.5,          # línea más gruesa\n     add = TRUE)\n\n# 4. observaciones de eBird\n# Listas donde NO se detectó Chucao (puntos grises pequeños)\nplot(filter(checklists_proj, !species_observed),\n     pch = 19,                          # punto sólido\n     cex = 0.2,                         # tamaño pequeño\n     col = alpha(\"#555555\", 0.5),       # gris semi-transparente\n     add = TRUE)\n#&gt; Warning in plot.sf(filter(checklists_proj, !species_observed), pch = 19, :\n#&gt; ignoring all but the first attribute\n\n# Listas donde SÍ se detectó Chucao (puntos verdes más grandes)\nplot(filter(checklists_proj, species_observed),\n     pch = 19,                          # punto sólido\n     cex = 0.3,                         # tamaño ligeramente mayor\n     col = alpha(\"#4daf4a\", 1),         # verde sólido\n     add = TRUE)\n#&gt; Warning in plot.sf(filter(checklists_proj, species_observed), pch = 19, :\n#&gt; ignoring all but the first attribute\n\n# Agregamos la leyenda\nlegend(\"bottomleft\",                   # posición en esquina inferior izquierda\n       bty = \"n\",                       # sin caja alrededor\n       col = c(\"#555555\", \"#4daf4a\"),   # colores: gris y verde\n       legend = c(\"Listas de eBird\",    # texto de leyenda\n                  \"Avistamientos de Chucao\"),\n       pch = 19)                        # símbolo: punto sólido\n\n# Agregsmos el borde y título\nbox()                                   # marco alrededor del mapa\ntitle(\"Observaciones de Chucao en eBird (2013-2025)\\nRegión de Los Lagos, Chile\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-access",
    "href": "ebirdst.html#sec-ebirdst-access",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "",
    "text": "Checkpoint\n\n\n\nPara asegurarte de que tu clave de acceso a los datos funciona, intenta ejecutar el siguiente código, que descargará un único archivo pequeño. Si no funciona, habla con el instructor o envíanos un correo para buscar una solución al problema.\n\ndir.create(\"data/ebirdst-data\", recursive = TRUE, showWarnings = FALSE) \n\nebirdst_download_status(\"grbfir1\", pattern = \"abundance_median_3km\", path = \"data/ebirdst-data/\", force = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-species",
    "href": "ebirdst.html#sec-ebirdst-species",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "4.2 Especies con Estados y Tendencias",
    "text": "4.2 Especies con Estados y Tendencias\nEl objeto ebirdst_runs es un data frame que enumera todas las especies disponibles:\n\nglimpse(ebirdst_runs)\n#&gt; Rows: 2,981\n#&gt; Columns: 30\n#&gt; $ species_code                   &lt;chr&gt; \"yebsap-example\", \"abetow\", \"absfin1\", …\n#&gt; $ scientific_name                &lt;chr&gt; \"Sphyrapicus varius\", \"Melozone aberti\"…\n#&gt; $ common_name                    &lt;chr&gt; \"Yellow-bellied Sapsucker\", \"Abert's To…\n#&gt; $ is_resident                    &lt;lgl&gt; FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, F…\n#&gt; $ breeding_quality               &lt;chr&gt; \"3\", NA, NA, \"3\", NA, NA, \"1\", NA, NA, …\n#&gt; $ breeding_start                 &lt;date&gt; 2023-05-17, NA, NA, 2023-05-31, NA, NA…\n#&gt; $ breeding_end                   &lt;date&gt; 2023-08-16, NA, NA, 2023-08-02, NA, NA…\n#&gt; $ nonbreeding_quality            &lt;chr&gt; \"3\", NA, NA, \"3\", NA, NA, \"1\", NA, NA, …\n#&gt; $ nonbreeding_start              &lt;date&gt; 2023-11-22, NA, NA, 2023-11-22, NA, NA…\n#&gt; $ nonbreeding_end                &lt;date&gt; 2023-03-08, NA, NA, 2023-02-22, NA, NA…\n#&gt; $ postbreeding_migration_quality &lt;chr&gt; \"3\", NA, NA, \"3\", NA, NA, \"0\", NA, NA, …\n#&gt; $ postbreeding_migration_start   &lt;date&gt; 2023-08-23, NA, NA, 2023-08-09, NA, NA…\n#&gt; $ postbreeding_migration_end     &lt;date&gt; 2023-11-15, NA, NA, 2023-11-15, NA, NA…\n#&gt; $ prebreeding_migration_quality  &lt;chr&gt; \"3\", NA, NA, \"3\", NA, NA, \"0\", NA, NA, …\n#&gt; $ prebreeding_migration_start    &lt;date&gt; 2023-03-15, NA, NA, 2023-03-01, NA, NA…\n#&gt; $ prebreeding_migration_end      &lt;date&gt; 2023-05-10, NA, NA, 2023-05-24, NA, NA…\n#&gt; $ resident_quality               &lt;chr&gt; NA, \"3\", \"3\", NA, \"3\", \"3\", NA, \"2\", \"3…\n#&gt; $ resident_start                 &lt;date&gt; NA, 2023-01-04, 2023-01-04, NA, 2023-0…\n#&gt; $ resident_end                   &lt;date&gt; NA, 2023-12-27, 2023-12-27, NA, 2023-1…\n#&gt; $ status_version_year            &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 202…\n#&gt; $ has_trends                     &lt;lgl&gt; TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, F…\n#&gt; $ trends_season                  &lt;chr&gt; \"breeding\", \"resident\", NA, \"breeding\",…\n#&gt; $ trends_region                  &lt;chr&gt; \"north_america\", \"north_america\", NA, \"…\n#&gt; $ trends_start_year              &lt;dbl&gt; 2012, 2012, NA, 2012, 2011, NA, NA, NA,…\n#&gt; $ trends_end_year                &lt;dbl&gt; 2022, 2022, NA, 2022, 2021, NA, NA, NA,…\n#&gt; $ trends_start_date              &lt;chr&gt; \"05-24\", \"01-25\", NA, \"05-24\", \"11-01\",…\n#&gt; $ trends_end_date                &lt;chr&gt; \"08-16\", \"05-10\", NA, \"08-02\", \"05-03\",…\n#&gt; $ rsquared                       &lt;dbl&gt; 0.857, 0.923, NA, 0.857, 0.881, NA, NA,…\n#&gt; $ beta0                          &lt;dbl&gt; 0.22700, -0.01392, NA, 0.68942, -0.0926…\n#&gt; $ trends_version_year            &lt;dbl&gt; 2022, 2022, NA, 2022, 2022, NA, NA, NA,…\n\nDesde RStudio también puedes utilizar View() para explorar de forma interactiva la base de datos. También puedes consultar la página de especies en Estados y Tendencias para ver la lista completa de especies disponibles. En esta página puedes filtrar por región, por ejemplo, para ver solo aquellas especies con alguna parte de su área de distribución dentro de Chile.\nEn el paquete de datos proveemos una lista de las aves de Chile, el cual podemos utilizar para filtrar el objeto “ebirdst_runs” para obtener la lista de especies con productos de S&T encontrados en el país.\n\naves_chile &lt;- read.csv2(\"data/lista aves de chile.csv\")\nstr(aves_chile)\n#&gt; 'data.frame':    563 obs. of  14 variables:\n#&gt;  $ orden_taxonomico  : int  35 161 165 171 205 219 220 224 231 233 ...\n#&gt;  $ codigo_eBird      : chr  \"lesrhe2\" \"orntin1\" \"chitin1\" \"andtin1\" ...\n#&gt;  $ categoría         : chr  \"especie\" \"especie\" \"especie\" \"especie\" ...\n#&gt;  $ orden             : chr  \"Rheiformes\" \"Tinamiformes\" \"Tinamiformes\" \"Tinamiformes\" ...\n#&gt;  $ familia           : chr  \"Rheidae\" \"Tinamidae\" \"Tinamidae\" \"Tinamidae\" ...\n#&gt;  $ nombre_cientifico : chr  \"Rhea pennata\" \"Nothoprocta ornata\" \"Nothoprocta perdicaria\" \"Nothoprocta pentlandii\" ...\n#&gt;  $ nombre_comun      : chr  \"Suri/Ñandú\" \"Perdiz cordillerana\" \"Perdiz chilena\" \"Perdiz andina\" ...\n#&gt;  $ nombre_inglés     : chr  \"Lesser Rhea\" \"Ornate Tinamou\" \"Chilean Tinamou\" \"Andean Tinamou\" ...\n#&gt;  $ clasificacion_IUCN: chr  \"LC\" \"LC\" \"LC\" \"LC\" ...\n#&gt;  $ clasificacion_RCE : chr  \"\" \"\" \"LC\" \"\" ...\n#&gt;  $ estado            : chr  \"X\" \"X\" \"X(e)\" \"X\" ...\n#&gt;  $ merlin_sound      : int  NA NA NA NA NA NA NA NA NA 1 ...\n#&gt;  $ status            : int  NA NA NA 1 NA NA NA 1 1 1 ...\n#&gt;  $ trends            : int  NA NA NA NA NA NA NA NA NA 1 ...\n\nebirdst_runs_chile &lt;- ebirdst_runs %&gt;% \n  filter(scientific_name %in% aves_chile$nombre_cientifico) %&gt;% \n left_join(\n    aves_chile %&gt;% select(nombre_cientifico, nombre_comun, estado),\n    by = c(\"scientific_name\" = \"nombre_cientifico\")\n  )\n\nglimpse(ebirdst_runs_chile)\n#&gt; Rows: 470\n#&gt; Columns: 32\n#&gt; $ species_code                   &lt;chr&gt; \"absfin1\", \"amekes\", \"ameoys\", \"amered\"…\n#&gt; $ scientific_name                &lt;chr&gt; \"Geospizopsis plebejus\", \"Falco sparver…\n#&gt; $ common_name                    &lt;chr&gt; \"Ash-breasted Sierra Finch\", \"American …\n#&gt; $ is_resident                    &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE…\n#&gt; $ breeding_quality               &lt;chr&gt; NA, \"3\", \"3\", \"3\", \"3\", \"3\", NA, NA, NA…\n#&gt; $ breeding_start                 &lt;date&gt; NA, 2023-05-17, 2023-05-10, 2023-06-14…\n#&gt; $ breeding_end                   &lt;date&gt; NA, 2023-08-02, 2023-07-26, 2023-07-19…\n#&gt; $ nonbreeding_quality            &lt;chr&gt; NA, \"3\", \"3\", \"3\", \"3\", \"3\", NA, NA, NA…\n#&gt; $ nonbreeding_start              &lt;date&gt; NA, 2023-11-15, 2023-11-22, 2023-11-29…\n#&gt; $ nonbreeding_end                &lt;date&gt; NA, 2023-02-15, 2023-02-22, 2023-03-15…\n#&gt; $ postbreeding_migration_quality &lt;chr&gt; NA, \"3\", \"3\", \"3\", \"3\", \"3\", NA, NA, NA…\n#&gt; $ postbreeding_migration_start   &lt;date&gt; NA, 2023-08-09, 2023-08-02, 2023-07-26…\n#&gt; $ postbreeding_migration_end     &lt;date&gt; NA, 2023-11-08, 2023-11-15, 2023-11-22…\n#&gt; $ prebreeding_migration_quality  &lt;chr&gt; NA, \"3\", \"3\", \"3\", \"3\", \"3\", NA, NA, NA…\n#&gt; $ prebreeding_migration_start    &lt;date&gt; NA, 2023-02-22, 2023-03-01, 2023-03-22…\n#&gt; $ prebreeding_migration_end      &lt;date&gt; NA, 2023-05-10, 2023-05-03, 2023-06-07…\n#&gt; $ resident_quality               &lt;chr&gt; \"3\", NA, NA, NA, NA, NA, \"2\", \"3\", \"3\",…\n#&gt; $ resident_start                 &lt;date&gt; 2023-01-04, NA, NA, NA, NA, NA, 2023-0…\n#&gt; $ resident_end                   &lt;date&gt; 2023-12-27, NA, NA, NA, NA, NA, 2023-1…\n#&gt; $ status_version_year            &lt;dbl&gt; 2023, 2023, 2023, 2023, 2023, 2023, 202…\n#&gt; $ has_trends                     &lt;lgl&gt; FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, …\n#&gt; $ trends_season                  &lt;chr&gt; NA, \"breeding\", \"breeding\", \"breeding\",…\n#&gt; $ trends_region                  &lt;chr&gt; NA, \"north_america\", \"north_america\", \"…\n#&gt; $ trends_start_year              &lt;dbl&gt; NA, 2012, 2012, 2012, NA, NA, NA, NA, N…\n#&gt; $ trends_end_year                &lt;dbl&gt; NA, 2022, 2022, 2022, NA, NA, NA, NA, N…\n#&gt; $ trends_start_date              &lt;chr&gt; NA, \"05-17\", \"05-10\", \"06-21\", NA, NA, …\n#&gt; $ trends_end_date                &lt;chr&gt; NA, \"08-09\", \"07-26\", \"07-12\", NA, NA, …\n#&gt; $ rsquared                       &lt;dbl&gt; NA, 0.877, 0.770, 0.835, NA, NA, NA, NA…\n#&gt; $ beta0                          &lt;dbl&gt; NA, 0.891, 0.834, -0.107, NA, NA, NA, N…\n#&gt; $ trends_version_year            &lt;dbl&gt; NA, 2022, 2022, 2022, NA, NA, NA, NA, N…\n#&gt; $ nombre_comun                   &lt;chr&gt; \"Plebeyo\", \"Cernícalo\", \"Pilpilén común…\n#&gt; $ estado                         &lt;chr&gt; \"X\", \"X\", \"X\", \"E\", \"NR\", \"E\", \"X\", \"X\"…\n\n\n4.2.1 Revisión de expertos\nTodas las especies pasan por un proceso de revisión por parte de expertos humanos antes de ser publicadas. El marco de datos «ebirdst_runs» también contiene información de este proceso de revisión. Los revisores evalúan cada una de las cuatro estaciones: reproducción, no reproducción, migración previa a la reproducción y migración posterior a la reproducción. Las especies residentes (es decir, no migratorias) se identifican con el valor «TRUE» en la columna resident column of ebirdst_runs, y estas especies se evalúan a lo largo de todo el año en lugar de por temporadas. «ebirdst_runs» contiene dos datos importantes para cada estación: una calificación de calidad (quality) y fechas estacionales (seasonal dates).\nLas seasonal dates definen las semanas que comprenden cada estación; las estimaciones de abundancia relativa para estas semanas se promedian para producir los mapas de abundancia relativa estacional en el sitio de Estados y Tendencias. Las fechas de la temporada reproductiva y no reproductiva se definen para cada especie como las semanas durante esas estaciones en las que la población de la especie no se desplaza. Por esta razón, estas estaciones también se describen como períodos estacionarios. Los períodos de migración se definen como los períodos de movimiento entre las temporadas estacionarias no reproductivas y reproductivas. Cabe señalar que, para muchas especies, estos períodos migratorios incluyen no solo el movimiento desde las zonas de reproducción a las zonas no reproductivas, sino también la dispersión posterior a la reproducción, la migración por muda y otros movimientos.\nLos revisores también examinan las estimaciones del modelo para cada temporada con el fin de evaluar el grado de extrapolación u omisión presente en el modelo, y asignan una calificación de calidad asociada que va de 0 (calidad más baja) a 3 (calidad más alta). La extrapolación se refiere a los casos en los que el modelo predice la presencia de una especie cuando se sabe que está ausente, mientras que la omisión se refiere a los casos en los que el modelo no predice la presencia de una especie cuando se sabe que está presente.\nUna calificación de 0 implica que esta temporada no ha superado la revisión y que los resultados del modelo no deben utilizarse en absoluto para este período. Las calificaciones de 1 a 3 corresponden a un gradiente de mayor a menor extrapolación y/u omisión, y a menudo utilizamos una analogía con los semáforos para referirnos a ellas:\n\nLuz roja (1): baja calidad, extrapolación y/u omisión extensas y ruido, pero al menos algunas regiones tienen estimaciones precisas; se puede utilizar con precaución en determinadas regiones.\nLuz amarilla (2): calidad media, cierta extrapolación y/u omisión; utilizar con precaución.\nLuz verde (3): calidad alta, muy poca o ninguna extrapolación y/u omisión; estas temporadas se pueden utilizar con seguridad.\n\n\n\n\n\n\n\nEjercicio\n\n\n\nElije una especie que te interese. Identifica las fechas estacionales y la calificacion de calidad.\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl Picaflor chico está catalogado como migratorio, con una calificación de calidad de 2 en las cuatro estaciones, lo que sugiere que hay alguna extrapolación u omisión.\n\nebirdst_runs %&gt;% \n  filter(scientific_name == \"Sephanoides sephaniodes\") %&gt;% \n  glimpse()\n#&gt; Rows: 1\n#&gt; Columns: 30\n#&gt; $ species_code                   &lt;chr&gt; \"grbfir1\"\n#&gt; $ scientific_name                &lt;chr&gt; \"Sephanoides sephaniodes\"\n#&gt; $ common_name                    &lt;chr&gt; \"Green-backed Firecrown\"\n#&gt; $ is_resident                    &lt;lgl&gt; FALSE\n#&gt; $ breeding_quality               &lt;chr&gt; \"3\"\n#&gt; $ breeding_start                 &lt;date&gt; 2023-11-22\n#&gt; $ breeding_end                   &lt;date&gt; 2023-04-26\n#&gt; $ nonbreeding_quality            &lt;chr&gt; \"3\"\n#&gt; $ nonbreeding_start              &lt;date&gt; 2023-06-14\n#&gt; $ nonbreeding_end                &lt;date&gt; 2023-08-30\n#&gt; $ postbreeding_migration_quality &lt;chr&gt; \"2\"\n#&gt; $ postbreeding_migration_start   &lt;date&gt; 2023-05-03\n#&gt; $ postbreeding_migration_end     &lt;date&gt; 2023-06-07\n#&gt; $ prebreeding_migration_quality  &lt;chr&gt; \"2\"\n#&gt; $ prebreeding_migration_start    &lt;date&gt; 2023-09-06\n#&gt; $ prebreeding_migration_end      &lt;date&gt; 2023-11-15\n#&gt; $ resident_quality               &lt;chr&gt; NA\n#&gt; $ resident_start                 &lt;date&gt; NA\n#&gt; $ resident_end                   &lt;date&gt; NA\n#&gt; $ status_version_year            &lt;dbl&gt; 2023\n#&gt; $ has_trends                     &lt;lgl&gt; TRUE\n#&gt; $ trends_season                  &lt;chr&gt; \"breeding\"\n#&gt; $ trends_region                  &lt;chr&gt; \"south_america\"\n#&gt; $ trends_start_year              &lt;dbl&gt; 2014\n#&gt; $ trends_end_year                &lt;dbl&gt; 2021\n#&gt; $ trends_start_date              &lt;chr&gt; \"11-22\"\n#&gt; $ trends_end_date                &lt;chr&gt; \"04-26\"\n#&gt; $ rsquared                       &lt;dbl&gt; 0.625\n#&gt; $ beta0                          &lt;dbl&gt; -0.194\n#&gt; $ trends_version_year            &lt;dbl&gt; 2022",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-download",
    "href": "ebirdst.html#sec-ebirdst-download",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "4.3 Descarga de datos",
    "text": "4.3 Descarga de datos\nLa función ebirdst_download_status() descarga datos de una sola especie a partir del nombre de la especie (nombre común en inglés, nombre científico o código de especie). Por ejemplo, para descargar los datos del Picaflor chico, utilice:\n\npath &lt;- ebirdst_download_status(species = \"Sephanoides sephaniodes\", path = \"data/ebirdst-data\", force = TRUE)\npath\n\n\n#&gt; [1] \"data/ebirdst-data/2023/grbfir1\"\n\nLa función identificará automáticamente una ubicación adecuada para almacenar los datos descargados y devolverá esa ruta, que hemos capturado en la variable path. Podemos ver qué archivos se han descargado con:\n\nlist.files(path, recursive = TRUE)\n#&gt;  [1] \"config.json\"                                                       \n#&gt;  [2] \"seasonal/grbfir1_abundance_full-year_max_27km_2023.tif\"            \n#&gt;  [3] \"seasonal/grbfir1_abundance_full-year_max_3km_2023.tif\"             \n#&gt;  [4] \"seasonal/grbfir1_abundance_full-year_max_9km_2023.tif\"             \n#&gt;  [5] \"seasonal/grbfir1_abundance_full-year_mean_27km_2023.tif\"           \n#&gt;  [6] \"seasonal/grbfir1_abundance_full-year_mean_3km_2023.tif\"            \n#&gt;  [7] \"seasonal/grbfir1_abundance_full-year_mean_9km_2023.tif\"            \n#&gt;  [8] \"seasonal/grbfir1_abundance_seasonal_max_27km_2023.tif\"             \n#&gt;  [9] \"seasonal/grbfir1_abundance_seasonal_max_3km_2023.tif\"              \n#&gt; [10] \"seasonal/grbfir1_abundance_seasonal_max_9km_2023.tif\"              \n#&gt; [11] \"seasonal/grbfir1_abundance_seasonal_mean_27km_2023.tif\"            \n#&gt; [12] \"seasonal/grbfir1_abundance_seasonal_mean_3km_2023.tif\"             \n#&gt; [13] \"seasonal/grbfir1_abundance_seasonal_mean_9km_2023.tif\"             \n#&gt; [14] \"seasonal/grbfir1_proportion-population_seasonal_mean_27km_2023.tif\"\n#&gt; [15] \"seasonal/grbfir1_proportion-population_seasonal_mean_3km_2023.tif\" \n#&gt; [16] \"seasonal/grbfir1_proportion-population_seasonal_mean_9km_2023.tif\" \n#&gt; [17] \"weekly/grbfir1_abundance_lower_27km_2023.tif\"                      \n#&gt; [18] \"weekly/grbfir1_abundance_lower_3km_2023.tif\"                       \n#&gt; [19] \"weekly/grbfir1_abundance_lower_9km_2023.tif\"                       \n#&gt; [20] \"weekly/grbfir1_abundance_median_27km_2023.tif\"                     \n#&gt; [21] \"weekly/grbfir1_abundance_median_3km_2023.tif\"                      \n#&gt; [22] \"weekly/grbfir1_abundance_median_9km_2023.tif\"                      \n#&gt; [23] \"weekly/grbfir1_abundance_upper_27km_2023.tif\"                      \n#&gt; [24] \"weekly/grbfir1_abundance_upper_3km_2023.tif\"                       \n#&gt; [25] \"weekly/grbfir1_abundance_upper_9km_2023.tif\"                       \n#&gt; [26] \"weekly/grbfir1_proportion-population_median_27km_2023.tif\"         \n#&gt; [27] \"weekly/grbfir1_proportion-population_median_3km_2023.tif\"          \n#&gt; [28] \"weekly/grbfir1_proportion-population_median_9km_2023.tif\"\n\nDentro de este directorio de paquetes de datos, los archivos están organizados según la siguiente estructura:\n\nweekly/: un directorio que contiene estimaciones semanales de ocurrencia, conteo, abundancia relativa y proporción de población en una cuadrícula regular en formato GeoTIFF con tres resoluciones. Ver más abajo para obtener más detalles.\nseasonal/: un directorio que contiene estimaciones estacionales de ocurrencia, conteo, abundancia relativa y proporción de población en una cuadrícula regular en formato GeoTIFF con tres resoluciones. Estas se derivan de los datos ráster semanales correspondientes. Las fechas que definen los límites de cada estación se establecen en función de cada especie por un revisor experto familiarizado con la misma. Estas fechas están disponibles en el marco de datos ebirdst_runs. Solo se incluyen las estaciones que han superado el proceso de revisión por expertos. Ver más abajo para obtener más detalles.\nranges/: un directorio que contiene GeoPackages que almacenan polígonos de límites de distribución. Ver más abajo para obtener más detalles.\nconfig.json: parámetros específicos de la ejecución, principalmente para uso interno, pero que también contienen parámetros útiles para cartografiar los datos de abundancia.\n\n\n\n\n\n\n\nTip\n\n\n\nLos datos espaciales se dividen en dos grandes categorías: datos ráster y datos vectoriales. Los datos ráster representan los datos espaciales como una cuadrícula regular de celdas con un valor o conjunto de valores asignados a cada una. Los datos vectoriales representan los datos espaciales como puntos, líneas o polígonos discretos. En los productos de datos de eBird Status, los datos ráster se distribuyen como GeoTIFF, mientras que los datos vectoriales se distribuyen como GeoPackages.\n\n\nPara una especie cuyos datos ya se han descargado, puede utilizar get_species_path(\"Sephanoides sephaniodes\") para identificar la ruta de acceso a los datos.\n\n4.3.1 Descarga de archivos específicos\nEl paquete completo de datos de cada especie contiene un gran número de archivos, muchos de los cuales pueden ser innecesarios para su aplicación. Puede utilizar el argumento dry_run = TRUE en ebirdst_download() para obtener una lista de los archivos disponibles sin descargarlos.\n\nebirdst_download_status(\"Sephanoides sephaniodes\", dry_run = TRUE)\n\nUna vez identificados los archivos que desea, puede utilizar el argumento pattern para descargar solo esos archivos. Por ejemplo, imaginemos que solo queremos los archivos abundance:\n\nebirdst_download_status(\"Sephanoides sephaniodes\", pattern = \"abundance\", path = \"data/ebirdst-data/\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-load",
    "href": "ebirdst.html#sec-ebirdst-load",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "4.4 Cargando datos en R",
    "text": "4.4 Cargando datos en R\nEn este curso, nos centraremos en los productos de datos ráster, que se pueden cargar en R utilizando la función load_raster() de ebirdst. En R, utilizaremos el paquete terra para trabajar con datos ráster. Los productos de datos ráster se dividen en dos grandes categorías que proporcionan estimaciones semanales y estacionales.\n\n4.4.1 Estimaciones semanales ráster\nLos productos básicos de datos ráster son las estimaciones semanales de presencia, conteo, abundancia relativa y proporción de población. Todas las estimaciones son el valor medio esperado para un listado con desplazamiento de eBird de 1 km y 1 hora realizado por un observador experto en el momento óptimo del día y en las condiciones meteorológicas óptimas para observar la especie en cuestión.\n\nOcurrencia occurrence: la probabilidad esperada de encontrar una especie.\nConteo count: el conteo esperado de una especie, condicionado a su ocurrencia en la ubicación dada.\nAbundancia relativa abundance: la abundancia relativa esperada de una especie, calculada como el producto de la probabilidad de ocurrencia y el conteo condicionado a la ocurrencia. Además de la abundancia relativa mediana, se proporcionan intervalos de confianza (IC) superiores e inferiores, definidos en el decil 10 y el decil 90 de la abundancia relativa, respectivamente.\nProporción de población proportion-population: la proporción de la abundancia relativa total dentro de cada celda. Se trata de un producto derivado que se calcula dividiendo cada valor de celda de abundancia relativa del ráster por la suma de todos los valores de celda.\n\nTodas las predicciones se realizan en una cuadrícula global estándar de 2,96 km x 2,96 km; sin embargo, también se proporcionan archivos GeoTIFF de menor resolución, que suelen ser mucho más rápidos de manejar. Las tres resoluciones son:\n\nAlta resolución (3km): datos con una resolución nativa de 2,96 km.\nResolución media (9km): datos 3km agregados por un factor de 3 en cada dirección, lo que da como resultado una resolución de 8,89 km.\nBaja resolución (27km): datos 3km agregados por un factor de 9 en cada dirección, lo que da como resultado una resolución de 26,7 km.\n\nLos archivos semanales utilizan la siguiente convención de nomenclatura:\nweekly/&lt;species_code&gt;_&lt;product&gt;_&lt;metric&gt;_&lt;resolution&gt;_&lt;year&gt;.tif\ndonde metric suele ser median, excepto en los IC de abundancia relativa, que utilizan lower y upper. La función load_raster() se utiliza para cargar estos datos en R y toma argumentos para product, metric y resolution. Por ejemplo, para cargar la abundancia relativa mediana de alta resolución, utilice:\n\nabd_median_3km &lt;- load_raster(species = \"grbfir1\", \n                              path = \"data/ebirdst-data/\", \n                              product = \"abundance\", \n                              period = \"weekly\", \n                              metric = \"median\", \n                              resolution = \"3km\")\nprint(abd_median_3km)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 5562, 11484, 52  (nrow, ncol, nlyr)\n#&gt; resolution  : 3000, 3000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source      : grbfir1_abundance_median_3km_2023.tif \n#&gt; names       : 2023-01-04, 2023-01-11, 2023-01-18, 2023-01-25, 2023-02-01, 2023-02-08, ... \n#&gt; min values  :       0.00,       0.00,       0.00,        0.0,       0.00,       0.00, ... \n#&gt; max values  :       4.09,       4.97,       4.53,        3.9,       3.76,       4.41, ...\n\nA menudo nos referimos a estos objetos ráster como cubos semanales (por ejemplo, el cubo de abundancia semanal). Obsérvese que los cubos contienen 52 capas, que corresponden a las semanas del año. Los nombres de las capas son las fechas asociadas al punto medio de cada semana.\n\nas.Date(names(abd_median_3km))\n#&gt;  [1] \"2023-01-04\" \"2023-01-11\" \"2023-01-18\" \"2023-01-25\" \"2023-02-01\"\n#&gt;  [6] \"2023-02-08\" \"2023-02-15\" \"2023-02-22\" \"2023-03-01\" \"2023-03-08\"\n#&gt; [11] \"2023-03-15\" \"2023-03-22\" \"2023-03-29\" \"2023-04-05\" \"2023-04-12\"\n#&gt; [16] \"2023-04-19\" \"2023-04-26\" \"2023-05-03\" \"2023-05-10\" \"2023-05-17\"\n#&gt; [21] \"2023-05-24\" \"2023-05-31\" \"2023-06-07\" \"2023-06-14\" \"2023-06-21\"\n#&gt; [26] \"2023-06-28\" \"2023-07-05\" \"2023-07-12\" \"2023-07-19\" \"2023-07-26\"\n#&gt; [31] \"2023-08-02\" \"2023-08-09\" \"2023-08-16\" \"2023-08-23\" \"2023-08-30\"\n#&gt; [36] \"2023-09-06\" \"2023-09-13\" \"2023-09-20\" \"2023-09-27\" \"2023-10-04\"\n#&gt; [41] \"2023-10-11\" \"2023-10-18\" \"2023-10-25\" \"2023-11-01\" \"2023-11-08\"\n#&gt; [46] \"2023-11-15\" \"2023-11-22\" \"2023-11-29\" \"2023-12-06\" \"2023-12-13\"\n#&gt; [51] \"2023-12-20\" \"2023-12-27\"\n\nComo otro ejemplo, podríamos cargar los intervalos de confianza de abundancia superior e inferior de baja resolución.\n\nabd_lower_27km &lt;- load_raster(species = \"grbfir1\", \n                              path = \"data/ebirdst-data/\",\n                              product = \"abundance\", \n                              metric = \"lower\", \n                              period = \"weekly\",\n                              resolution = \"27km\")\n\nabd_upper_27km &lt;- load_raster(species = \"grbfir1\", \n                              path = \"data/ebirdst-data/\",\n                              product = \"abundance\", \n                              metric = \"upper\", \n                              period = \"weekly\",\n                              resolution = \"27km\")\n\n\n\n\n\n\n\nEjercicio\n\n\n\nIntente cargar el cubo del porcentaje medio semanal de la población con una resolución media.\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\npct_pop &lt;- load_raster(species = \"grbfir1\", \n                       path = \"data/ebirdst-data/\",\n                       product = \"proportion-population\", \n                       metric = \"median\", \n                       resolution = \"9km\")\nprint(pct_pop)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 1854, 3828, 52  (nrow, ncol, nlyr)\n#&gt; resolution  : 9000, 9000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source      : grbfir1_proportion-population_median_9km_2023.tif \n#&gt; names       : 2023-01-04, 2023-01-11, 2023-01-18, 2023-01-25, 2023-02-01, 2023-02-08, ... \n#&gt; min values  :    0.00000,    0.00000,     0.0000,    0.00000,   0.000000,   0.000000, ... \n#&gt; max values  :    0.00115,    0.00122,     0.0012,    0.00101,   0.000919,   0.000875, ...\n\n\n\n\n\n\n4.4.2 Rásters de estimaciones estacionales\nLos rásters de estimaciones estacionales se proporcionan para el mismo conjunto de productos y con las mismas tres resoluciones que las estimaciones semanales. Se obtienen a partir de los datos semanales tomando la media o el máximo por celda a lo largo de las semanas de cada estación. Recuerde que las fechas límite estacionales están disponibles en ebirdst_runs; no se proporcionan datos para las estaciones con una puntuación de calidad de 0.\nLos GeoTIFF estacionales utilizan la siguiente convención de nomenclatura:\nseasonal/&lt;species_code&gt;_&lt;product&gt;_seasonal_&lt;metric&gt;_&lt;resolution&gt;_&lt;year&gt;.tif\ndonde metric es mean o max. La función load_raster(period = \"seasonal\") se utiliza para cargar estos datos en R y toma argumentos para product, metric y resolution. Por ejemplo, para cargar la abundancia relativa estacional media de baja resolución, utilice:\n\nabd_seasonal_mean &lt;- load_raster(species = \"grbfir1\", \n                                 path = \"data/ebirdst-data/\",\n                                 product = \"abundance\", \n                                 period = \"seasonal\", \n                                 metric = \"mean\", \n                                 resolution = \"27km\")\nprint(abd_seasonal_mean)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 618, 1276, 4  (nrow, ncol, nlyr)\n#&gt; resolution  : 27000, 27000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source      : grbfir1_abundance_seasonal_mean_27km_2023.tif \n#&gt; names       : breeding, nonbreeding, prebree~gration, postbre~gration \n#&gt; min values  :     0.00,        0.00,            0.00,             0.0 \n#&gt; max values  :     3.28,        4.89,            2.47,             5.3\n\nObserve que hay cuatro capas en este ráster que corresponden a las cuatro estaciones.\n\nnames(abd_seasonal_mean)\n#&gt; [1] \"breeding\"               \"nonbreeding\"            \"prebreeding_migration\" \n#&gt; [4] \"postbreeding_migration\"\n\nPor último, para mayor comodidad, los productos de datos incluyen rásteres anuales que resumen la media o el máximo de todas las semanas que caen dentro de una estación que ha superado el proceso de revisión por expertos. Se puede acceder a ellos de forma similar a los productos estacionales, solo que con «period = “full-year”» en lugar de «period = “week”». Por ejemplo, estas capas se pueden utilizar en la planificación de la conservación para evaluar los sitios más importantes en todo el área de distribución y el ciclo anual completo de una especie.\n\nabd_fy_max &lt;- load_raster(species = \"grbfir1\",  \n                          path = \"data/ebirdst-data/\", \n                          product = \"abundance\", \n                          period = \"full-year\", \n                          metric = \"max\", \n                          resolution = \"3km\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-explore",
    "href": "ebirdst.html#sec-ebirdst-explore",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "4.5 Explorando los datos ráster",
    "text": "4.5 Explorando los datos ráster\nCarguemos los ráster de abundancia relativa semanal y estacional de baja resolución y utilicémoslos para demostrar algunas operaciones ráster básicas con los datos.\n\nabd_weekly &lt;- load_raster(species = \"grbfir1\",  \n                          path = \"data/ebirdst-data/\",\n                          product = \"abundance\", \n                          resolution = \"27km\")\n\nabd_seasonal &lt;- load_raster(species = \"grbfir1\",  \n                            path = \"data/ebirdst-data/\", \n                            product = \"abundance\", \n                            period = \"seasonal\", \n                            resolution = \"3km\")\n\nEstos ráster se pueden dividir fácilmente en subconjuntos de una sola semana o temporada.\n\n# week of may 17\nabd_weekly[[\"2023-05-17\"]]\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 618, 1276, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 27000, 27000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source      : grbfir1_abundance_median_27km_2023.tif \n#&gt; name        : 2023-05-17 \n#&gt; min value   :       0.00 \n#&gt; max value   :       5.49\n\n# breeding season\nabd_seasonal[[\"breeding\"]]\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 5562, 11484, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 3000, 3000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source      : grbfir1_abundance_seasonal_mean_3km_2023.tif \n#&gt; name        : breeding \n#&gt; min value   :     0.00 \n#&gt; max value   :     4.57\n\nTambién podemos dividir el ráster semanal en un rango de semanas. Por ejemplo, dividamos solo las estimaciones de las semanas de mayo y luego calculemos el promedio de todas las semanas.\n\n# determine qué fechas podemos incluir\nweek_dates &lt;- as.Date(names(abd_weekly))\nstart_date &lt;- as.Date(\"2023-05-01\")\nend_date &lt;- as.Date(\"2023-05-31\")\nweek_in_may &lt;- week_dates &gt;= start_date & week_dates &lt;= end_date\n\n# subset a las semanas de mayo\nabd_weekly_may &lt;- abd_weekly[[week_in_may]]\n\n# promedio semanal\nmean(abd_weekly_may, na.rm = TRUE)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 618, 1276, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 27000, 27000  (x, y)\n#&gt; extent      : -17226000, 17226000, -8343000, 8343000  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : WGS 84 / Equal Earth Greenwich (EPSG:8857) \n#&gt; source(s)   : memory\n#&gt; name        : mean \n#&gt; min value   : 0.00 \n#&gt; max value   : 5.34\n\nCrear un mapa sencillo con los datos producirá resultados inesperados. Por ejemplo, vamos a trazar un mapa de la abundancia relativa durante la temporada de reproducción del Picaflro chico.\n\nplot(abd_seasonal[[\"breeding\"]])\n\n\n\n\n\n\n\n\nRecuerda que todos los productos de datos de eBird Status se proporcionan para todo el mundo, independientemente del área de distribución de las especies. Además, tenga en cuenta que algunas zonas, como la mayor parte de la cuenca del Amazonas, tienen valores faltantes, lo que indica que no se disponía de datos suficientes para hacer una predicción en la región. Otras zonas, como América del Norte, contaban con datos suficientes para predecir que la especie está ausente. Probemos a utilizar los datos SIG incluidos en el paquete de datos del curso para recortar el ráster a la región de Los Lagos y crear un mapa más significativo.\n\n# Límite de Los Lagos, proyectado para coincidir con los datos ráster.\nlos_lagos &lt;- read_sf(\"data/gis-data.gpkg\",  layer = \"ne_states\") %&gt;% \n  filter(state == \"Los Lagos\") %&gt;% \n  st_transform(crs = crs(abd_seasonal)) %&gt;% \n  st_geometry()\n\n# Recortar datos ráster a Chile\nabd_breeding_ll &lt;- crop(abd_seasonal[[\"breeding\"]], los_lagos)\n\n# mapear\nplot(abd_breeding_ll)\nplot(los_lagos, add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nHagamos una pausa antes de continuar con algunas aplicaciones más realistas de los productos de datos de eBird Status. Asegúrate de que te sientes cómodo cargando los datos en R y realizando algunas de las operaciones básicas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-applications",
    "href": "ebirdst.html#sec-ebirdst-applications",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "4.6 Aplicaciones de productos S&T",
    "text": "4.6 Aplicaciones de productos S&T\nAhora trabajaremos algunos ejemplos de aplicaciones prácticas utilizando los productos de Estados y Tendencias.\n\nTrayectorias: visualiza el cambio en la proporción de la población de un grupo de especies en una región determinada a lo largo del año.\nEstadísticas regionales: calcula la proporción de la población reproductiva presente en áreas protegidas para un grupo de especies.\nPriorización: us los productos de Estados para identificas áreas de importancia para la protección de un grupo de especies.\n\n\n4.6.1 Trayectorias\nEn este ejercicio, analizaremos el cambio en las poblaciones de dos especies a lo largo del año en la región de Los Lagos. Consideraremos el Picaflor chico y la Viudita, dos especies migratorias que son casi endémicas de Chile. Al comparar varias especies, o una sola especie entre diferentes estaciones, como es el caso aquí, es importante tener en cuenta la proporción de la población en lugar de la abundancia relativa para mitigar el impacto de las diferencias en la detectabilidad entre estaciones y especies.\nComencemos cargando los datos de proporción de población semanal de resolución media para estas especies, así como un polígono límite para Los Lagos.\n\n# datos de proporción de la población\npop_grbfir1 &lt;- load_raster(species = \"grbfir1\", \n                       path = \"data/ebirdst-data/\",\n                       product = \"proportion-population\", \n                       metric = \"median\", \n                       resolution = \"9km\")\n\n\nebirdst_download_status(\"Patagonian Tyrant\", path = \"data/ebirdst-data/\")\n\npop_pattyr2 &lt;- load_raster(species = \"pattyr2\", \n                       path = \"data/ebirdst-data/\",\n                       product = \"proportion-population\", \n                       metric = \"median\", \n                       resolution = \"9km\")\n\n# límite de Los Lagos proyectado a la misma proyección de los datos ráster\nlos_lagos &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_states\") %&gt;% \n  filter(state == \"Los Lagos\") %&gt;% \n  st_transform(crs = crs(pop_grbfir1)) %&gt;% \n  st_geometry()\n\nAhora utilizaremos el paquete exactextractr para calcular la suma de las proporciones de cada especies en Los Lagos.\n\n# suma dentro de los lagos\n# picaflor chico\ntray_grbfir1 &lt;- exact_extract(pop_grbfir1, los_lagos, fun = \"sum\")\ntray_grbfir1 &lt;- data.frame(species = \"Green-backed Firecrown\",\n                           week = as.Date(names(pop_grbfir1)),\n                           prop_pop = as.numeric(tray_grbfir1[1, ]))\n# viudita\ntray_pattyr2 &lt;- exact_extract(pop_pattyr2, los_lagos, fun = \"sum\")\ntray_pattyr2 &lt;- data.frame(species = \"Patagonian Tyrant\",\n                           week = as.Date(names(pop_pattyr2)),\n                           prop_pop = as.numeric(tray_pattyr2[1, ]))\n\n# combinar\ntrayectorias &lt;- bind_rows(tray_grbfir1, tray_pattyr2)\nhead(trayectorias)\n#&gt;                  species       week prop_pop\n#&gt; 1 Green-backed Firecrown 2023-01-04    0.244\n#&gt; 2 Green-backed Firecrown 2023-01-11    0.230\n#&gt; 3 Green-backed Firecrown 2023-01-18    0.256\n#&gt; 4 Green-backed Firecrown 2023-01-25    0.244\n#&gt; 5 Green-backed Firecrown 2023-02-01    0.243\n#&gt; 6 Green-backed Firecrown 2023-02-08    0.238\n\nFinally we can plot the trajectories.\n\nggplot(trayectorias, aes(x = week, y = prop_pop, color = species)) +\n  geom_line() +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Semana\", \n       y = \"% de población\",\n       title = \"Trayectorias de % semanal de la proporción de la población en Los Lagos\",\n       color = NULL) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n4.6.2 Estadísticas regionales\nPara este ejercicio calcularemos la proporción de la población dentro de areas protegidas en Chile para un grupo de especies. Como un ejemplo de grupo de especies usaremos 10 especies endémicas o casi endémicas de Chile. Para las especies que sean migratorias nos enfocaremos en la temporada reproductiva.\nPara elegir el grupo de especies podemos filtrar las especie en ‘ebirdst_runs_chile’ a solo aquellas que son endémicas. Vemos que solo hay 9 especies endémicas con modelos S&T, por lo que de estas tomaremos las especies con rangos geográficos superpuestos y agregaremos algunas otras especies residentes similares. Recomendamos utilizar un grupo de especies que utilicen areas geográficas similares para realizar el ejercicio de priorización, ya que si son de zonas totalmente distintas es dificil encontrar areas para priorizar para el grupo.\n\n\n\n© Michel Gutierrez, Macaulay Library (#323675721)\n\n\n\nendemicas &lt;- ebirdst_runs_chile %&gt;% \n  filter(estado == \"X(e)\")\n\nlista_especies &lt;- c(\"cthhue1\", \"chipig2\", \"chimoc1\", \"crachi1\", \"chutap1\", \n                  \"slbpar1\", \"chitin1\", \"whttap1\", \"moutur1\", \"dutcan1\")\n\n# descargar datos para el grupo de especies\nfor (i in 1:length(lista_especies)){\n  ebirdst_download_status(lista_especies[i], path = \"data/ebirdst-data/\", pattern = \"proportion-population_seasonal_mean_9km\")\n}\n\n# agregar nombre común, residente/migratoria y calidad\nlista_especies &lt;- filter(ebirdst_runs, species_code %in% lista_especies) %&gt;% \n  mutate(quality = ifelse(is_resident, resident_quality, breeding_quality)) %&gt;% \n  dplyr::select(species_code, common_name, is_resident, quality)\nprint(lista_especies)\n#&gt; # A tibble: 10 × 4\n#&gt;   species_code common_name                 is_resident quality\n#&gt;   &lt;chr&gt;        &lt;chr&gt;                       &lt;lgl&gt;       &lt;chr&gt;  \n#&gt; 1 chimoc1      Chilean Mockingbird         TRUE        3      \n#&gt; 2 chipig2      Chilean Pigeon              FALSE       3      \n#&gt; 3 chitin1      Chilean Tinamou             TRUE        3      \n#&gt; 4 chutap1      Chucao Tapaculo             TRUE        3      \n#&gt; 5 crachi1      Crag Chilia                 TRUE        2      \n#&gt; 6 cthhue1      Chestnut-throated Huet-huet TRUE        2      \n#&gt; # ℹ 4 more rows\n\nTenemos dos especies migratorias y ocho residentes. Observe que 0 de estas especies tienen una calificación de calidad de 1, lo que indica que se debe tener precaución al utilizar los resultados. Para su uso en el mundo real, debe examinar los mapas de abundancia relativa en busca de errores antes de utilizarlos para el análisis; sin embargo, para este ejemplo, utilizaremos esta lista de especies tal cual. Cargaremos y combinaremos los porcentajes de población reproductora (para las migratorias) y residente (para las residentes) de esta lista de especies.\n\n\n\n\n\n\nTip\n\n\n\nLas estimaciones de abundancia relativa se ven afectadas por las tasas de detección, que pueden variar entre especies. Por lo tanto, al comparar los datos entre especies, es fundamental utilizar siempre las capas de proporción de población, que se han estandarizado dividiendo el valor de cada celda por la abundancia relativa total de todas las celdas.\n\n\n\n# loop over the species list extracting the seasonal percent of population\nproporcion_poblacion &lt;- list()\nfor (i in seq_len(nrow(lista_especies))) {\n  # load the seasonal cube for this species\n  this_species &lt;- lista_especies[i, ]\n  pop &lt;- load_raster(this_species$species_code, \n                     path = \"data/ebirdst-data\", \n                     product = \"proportion-population\", \n                     period = \"seasonal\",\n                     resolution = \"9km\")\n  \n  # subset to the layer we need: breeding or resident\n  pop &lt;- pop[[ifelse(this_species$is_resident, \"resident\", \"breeding\")]]\n  proporcion_poblacion[[this_species$species_code]] &lt;- pop\n}\n# stack the rasters into a single object\nproporcion_poblacion &lt;- rast(proporcion_poblacion)\n\nLos datos SIG disponibles en el paquete de datos del taller contienen límites poligonales de las áreas protegidas públicas de Chile. Vamos a cargarlos ahora y proyectarlos para que coincidan con las capas ráster. Para este ejemplo, combinaremos todos los polígonos de las áreas protegidas en una sola característica; sin embargo, este análisis podría modificarse para tener en cuenta cómo varía la distribución de las especies entre las áreas protegidas.\n\nprotegido &lt;- read_sf(\"data/gis-data.gpkg\",  layer = \"protected_areas\") %&gt;% \n  st_combine() %&gt;% \n  st_transform(crs = crs(proporcion_poblacion))\n\nFinally, we can use exactextracr to calculate the total percent of population within protected areas for each species.\n\nporcentaje_protegido &lt;- exact_extract(proporcion_poblacion, protegido, fun = \"sum\")\nporcentaje_protegido &lt;- as.numeric(porcentaje_protegido[1, ])\nporcentaje_protegido &lt;- data.frame(species_code = lista_especies$species_code,\n                                common_name = lista_especies$common_name,\n                                proporcion_poblacion = porcentaje_protegido) %&gt;% \n  arrange(desc(proporcion_poblacion))\nprint(porcentaje_protegido)\n#&gt;    species_code                 common_name proporcion_poblacion\n#&gt; 1       chutap1             Chucao Tapaculo              0.16700\n#&gt; 2       chipig2              Chilean Pigeon              0.06149\n#&gt; 3       cthhue1 Chestnut-throated Huet-huet              0.02409\n#&gt; 4       whttap1     White-throated Tapaculo              0.01827\n#&gt; 5       moutur1            Moustached Turca              0.01618\n#&gt; 6       dutcan1      Dusky-tailed Canastero              0.01558\n#&gt; 7       slbpar1     Slender-billed Parakeet              0.01450\n#&gt; 8       crachi1                 Crag Chilia              0.01301\n#&gt; 9       chimoc1         Chilean Mockingbird              0.00794\n#&gt; 10      chitin1             Chilean Tinamou              0.00696\n\n# plotear los datos\nggplot(porcentaje_protegido) +\n  aes(x = fct_reorder(common_name, proporcion_poblacion),\n      y = proporcion_poblacion) +\n  geom_col() +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = NULL, y = \"Proporción de la población en áreas protegidas\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n4.6.3 Priorización\nPara el ejercicio final, realizaremos una priorización de sitios multiespecíficos, identificando sitios importantes para proteger el conjunto de 10 especies casi endémicas que identificamos en el ejercicio anterior. Comencemos por generar una capa de importancia multiespecífica calculando el porcentaje medio de población de las 10 especies. Dado que nos centramos en identificar sitios en Chile, también recortaremos y enmascararemos la capa de importancia dentro de los límites de Chile.\n\n# límite territorio chileno\nchile &lt;- read_sf(\"data/gis-data.gpkg\", layer = \"ne_states\") %&gt;% \n  filter(country_code == \"CL\") %&gt;% \n  st_transform(crs = crs(proporcion_poblacion))\n\n# importancia: porcentaje promedio de proporción de la población entre especies\n# rellenar valores faltantes con ceros antes de promediar \nimportancia &lt;- ifel(is.na(proporcion_poblacion), 0, proporcion_poblacion) %&gt;% \n  mean(na.rm = TRUE) %&gt;% \n  # recortar y enmascarar a límite chileno\n  crop(chile) %&gt;% \n  mask(chile)\n#&gt; \n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n# plotear la raíz cuadrada de la importancia, ya que los datos están sesgados hacia la derecha.\npar(mar = c(0.25, 0.25, 0.25, 0.25))\ncrs &lt;- \"+proj=laea +lat_0=-40 +lon_0=-72\"\nr_plot &lt;- sqrt(importancia) %&gt;% \n  project(crs, method = \"near\") %&gt;% \n  trim()\nplot(r_plot, axes = FALSE)\n\n\n\n\n\n\n\n\nLos números absolutos de este mapa son difíciles de interpretar (son la proporción media de la población de las 10 especies en cada celda). En cambio, los valores deben interpretarse en términos relativos, dando la importancia relativa de cada celda para este conjunto de 10 especies.\nEn la aplicación anterior, examinamos las áreas protegidas públicas existentes. Para efectos comparativos, imaginemos que queremos identificar los sitios más importantes de Chile que cubren la misma superficie que la red de áreas protegidas existente. ¿Qué proporción de Chile cubre la red actual de áreas protegidas?\n\n# proporción de Chile en red existente de áreas protegidas\narea_chile &lt;- sum(st_area(chile))\narea_protegida &lt;- st_area(protegido)\nproporcion_protegido &lt;- as.numeric(area_protegida / area_chile)\nprint(proporcion_protegido)\n#&gt; [1] 0.208\n\nEntonces, 20.8% de Chile está cubierto por la red existente de áreas protegidas públicas. Identifiquemos el 20.8% de celdas más importantes desde la capa de importancia multiespecies.\n\n# indentificar el quantil correspondiente al nivel de protección deseado\nq &lt;- global(importancia, fun = quantile, \n            probs = 1 - proporcion_protegido, na.rm = TRUE) %&gt;% \n  as.numeric()\n# identificar las celdas más importantes\nsitios_seleccionados &lt;- as.numeric(importancia &gt;= q)\n\nComparemos loa mapas de la red existente de áreas protegidas y las seleccionadas usando Estados y Tendencias.\n\npar(mar = c(0.25, 0.25, 0.25, 0.25))\n\n# importancia alta\nr_plot &lt;- project(sitios_seleccionados, crs, method = \"near\") %&gt;% \n  trim()\nproy_protegido &lt;- st_transform(protegido, crs = crs) %&gt;% \n  st_geometry()\nplot(r_plot, axes = FALSE, legend = FALSE)\n\n# existente\nplot(st_simplify(proy_protegido), \n     col = \"grey50\", border = NA,\n     add = TRUE)\n\n\n\n\n\n\n\n\nLos sitios de alta importancia que identificamos se muestran en verde, mientras que la red de áreas protegidas existente se superpone en gris. Vemos que la red de áreas protegidas existente se encuentra principalmente en el sur de Chile y que hay una superposición limitada con las áreas de alta importancia para las 10 especies casi endémicas en las que decidimos centrarnos. Esto no es sorprendente, ya que la ubicación de las áreas protegidas existentes no se eligió específicamente para proteger estas 10 especies. Cuantifiquemos qué proporción de la población capturan estas dos regiones.\n\n# enmascarar las capas de proporción de población por los sitios seleccionados\npp_seleccionados &lt;- proporcion_poblacion %&gt;% \n  crop(sitios_seleccionados) %&gt;% \n  mask(sitios_seleccionados, maskvalues = c(0, NA))\n\n# calcular el porcentaje total de población dentro de los sitios propuestos\nporcentaje_seleccionados &lt;- global(pp_seleccionados, fun = \"sum\", na.rm = TRUE)\nporcentaje_seleccionados &lt;- data.frame(species_code = names(pp_seleccionados),\n                               porcentaje_seleccionados = porcentaje_seleccionados[, 1])\n\n# combinar con los valores de la red existente\ncomparasion &lt;- inner_join(porcentaje_protegido, porcentaje_seleccionados,\n                         by = \"species_code\") %&gt;% \n  rename(existing_network = proporcion_poblacion,\n         prioritized_sites = porcentaje_seleccionados) %&gt;% \n  pivot_longer(cols = c(existing_network, prioritized_sites),\n               names_to = \"network_type\",\n               values_to = \"proporcion_poblacion\")\n\nggplot(comparasion) +\n  aes(x = fct_reorder(common_name, proporcion_poblacion, .fun = max),\n      y = proporcion_poblacion,\n      group = network_type,\n      fill = network_type) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = NULL, \n       y = \"Proporción de población en áreas protegidas\",\n       fill = NULL) +\n  coord_flip() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nPor lo tanto, para una misma superficie total, podríamos capturar una proporción mucho mayor de las poblaciones de estas especies si utilizáramos los productos de datos de eBird Status para estas especies en nuestra priorización de sitios. Por supuesto, este ejemplo es demasiado simplista. Por ejemplo, en una aplicación real, los diferentes sitios tienen diferentes costos asociados a la protección y habría que tenerlo en cuenta a la hora de establecer las prioridades. Para problemas de priorización más complejos, se pueden utilizar eficazmente herramientas de planificación sistemática de la conservación, como el paquete R prioritizr, junto con los productos de datos de Estados de eBird.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html",
    "href": "intror.html",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "",
    "text": "1.1 Introducción\nA lo largo de los ejercicios de este curso dejaremos explicaciones de las funciones utilizadas, pero si buscas profundizar en el uso de Tidyverse te recomendamos el libro en línea R for Data Science by Hadley Wickham.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "distabund.html",
    "href": "distabund.html",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "",
    "text": "3.1 Tasa de encuentro\nEn este capítulo estimaremos la tasa de avistamiento del Zorzal de Swainson en las listas de eBird durante el mes de junio en el estado de Georgia. Definimos la tasa de avistamiento como la probabilidad de que un observador de eBird encuentre una especie en una lista estándar de eBird.\nLa métrica ecológica que nos interesa es la probabilidad de que una especie se encuentre en un sitio (es decir, la probabilidad de ocupación). Normalmente, esto no se puede estimar con datos de ciencia ciudadana semiestructurados como los de eBird, ya que generalmente no podemos estimar la detectabilidad absoluta. Sin embargo, al tener en cuenta gran parte de la variación en la detectabilidad mediante la inclusión de covariables de esfuerzo en nuestro modelo, la detectabilidad restante no contabilizada será más consistente entre los sitios. Por lo tanto, la tasa de avistamiento será proporcional a la ocupación, aunque menor en una cantidad consistente. Para algunas especies fácilmente detectables, la diferencia entre la tasa de presencia y la tasa de ocupación real será pequeña, y estas tasas de avistamiento se aproximarán a las tasas de ocupación reales de la especie. Para las especies más difíciles de detectar, la tasa de avistamiento puede ser sustancialmente menor que la tasa de ocupación.\nLos Random forests son un método de aprendizaje automático de propósito general aplicable a una amplia gama de problemas de clasificación y regresión, Incluyendo la tarea en cuestión: clasificar la detección y no detección de una especie en las listas de eBird. Además de tener un buen rendimiento predictivo, los random forests son relativamente fáciles de usar y cuentan con varias implementaciones eficientes en R. Antes de entrenar un modelo de random forest, demostraremos cómo abordar los problemas de desequilibrio de clases y sesgo espacial utilizaremos un submuestreo espacial en una cuadrícula regular. Tras entrenar el modelo, evaluaremos su rendimiento con un subconjunto de datos reservado para pruebas y lo calibraremos para garantizar la precisión de las predicciones. Finalmente, predeciremos las tasas de encuentro en toda el área de estudio y generaremos mapas con estas predicciones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "ebirdst.html",
    "href": "ebirdst.html",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "",
    "text": "4.1 Data access\nEl proyecto Estados y Tendencias utiliza modelos de machine learning de ciclo anual completo que combinan datos de eBird con datos de teledetección y toman en cuenta las variaciones en el comportamiento y el esfuerzo de los observadores para producir estimaciones semanales de alta resolución de los límites de distribución, la tasa de ocurrencia y la abundancia relativa de las especies de aves. La última versión, con estimaciones hasta el año 2023, incluye resultados para 2981 especies en todo el mundo, de las cuales 471 han sido registradas en Chile. Las visualizaciones interactivas de estas especies están disponibles en el sitio web de eBird Estados y Tendencias y los productos de datos de Estados y Tendencias de eBird están disponibles a través del paquete de R ebirdst.\nEn este modulo nos familiarizaremos con los productos de datos de Estados y Tendencias de eBird y el paquete R ebirdst, desarrollado específicamente para trabajar con estos datos. Presentaremos la gama de datos disponibles y, a continuación, les mostraremos cómo descargar estos productos de datos y cargarlos en R para su posterior análisis. Luego, trabajaremos con una serie de ejemplos de aplicaciones prácticas. Comencemos cargando los paquetes que utilizaremos a lo largo de este taller.\nEl acceso a los productos de Estados y Tendencias de eBird se obtiene mediante un formulario de solicitud de acceso disponible en: https://ebird.org/st/request. Las condiciones de uso se han diseñado para ser bastante permisivas en muchos casos, especialmente en lo que respecta al uso académico y de investigación. Después de leer las Condiciones de uso de los productos de estado y tendencias de eBird y rellenar el Formulario de solicitud de acceso, se le proporcionará una clave de acceso alfanumérica. Para almacenar la clave de acceso de modo que R y el paquete ebirdst puedan acceder a ella, ejecute lo siguiente (sustituyendo \"XXXXXXXXX\" por su clave real):\nset_ebirdst_access_key(\"XXXXXXXXX\", overwrite = TRUE)\nA continuación, reinicie R inmediatamente. Esto guardará la clave de acceso como variable de entorno EBIRDST_KEY en su archivo .Renviron, de modo que pueda acceder a ella desde su sesión de R.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html#sec-intro-tidyverse",
    "href": "intror.html#sec-intro-tidyverse",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "1.2 Tidyverse",
    "text": "1.2 Tidyverse\nEn el curso utilizaremos paquetes del Tidyverse, una colección de paquetes de R diseñados para el análisis de datos. Paquetes como ggplot2 (para visualización de datos) y dplyr (para manipulación de datos), son algunos de los más conocidos de la colección.\nUno de los elementos del Tidyverse que utilizaremos bastante a lo largo de este curso es el operador pipe %&gt;% (|&gt;). El pipe toma la expresión a su izquierda y la “canaliza” hacia el primer argumento de la expresión a su derecha.\n\nlibrary(dplyr)\n\n# sin pipe\nmean(1:10)\n#&gt; [1] 5.5\n\n# con pipe\n1:10 %&gt;% mean()\n#&gt; [1] 5.5\n1:10 |&gt; mean()\n#&gt; [1] 5.5\n\nEl pipe hace que el código sea mucho más legible al evitar llamadas de funciones anidadas, reducir la necesidad de variables intermedias y permitir que las operaciones secuenciales se lean de izquierda a derecha. Por ejemplo, para agregar una nueva variable a una base de datos y luego resumir agrupando por otra variable, podemos hacer cualquiera de las siguientes opciones:\n\n## OPCION 1 ##\n# Variables intermedias\nmtcars_kg &lt;- mutate(mtcars, wt_kg = 454 * wt)\nmtcars_grouped &lt;- group_by(mtcars_kg, cyl)\nsummarize(mtcars_grouped, wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n# Funciones anidadas\nsummarize(\n  group_by(\n    mutate(mtcars, wt_kg = 454 * wt),\n    cyl\n  ),\n  wt_kg = mean(wt_kg)\n)\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n## OPCION 2 ##\n# uso de pipes\nmtcars %&gt;% \n  mutate(wt_kg = 454 * wt) %&gt;% \n  group_by(cyl) %&gt;% \n  summarize(wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\nComo se ve en el ejercicio, el uso de pipes reduce el código evitando la creación de variables intermedias.\n\n\n\n\n\n\nEjercicio\n\n\n\nReescribe el siguiente código usando pipes:\n\nset.seed(1)\nround(log(runif(10, min = 0.5)), 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6\n\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\n\nset.seed(1)\nrunif(10, min = 0.5) %&gt;% \n  log() %&gt;% \n  round(digits = 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6\n\nrunif(10, min = 0.5) |&gt; \n  log() |&gt; \n  round(digits = 1)\n#&gt;  [1] -0.5 -0.5 -0.2 -0.4 -0.1 -0.3 -0.2  0.0 -0.4 -0.1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "index.html#sec-intro-config",
    "href": "index.html#sec-intro-config",
    "title": "Curso ROC: Análisis de datos de eBird utilizando R",
    "section": "Configuración",
    "text": "Configuración\nEste cruso está pensado para ser interactivo. Todos los ejemplos están escritos en el lenguaje de programación R, y el instructor los irá resolviendo en tiempo real. Recomendamos seguir la clase seguirlo escribiendo el mismo código en su computador. Para evitar retrasos innecesarios, siga estas instrucciones de configuración antes del curso:\n\nCrea una cuenta de eBird si aún no tiene una y solicita acceso a los datos crudos de eBird y a los productos de Estados y Tendencias:\n\nSolicita acceso al eBird Basic Dataset (EBD).\nSolicita acceso a los productos de Estados y Tendencias\n\nDescarga e instala la última versión de R. Se requiere la versión 4.0.0 o posterior de R para poder seguir este curso\nDescarga e instala la última versión de RStudio. RStudio no es necesario para este taller; sin embargo, los instructores lo utilizarán y es posible que te resulte más fácil seguir el curso si trabajas en el mismo entorno.\nLos ejercicios de este curso utilizan varios paquetes de R. Para instalar todos los paquetes necesarios, ejecute el siguiente código\n\n\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nremotes::install_github(\"ebird/ebird-best-practices\")\n\n\nAsegúrate de que todos los paquetes estén actualizados a sus versiones más recientes haciendo clic en el botón Actualizar de la pestaña Paquetes en RStudio.\nDescarga el paquete de datos que utilizaremos en este curso.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#sec-tutorial-config",
    "href": "index.html#sec-tutorial-config",
    "title": "Curso ROC: Análisis de datos de eBird utilizando R",
    "section": "Tutorial de configuración",
    "text": "Tutorial de configuración\nHemos creado un video introductorio explicando los pasos a seguir para la descarga e instalación de todos los requerimientos del curso.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "intror.html#software",
    "href": "intror.html#software",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "1.3 Software",
    "text": "1.3 Software\nLos ejemplos del curso usan el lenguaje R (R Core Team 2023). Si no tienes R instalado, descárgalo. Si ya lo tienes, puede que esté desactualizado: conviene actualizarlo a la versión más reciente. R se actualiza con frecuencia, y es importante contar con la versión más reciente para evitar problemas al instalar paquetes.\nRecomendamos usar RStudio si eres usuario de R. RStudio no es obligatorio para seguir esta guía, pero mejora muchísimo la experiencia. Si no lo tienes, descárgalo; si ya lo tienes, actualízalo, pues regularmente aparecen versiones nuevas con características útiles.\nDebido al tamaño grande del conjunto de datos de eBird, trabajar con él requiere la utilidad de línea de comandos Unix AWK. No necesitas usar AWK directamente, porque el paquete R auk se encarga de hacerlo, pero sí debes tener AWK instalado en tu computador:\n\nEn Linux y macOS ya suele venir AWK instalado.\nEn Windows, necesitarás instalar Cygwin, un software libre que permite usar herramientas Unix bajo Windows. Asegúrate de instalarlo en la ubicación predeterminada (por ejemplo, C:/cygwin/bin/gawk.exe o C:/cygwin64/bin/gawk.exe) para que todo funcione correctamente. Si tienes dudas con esto, puedes volver al video introductorio en el se muestra este paso.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html#datos-gis-cartográficos",
    "href": "intror.html#datos-gis-cartográficos",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "1.4 Datos GIS / cartográficos",
    "text": "1.4 Datos GIS / cartográficos\nPara dar contexto espacial a los análisis que realicemos, necesitaremos datos GIS (bordes políticos, límites, etc.). Natural Earth es una de las mejores fuentes de datos GIS vectoriales y raster integrados de calidad profesional. Con el paquete rnaturalearth de R pueden acceder a esos datos fácilmente desde R.\nEl siguiente código descarga datos cartográficos de Natural Earth y crea un archivo GeoPackage con diferentes capas geográficas de Chile.\n\nlibrary(rnaturalearth)\nlibrary(sf) \nlibrary(dplyr)\n\n# Definir la ruta y nombre del archivo GeoPackage donde guardaremos todo\ngpkg_file &lt;- \"data/gis-data-chile.gpkg\"\n\n# Crear el directorio 'data/' si no existe\ndir.create(dirname(gpkg_file), showWarnings = FALSE, recursive = TRUE)\n\n# Descargar y procesar territorio de Chile\n  #Descargar datos de todos los países del mundo\nchile_land &lt;- ne_download(\n  scale = 10, # scale = 10 (también existe 50 y 110)\n  category = \"cultural\",\n  type = \"admin_0_countries_lakes\", \n  returnclass = \"sf\"\n) |&gt;\n  # Filtrar solo Chile\n  filter(ADMIN == \"Chile\") |&gt;\n  # Ajustar precisión para evitar problemas geométricos\n  st_set_precision(1e6) |&gt;\n  # Unir todas las geometrías en una sola (incluyendo islas)\n  st_union()\n#&gt; Reading layer `ne_10m_admin_0_countries_lakes' from data source \n#&gt;   `/private/var/folders/hl/htdls_lx1rlfx23h9wwv62xm0000gn/T/Rtmp7jdwHl/ne_10m_admin_0_countries_lakes.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 258 features and 168 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.6\n#&gt; Geodetic CRS:  WGS 84\n\n# Descargar regiones de Chile (divisiones administrativas)\n  # Descargar divisiones administrativas de nivel 1 (regiones/estados)\nchile_regions &lt;- ne_download(\n  scale = 10,\n  category = \"cultural\", \n  type = \"admin_1_states_provinces\",\n  returnclass = \"sf\"\n) |&gt;\n  filter(iso_a2 == \"CL\") |&gt;\n  # Seleccionar columnas relevantes\n  select(\n    region = name             # Nombre de la región\n  )\n#&gt; Reading layer `ne_10m_admin_1_states_provinces' from data source \n#&gt;   `/private/var/folders/hl/htdls_lx1rlfx23h9wwv62xm0000gn/T/Rtmp7jdwHl/ne_10m_admin_1_states_provinces.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 4596 features and 121 fields\n#&gt; Geometry type: MULTIPOLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -180 ymin: -90 xmax: 180 ymax: 83.6\n#&gt; Geodetic CRS:  WGS 84\n\n# Descargar líneas fronterizas de Chile\n  # Primero obtenemos TODAS las líneas fronterizas del mundo\nall_country_lines &lt;- ne_download(\n  scale = 10, \n  category = \"cultural\",\n  type = \"admin_0_boundary_lines_land\",\n  returnclass = \"sf\"\n)\n#&gt; Reading layer `ne_10m_admin_0_boundary_lines_land' from data source \n#&gt;   `/private/var/folders/hl/htdls_lx1rlfx23h9wwv62xm0000gn/T/Rtmp7jdwHl/ne_10m_admin_0_boundary_lines_land.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 515 features and 54 fields\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -141 ymin: -55.1 xmax: 146 ymax: 70.1\n#&gt; Geodetic CRS:  WGS 84\n\n# Identificamos qué líneas intersectan con el territorio de Chile\nlines_touching_chile &lt;- st_intersects(\n  all_country_lines, \n  chile_land, \n  sparse = FALSE\n)[,1]  \n\n# Filtrar solo las líneas que tocan Chile (fronteras con Argentina, Perú, Bolivia)\nchile_country_lines &lt;- all_country_lines[lines_touching_chile,] |&gt;\n  st_geometry() \n\n# Descargar líneas entre regiones\n  # Descargar líneas de divisiones administrativas nivel 1\nall_region_lines &lt;- ne_download(\n  scale = 10,\n  category = \"cultural\",\n  type = \"admin_1_states_provinces_lines\",\n  returnclass = \"sf\"\n)\n#&gt; Reading layer `ne_10m_admin_1_states_provinces_lines' from data source \n#&gt;   `/private/var/folders/hl/htdls_lx1rlfx23h9wwv62xm0000gn/T/Rtmp7jdwHl/ne_10m_admin_1_states_provinces_lines.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 10179 features and 57 fields (with 1 geometry empty)\n#&gt; Geometry type: MULTILINESTRING\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -178 ymin: -49.3 xmax: 178 ymax: 81.1\n#&gt; Geodetic CRS:  WGS 84\n\n  # Filtrar líneas que intersectan con Chile\nlines_in_chile &lt;- st_intersects(\n  all_region_lines,\n  chile_land,\n  sparse = FALSE\n)[,1] \n\nchile_region_lines &lt;- all_region_lines[lines_in_chile,] |&gt;\n  st_geometry()\n\n# Guardar todas las capas en el GeoPackage\nwrite_sf(chile_land, gpkg_file, \"chile_territorio\")\nwrite_sf(chile_regions, gpkg_file, \"chile_regiones\")\nwrite_sf(chile_country_lines, gpkg_file, \"chile_fronteras\")\nwrite_sf(chile_region_lines, gpkg_file, \"chile_limites_regionales\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html#acceso-a-datos-de-ebird",
    "href": "intror.html#acceso-a-datos-de-ebird",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "2.1 Acceso a datos de eBird",
    "text": "2.1 Acceso a datos de eBird\nEl acceso a la base de datos de eBird se proporciona a través del eBird Basic Dataset (EBD) como archivos de texto separados por tabulaciones. Para acceder al EBD, comienza creando una cuenta de eBird e iniciando sesión. Luego visita la página de Acceso a Datos de eBird y completa el formulario de solicitud de datos. El acceso a los datos de eBird es gratuito para la mayoría de los usos; sin embargo, necesitarás solicitar acceso para poder descargar el EBD. Completar el formulario de solicitud de acceso permite a eBird hacer seguimiento del número de personas que usan los datos y obtener información sobre las aplicaciones para las cuales se utilizan los datos.\nUna vez que se te haya otorgado acceso al EBD, podrás descargar ya sea el conjunto de datos completo de eBird o subconjuntos para especies, regiones o períodos de tiempo específicos. Esto se lo veremos con más detalle en la última sección.\nLos datos de eBird se organizan en checklist, estos listados representan observaciones de un único evento de observación de aves, como una caminata de 1 km por un parque o 15 minutos observando comederos en tu jardín. Cada listado incluye las especies observadas, el número de individuos vistos de cada especie, la ubicación y hora de las observaciones, información sobre el tipo de muestreo realizado, y medidas del esfuerzo invertido durante la recolección de datos. La siguiente imagen muestra una lista típica de eBird tal como se ve en el sitio web de eBird:\n\n\n\n\n\nHay tres características clave que distinguen a eBird de muchos otros proyectos de ciencia ciudadana y que facilitan análisis ecológicos robustos. Primero, los observadores especifican el protocolo de muestreo utilizado, ya sea en tránsito, estacionario, incidental (es decir, si las observaciones se recolectaron cuando observar aves no era la actividad principal). Segundo, además de la información usual sobre cuándo y dónde se hicieron las observaciones, los observadores registran información de esfuerzo especificando cuánto tiempo buscaron, qué distancia recorrieron y el número total de observadores en su grupo. Recolectar estos datos facilita análisis robustos al permitir a los investigadores controlar la variación en el proceso de observación (La Sorte et al. 2018; Kelling et al. 2018). Finalmente, se pide a los observadores que indiquen si están reportando todas las aves que pudieron detectar e identificar. Las listas con todas las especies reportadas, conocidas como listas completas, permiten a los investigadores inferir conteos de cero individuos para las especies que no fueron reportadas. Si las listas no son completas, no es posible determinar si la ausencia de una especie en la lista fue una no detección o el resultado de que el participante no registró la especie.\nLos proyectos de ciencia ciudadana ocurren en un espectro, desde aquellos con estructuras de muestreo predefinidas que se asemejan más a diseños tradicionales de muestreo (como el Breeding Bird Survey en Estados Unidos), hasta aquellos que no están estructurados y recolectan observaciones de manera oportunista (como iNaturalist). Nos referimos a eBird como un proyecto semi-estructurado (Kelling et al. 2018), con protocolos flexibles y fáciles de seguir que atraen a muchos participantes, pero que también recolectan datos sobre el proceso de observación y permiten inferir no detecciones en listas completas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html#desafíos-asociados-con-datos-de-ebird",
    "href": "intror.html#desafíos-asociados-con-datos-de-ebird",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "2.2 Desafíos asociados con datos de eBird",
    "text": "2.2 Desafíos asociados con datos de eBird\nA pesar de las fortalezas de los datos de eBird, las observaciones de especies recolectadas a través de proyectos de ciencia ciudadana presentan una serie de desafíos que no se encuentran en datos científicos convencionales. Los siguientes son algunos de los principales desafíos asociados con estos datos; desafíos que serán abordados a lo largo de esta guía:\n\nSesgo taxonómico: los participantes a menudo tienen preferencias por ciertas especies, lo que puede llevar a un registro preferencial de algunas especies sobre otras (Greenwood 2007; Tulloch and Szabo 2012). Restringir los análisis a listas completas mitiga en gran medida este problema.\nSesgo espacial: la mayoría de los participantes en proyectos de ciencia ciudadana muestrean cerca de sus hogares (Luck et al. 2004), en áreas de fácil acceso como bordes de carreteras (Kadmon, Farber, and Danin 2004), o en áreas y hábitats de alta biodiversidad conocida (Prendergast et al. 1993). Un método simple para reducir el sesgo espacial es crear una grilla sobre la región de interés y muestrear un número determinado de listas desde cada celda de la grilla.\nSesgo temporal: los participantes muestrean preferentemente cuando están disponibles, como los fines de semana (Courter et al. 2013), y en épocas del año cuando esperan observar más aves; notablemente, en Estados Unidos hay un gran aumento en envíos de eBird durante la migración de primavera (Sullivan et al. 2014). Además, eBird ha aumentado constantemente en popularidad con el tiempo, lo que lleva a un fuerte sesgo hacia más datos en años recientes. Para abordar el sesgo de fin de semana, recomendamos usar una escala temporal de una semana o varias semanas para la mayoría de los análisis. Los sesgos temporales a escalas más largas pueden abordarse submuestreando los datos para producir una distribución temporal más uniforme.\nDesbalance de clases: las especies de aves que son raras o difíciles de detectar pueden tener datos con alto desbalance de clases, con muchas más listas con no detecciones que con detecciones. Para estas especies, un modelo de distribución que predice que la especie está ausente en todas partes tendrá alta precisión, pero ningún valor ecológico. Seguiremos los métodos para abordar el desbalance de clases propuestos por Robinson et al. (2018), muestreando los datos para aumentar artificialmente la prevalencia de detecciones antes del modelado.\nPrecisión espacial: la ubicación espacial de una lista de eBird se proporciona como un único punto latitud-longitud; sin embargo, esto puede no ser preciso por dos razones principales. Primero, para listas en tránsito, esta ubicación representa solo un punto en el recorrido. Segundo, las listas de eBird a menudo se asignan a un hotspot (una ubicación común para todos los observadores que visitan un sitio popular) en lugar de su ubicación verdadera. Por estas razones, no es apropiado alinear las ubicaciones de eBird con variables de hábitat muy precisas, y recomendamos resumir variables dentro de un vecindario alrededor de la ubicación de la lista.\nVariación en detectabilidad/esfuerzo: la detectabilidad describe la probabilidad de que una especie este presente en un área y sea detectada e identificada. La detectabilidad varía según la estación, hábitat y especie (Johnston et al. 2014, 2018). Además, los datos de eBird se recolectan con alta variación en esfuerzo, hora del día, número de observadores y condiciones externas como el clima, todo lo cual puede afectar la detectabilidad de las especies (Ellis and Taylor 2018; Oliveira et al. 2018). Por lo tanto, la detectabilidad es particularmente importante de considerar al comparar entre estaciones, hábitats o especies. Dado que eBird usa un protocolo semi-estructurado que recolecta datos sobre el proceso de observación, podremos controlar una mayor proporción de esta variación en nuestros análisis.\n\nEl resto de esta guía demostrará cómo abordar estos desafíos usando datos reales de eBird para producir estimaciones confiables de distribuciones de especies. En general, tomaremos un enfoque de dos frentes para lidiar con datos no estructurados y maximizar el valor de los datos de ciencia ciudadana: imponer más estructura en los datos mediante filtrado e incluir variables predictoras que describan el proceso de observación en nuestros modelos para controlar la variación restante.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "intror.html#descarga-de-datos",
    "href": "intror.html#descarga-de-datos",
    "title": "1  Introducción al entorno R en el contexto de eBird",
    "section": "2.2 Descarga de datos",
    "text": "2.2 Descarga de datos\nLos datos de eBird se distribuyen típicamente en dos partes: datos de observación y datos de lista. En el conjunto de datos de observación, cada fila corresponde al avistamiento de una única especie en una lista, incluyendo el conteo y cualquier otra información a nivel de especie (por ejemplo, edad, sexo, comentarios sobre la especie, etc.). En el conjunto de datos de lista, cada fila corresponde a una lista, incluyendo la fecha, hora, ubicación, esfuerzo (por ejemplo, distancia recorrida, tiempo invertido, etc.) y cualquier información adicional a nivel de lista (por ejemplo, si es una lista completa o no). Estos dos conjuntos de datos pueden unirse usando un identificador único de lista (a veces referido como identificador de evento de muestreo).\nLos datos de observación y lista se publican como archivos de texto separados por tabulaciones, referidos como el eBird Basic Dataset (EBD) y el Sampling Event Data (SED), respectivamente. Estos archivos se publican mensualmente y contienen todos los avistamientos de aves validados en la base de datos de eBird al momento de la publicación. Ambos conjuntos de datos pueden descargarse en su totalidad, o de manera más práctica, se puede solicitar un subconjunto para una especie, región o período de tiempo determinados a través del formulario de Descarga Personalizada (Custom Download). Recomendamos enfáticamente no intentar descargar el EBD completo, ya que supera los 100GB. En esta sección demostraremos un flujo de trabajo usando el enfoque de Descarga Personalizada.\nComenzaremos descargando los datos de observación (EBD) y de lista (SED) de eBird correspondientes visitando la página de descarga del eBird Basic Dataset y completando el formulario de Descarga Personalizada. Asegúrate de marcar la casilla “Include sampling event data”, que incluirá el SED en la descarga de datos además del EBD.\n\n\n\n\n\nUna vez que los datos estén listos, recibirás un correo electrónico con un enlace de descarga. Los datos descargados estarán en formato comprimido .zip y deberán descomprimirse. El directorio resultante contendrá dos archivos de texto: uno para el EBD (por ejemplo, ebd_CL-LL_smp_relAug-2025.txt) que contiene todas las observaciones del país y uno para el SED (por ejemplo, ebd_CL-LL_smp_relAug-2025_sampling.txt) que contiene todas las listas de la región de Los Lagos. El componente relAug-2025 del nombre de los archivos describe qué versión del EBD es este conjunto de datos; en este caso, es la versión de agosto de este año.\nDado que el EBD se actualiza mensualmente, probablemente recibirás una versión diferente de los datos que la versión de agosto de 2025 usada a lo largo del resto de esta lección. Siempre que actualices los nombres de los archivos descargados en consecuencia en tus códigos, la diferencia en versiones no será un problema. Sin embargo, si quieres descargar y usar exactamente los mismos archivos usados en esta lección, puedes descargar el archivo zip del EBD correspondiente.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción al entorno R en el contexto de eBird</span>"
    ]
  },
  {
    "objectID": "ebird.html",
    "href": "ebird.html",
    "title": "2  Best Practices for using eBird Data",
    "section": "",
    "text": "2.1 Desafíos asociados con datos de eBird\nEn este capítulo, destacaremos algunos de los desafíos asociados con el uso de datos de eBird. Luego mostraremos cómo importar los datos en R, aplicar filtros y usar listas completas para producir datos de detección/no detección adecuados para modelar la distribución y abundancia de especies. Finalmente, realizaremos algunos pasos de pre-procesamiento necesarios para asegurar el análisis apropiado de los datos.\nUsamos los términos detección y no detección en lugar de los términos más comunes presencia y ausencia a lo largo de esta guía para reflejar el hecho de que un conteo inferido de cero no necesariamente significa que una especie está ausente, solo que no fue detectada en la lista en cuestión.\nA pesar de las fortalezas de los datos de eBird, las observaciones de especies recolectadas a través de proyectos de ciencia ciudadana presentan una serie de desafíos que no se encuentran en datos científicos convencionales. Alguno de los siguientes desafíos asociados con estos datos que serán abordados a lo largo de este curso son:\nEl resto de esta guía demostrará cómo abordar estos desafíos usando datos reales de eBird para producir estimaciones confiables de distribuciones de especies. En general, tomaremos un enfoque de dos frentes para lidiar con datos no estructurados y maximizar el valor de los datos de ciencia ciudadana: imponer más estructura en los datos mediante filtrado e incluir variables predictoras que describan el proceso de observación en nuestros modelos para controlar la variación restante.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebird.html#desafíos-asociados-con-datos-de-ebird",
    "href": "ebird.html#desafíos-asociados-con-datos-de-ebird",
    "title": "2  Best Practices for using eBird Data",
    "section": "",
    "text": "Sesgo taxonómico: los participantes a menudo tienen preferencias por ciertas especies, lo que puede llevar a un registro preferencial de algunas especies sobre otras (Greenwood 2007; Tulloch and Szabo 2012). Restringir los análisis a listas completas mitiga en gran medida este problema.\nSesgo espacial: la mayoría de los participantes en proyectos de ciencia ciudadana muestrean cerca de sus hogares (Luck et al. 2004), en áreas de fácil acceso como bordes de carreteras (Kadmon, Farber, and Danin 2004), o en áreas y hábitats de alta biodiversidad conocida (Prendergast et al. 1993). Un método simple para reducir el sesgo espacial es crear una grilla sobre la región de interés y muestrear un número determinado de listas desde cada celda de la grilla.\nSesgo temporal: los participantes muestrean preferentemente cuando están disponibles, como los fines de semana (Courter et al. 2013), y en épocas del año cuando esperan observar más aves; notablemente, en Estados Unidos hay un gran aumento en envíos de eBird durante la migración de primavera (Sullivan et al. 2014). Además, eBird ha aumentado constantemente en popularidad con el tiempo, lo que lleva a un fuerte sesgo hacia más datos en años recientes. Para abordar el sesgo de fin de semana, recomendamos usar una escala temporal de una semana o varias semanas para la mayoría de los análisis. Los sesgos temporales a escalas más largas pueden abordarse submuestreando los datos para producir una distribución temporal más uniforme.\nDesbalance de clases: las especies de aves que son raras o difíciles de detectar pueden tener datos con alto desbalance de clases, con muchas más listas con no detecciones que con detecciones. Para estas especies, un modelo de distribución que predice que la especie está ausente en todas partes tendrá alta precisión, pero ningún valor ecológico. Seguiremos los métodos para abordar el desbalance de clases propuestos por Robinson et al. (2018), muestreando los datos para aumentar artificialmente la prevalencia de detecciones antes del modelado.\nPrecisión espacial: la ubicación espacial de una lista de eBird se proporciona como un único punto latitud-longitud; sin embargo, esto puede no ser preciso por dos razones principales. Primero, para listas en tránsito, esta ubicación representa solo un punto en el recorrido. Segundo, las listas de eBird a menudo se asignan a un hotspot (una ubicación común para todos los observadores que visitan un sitio popular) en lugar de su ubicación verdadera. Por estas razones, no es apropiado alinear las ubicaciones de eBird con variables de hábitat muy precisas, y recomendamos resumir variables dentro de un vecindario alrededor de la ubicación de la lista.\nVariación en detectabilidad/esfuerzo: la detectabilidad describe la probabilidad de que una especie este presente en un área y sea detectada e identificada. La detectabilidad varía según la estación, hábitat y especie (Johnston et al. 2014, 2018). Además, los datos de eBird se recolectan con alta variación en esfuerzo, hora del día, número de observadores y condiciones externas como el clima, todo lo cual puede afectar la detectabilidad de las especies (Ellis and Taylor 2018; Oliveira et al. 2018). Por lo tanto, la detectabilidad es particularmente importante de considerar al comparar entre estaciones, hábitats o especies. Dado que eBird usa un protocolo semi-estructurado que recolecta datos sobre el proceso de observación, podremos controlar una mayor proporción de esta variación en nuestros análisis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebird.html#código-para-extraer-datos-del-ebird-basic-dataset-ebd-para-sitios-prioritarios",
    "href": "ebird.html#código-para-extraer-datos-del-ebird-basic-dataset-ebd-para-sitios-prioritarios",
    "title": "2  Best Practices for using eBird Data",
    "section": "2.6 Código para extraer datos del eBird Basic Dataset (EBD) para sitios prioritarios",
    "text": "2.6 Código para extraer datos del eBird Basic Dataset (EBD) para sitios prioritarios\nEste código nos permitirá extraer datos del EBD y resumir la información registrada para un área geográfica de interés utilizando un polígono.\nPara correr este código se requieren de tres archivos.\n\nEl eBird Basic Dasaset (EBD) de la región de Los Lagos (ebd_CL-LL_smp_relAug-2025.txt).\nEl polígono del área de interés, que en este caso es un área que cubre parte del río Petrohue, Ralún, Chile (ralun.kml). El paquete “sf” utilizado acepta archivos en formato .shp o .kml\nOpcional Un archivo con nombres locales y categorías de conservación de las especies. En este caso, un archivo con el listado de aves de Chile y su categoría de conservación (lista aves de chile.csv).\n\nPartimos cargando los paquetes que necesitaremos en esta parte del curso\n\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(sf)\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(readr)\n\nLuego, importamos los archivos que necesitaremos para trabajar. El set de datos con los que trabajaremos (EBD), en este caso son todos los registros que existen en la región de Los Lagos, el polígono del área de interés y una planilla que contiene información sobre las aves, como sus nombre comunes en español, su estatus en el país y sus categorías de conservación.\n\n# importamos los datos de observaciones\nf_ebd &lt;- \"data/ebd_CL-LL_smp_relAug-2025.txt\" \nobs &lt;- read_ebd(f_ebd)\n\n# en la columna de conteos convertimos los \"X\" a NA y transformamos el formato a números enteros\nobs$observation_count &lt;- if_else(obs$observation_count == \"X\", NA_character_, \n                                 obs$observation_count) %&gt;% \n  as.integer()\n\n# cargamos el archivo del polígono, puede ser .shp o .kml \npoly &lt;- read_sf(\"data/ralun.kml\") #insertar nombre de archivo propio\n\n# cargamos la planilla con información de las especies, como su categoría de conservacion\ncat &lt;- read.csv2(\"data/lista aves de chile.csv\")\n# seleccionamos las columnas que son de nuestro interés\ncat &lt;- cat %&gt;% select(nombre_cientifico, nombre_comun, clasificacion_IUCN, clasificacion_RCE, clasificacion_RCE, estado)\n\nUna vez cargados los archivos, filtraremos la base de datos de las observaciones de acuerdo a criterios que uno establezca relacionados al esfuerzo de muestreo, como por ejemplo el tipo de observación realizado, la distancia recorrida, la duración del muestreo o la cantidad de observadores.\nPara este ejemplo, filtraremos las listas que presenten distancias recorridas menores a 10 km y menos de seis horas de observación. Además, filtraremos las columnas de nuestro interés y modificaremos las categorías de códigos reproductivos para facilitar la visualización.\n\nobs_fil &lt;- obs %&gt;%\n  filter(protocol_name %in% c(\"Traveling\", \"Stationary\"), # filtramos listas hechas con desplazamiento y estacionarias\n         duration_minutes &lt; 6 * 60, # que tengan una duración menor a 6 horas\n         effort_distance_km &lt; 10 | protocol_name == \"Stationary\") # con distancias recorridas menores a 10 km\n\n# seleccionamos solo las columnas necesarias para reducir tamaño del dataframe\nobs_lim &lt;- obs_fil %&gt;%\n  select(sampling_event_identifier,\n         taxonomic_order,\n         common_name,\n         scientific_name,\n         observation_count,\n         breeding_category,\n         latitude,\n         longitude,\n         observation_date)\n\n# cambiamos la jerarquía de categorias de códigos reproductivos a una jerarquía numérica\nobs_lim &lt;- obs_lim %&gt;%\n  mutate(breeding_category = recode(breeding_category,'C1'=1,'C2'=2,'C3'=3,'C4'=4),\n         breeding_category = as.integer(as.character(breeding_category)))\n\nCon nuestros archivos preparados, trabajaremos ahora en la sección espacial del código. Partiremos transformando el objeto que contiene las observaciones (obs_lim) a un formato shapefile. Dejaremos ambos objetos con los que trabajaremos (ebd_sf y poly) con el mismo crs. Opcionalmente dejamos explicita la opción de incorporar un buffer al polígono , por si quisiéramos considerar también listados que quedasen justo fuera del polígono, por haber terminado o empezado fuera de este. Finalmente identificaremos y filtraremos los listados que caen dentro del polígono del área de interés.\n\n# transformamos el objeto con las observaciones a formato shape file y le asignamos crs\nebd_sf &lt;- obs_lim %&gt;% \n  select(longitude, latitude) %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326)\n\n# transformamos el polígono de nuestra área de interés para tener el mismo crs que el archivo de las observaciones\npoly_ll &lt;- st_transform(poly, crs = st_crs(ebd_sf))\n\n# opcionalmente podemos incluir un buffer alrededor del polígono para incluir datos de listas que pudieran haber empezado o terminado fuera del polígono\npoly_ll_buffer &lt;- st_buffer(poly_ll, dist = 1000) # en este caso agregamos un buffer de 1km\n\n# identificamos los puntos (listas) que caen dentro del polígono\nin_poly &lt;- st_within(ebd_sf, poly_ll_buffer, sparse = FALSE)\n\n# filtramos los datos que caen dentro del polígono\nebd_in_poly &lt;- obs_lim[in_poly[, 1], ]\n\nFinamente, tenemos la base de datos registrados en el área de interés. En esta última parte generaremos una tabla resumen que presente las observaciones del área de manera consisa.\n\n# realizamos una lista de especies registradas, con nombre común, científico y orden taxonómico\nespecie &lt;-   ebd_in_poly %&gt;% \n  distinct(common_name,scientific_name,taxonomic_order) %&gt;% \n  arrange(common_name) %&gt;%\n  distinct(common_name, .keep_all = TRUE)\n\n# generamos una lista de especies registradas durante el último año y sus máximos para ese año\nregistro_último_año &lt;-  ebd_in_poly %&gt;% \n  filter(year(observation_date) == year(max(observation_date))) %&gt;% \n  group_by(common_name) %&gt;% \n  arrange(desc(observation_count)) %&gt;%  # Ordenar en orden descendente de conteo\n  summarise(conteo_max_último_año = max(observation_count, na.rm=TRUE),checklist.x = first(sampling_event_identifier),\n            conteo_max_último_año = replace(conteo_max_último_año, conteo_max_último_año == -Inf, 0)) %&gt;%\n  mutate(registro_último_año = TRUE)\n#&gt; Warning: There were 4 warnings in `summarise()`.\n#&gt; The first warning was:\n#&gt; ℹ In argument: `conteo_max_último_año = max(observation_count, na.rm = TRUE)`.\n#&gt; ℹ In group 5: `common_name = \"Black-crowned Night Heron\"`.\n#&gt; Caused by warning in `max()`:\n#&gt; ! no non-missing arguments to max; returning -Inf\n#&gt; ℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.\n\n# resumimos el conteo máximo histórico para cada especie registrada en el polígono\nconteo_max_h &lt;- ebd_in_poly %&gt;% \n  group_by(common_name) %&gt;%\n  arrange(desc(observation_count)) %&gt;%\n  slice(1) %&gt;%  # Tomar solo la primera fila (máximo conteo)\n  summarise(conteo_max_h = max(observation_count, na.rm=TRUE),\n            año_max_h = max(year(observation_date)), \n            checklist.y = first(sampling_event_identifier))\n#&gt; Warning: There were 3 warnings in `summarise()`.\n#&gt; The first warning was:\n#&gt; ℹ In argument: `conteo_max_h = max(observation_count, na.rm = TRUE)`.\n#&gt; ℹ In group 8: `common_name = \"Black-chested Buzzard-Eagle\"`.\n#&gt; Caused by warning in `max()`:\n#&gt; ! no non-missing arguments to max; returning -Inf\n#&gt; ℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\n# calculamos un promedio de conteo en los registros de los últimos 5 años para cada especie\nprom_conteo_5_años &lt;- ebd_in_poly %&gt;% \n  filter(year(observation_date) &gt;= (year(max(observation_date)) - 4)) %&gt;% \n  group_by(common_name) %&gt;% \n  summarise(prom_conteos_5_años = round(mean(observation_count, na.rm=TRUE)))\n\n# asignamos el código reproductivo más alto registrado para cada especie en el polígono\ncod_rep &lt;- ebd_in_poly %&gt;% \n  group_by(common_name) %&gt;% \n  summarise(cod_rep = max(breeding_category, na.rm = TRUE),\n            cod_rep = replace(cod_rep, cod_rep == -Inf, 0))\n#&gt; Warning: There were 59 warnings in `summarise()`.\n#&gt; The first warning was:\n#&gt; ℹ In argument: `cod_rep = max(breeding_category, na.rm = TRUE)`.\n#&gt; ℹ In group 1: `common_name = \"Ashy-headed Goose\"`.\n#&gt; Caused by warning in `max()`:\n#&gt; ! no non-missing arguments to max; returning -Inf\n#&gt; ℹ Run `dplyr::last_dplyr_warnings()` to see the 58 remaining warnings.\n\n# creamos la tabla resumen                                                  \ntabla_datos &lt;- left_join(especie,registro_último_año, by = \"common_name\") %&gt;%\n  left_join(.,conteo_max_h, by = \"common_name\") %&gt;%\n  left_join(.,prom_conteo_5_años, by = \"common_name\") %&gt;%\n  left_join(.,cod_rep, by = \"common_name\") %&gt;%\n  left_join(., cat, by = c(\"scientific_name\" = \"nombre_cientifico\")) %&gt;% \n  group_by(common_name) %&gt;%\n  select(\"nombre_comun\",\"common_name\",\"scientific_name\",\"registro_último_año\",\"conteo_max_último_año\",\"checklist.x\",\"conteo_max_h\",\"año_max_h\",\"checklist.y\",\"prom_conteos_5_años\",\"cod_rep\",\"clasificacion_RCE\",\"clasificacion_IUCN\",\"taxonomic_order\",\"estado\")\n\n\n# ordenamos la tabla según orden taxonómico, reemplazamos los NAs y los números infinitos por 0\ntabla_datos &lt;- tabla_datos %&gt;%\n  arrange(taxonomic_order) %&gt;% # ordenamos la tabla de acuerdo al orden taxonómico\n  mutate_all(function(x) ifelse(is.infinite(x), 0, x)) %&gt;% # reemplazamos los numeros infinitos por 0, cuando todos los registros de la especie fueron ingresados como 'X' \n  select(-taxonomic_order)%&gt;% # quitamos la columna de número taxonómico\n  rename(nombre_ingles = common_name, nombre_cientifico = scientific_name) # renombramos las columnas para que tengan el mismo idioma y formato \n\n# remplazamos los NA con 0 en columnas numéricas de la tabla resumen\ntabla_datos &lt;- tabla_datos %&gt;%\n  mutate(conteo_max_último_año = ifelse(is.na(conteo_max_último_año), 0, conteo_max_último_año),\n         prom_conteos_5_años = ifelse(is.na(prom_conteos_5_años), 0, prom_conteos_5_años))\n\n# remplazamos con NA los 0 en las columna de texto\ntabla_datos$registro_último_año &lt;- replace(tabla_datos$registro_último_año, is.na(tabla_datos$registro_último_año),FALSE)\n\n# exportamos la tabla resumen como archivo .csv\nwrite.csv(tabla_datos, \"datos_eBird_ralun.csv\")\n\nComo herramienta adicional, podemos graficar la ubicación de los listados extraidos. esto nos permite revisar la distribución de estos en el área de interés, como también corroborar si el uso del buffer se justifica o si modificamos el tamaño de este.\n\npar(mar = c(0, 0, 0, 0))\nplot(poly %&gt;% st_geometry(), col = \"gray\", border = NA)\nplot(ebd_sf[in_poly[, 1], ], \n     col = \"black\", pch = 19, cex = 0.5, \n     add = TRUE)\nlegend(\"top\", \n       legend = \"Ubicación datos eBird dentro del poligono\",\n       pch = 19,\n       bty = \"n\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Best Practices for using eBird Data</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#conversión-a-formatos-espaciales",
    "href": "ebirdst.html#conversión-a-formatos-espaciales",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "5.1 Conversión a formatos espaciales",
    "text": "5.1 Conversión a formatos espaciales\nLos datos de tendencias de eBird se almacenan en formato tabular, donde cada fila proporciona la estimación de la tendencia para una sola celda 27 km por 27 km. Para cada celda de la grilla, se proporcionan las coordenadas (longitud y latitud) del centro de la celda. Para muchas aplicaciones, un formato explícitamente espacial es más útil y estas coordenadas se pueden utilizar para convertir el formato tabular a un formato vectorial o ráster.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#vector-puntos",
    "href": "ebirdst.html#vector-puntos",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "5.2 Vector (puntos)",
    "text": "5.2 Vector (puntos)\nLos datos de tendencias tabulares se pueden convertir en características vectoriales de puntos para su uso con el paquete sf utilizando la función sf st_as_sf().\n\ntrends_sf &lt;- st_as_sf(trends_golo, \n                      coords = c(\"longitude\", \"latitude\"), \n                      crs = 4326)\nprint(trends_sf)\n#&gt; Simple feature collection with 2389 features and 15 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -75.7 ymin: -55.9 xmax: -58.3 ymax: -26.4\n#&gt; Geodetic CRS:  WGS 84\n#&gt; # A tibble: 2,389 × 16\n#&gt;   species_code season   start_year end_year start_date end_date srd_id    abd\n#&gt; * &lt;chr&gt;        &lt;chr&gt;         &lt;int&gt;    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 chiswa1      breeding       2014     2021 10-25      02-15    728957 0.0173\n#&gt; 2 chiswa1      breeding       2014     2021 10-25      02-15    731962 0.0579\n#&gt; 3 chiswa1      breeding       2014     2021 10-25      02-15    733464 0.194 \n#&gt; 4 chiswa1      breeding       2014     2021 10-25      02-15    733465 0.0161\n#&gt; 5 chiswa1      breeding       2014     2021 10-25      02-15    734967 0.240 \n#&gt; 6 chiswa1      breeding       2014     2021 10-25      02-15    734968 0.280 \n#&gt; # ℹ 2,383 more rows\n#&gt; # ℹ 8 more variables: abd_ppy &lt;dbl&gt;, abd_ppy_lower &lt;dbl&gt;, abd_ppy_upper &lt;dbl&gt;,\n#&gt; #   abd_ppy_nonzero &lt;lgl&gt;, abd_trend &lt;dbl&gt;, abd_trend_lower &lt;dbl&gt;,\n#&gt; #   abd_trend_upper &lt;dbl&gt;, geometry &lt;POINT [°]&gt;",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#vector-círculos-escalados-según-la-abundancia",
    "href": "ebirdst.html#vector-círculos-escalados-según-la-abundancia",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "5.3 Vector (círculos escalados según la abundancia)",
    "text": "5.3 Vector (círculos escalados según la abundancia)\nPara generar mapas similares a los del sitio web eBird Status and Trends, la función ‘vectorize_trends()’ convertirá las tendencias tabulares en círculos espaciales con áreas aproximadamente proporcionales a la abundancia relativa en cada celda de 27 km por 27 km. Para generar círculos que no estén sesgados, es importante proporcionar el sistema de referencia de coordenadas en el que se pretende mapear las tendencias resultantes. Lo ideal es que sea una proyección de área igual y, en el ejemplo anterior, hemos utilizado la proyección Equal Earth centrada en América del Norte.\n\ntrends_circles &lt;- vectorize_trends(trends_golo,\n                                   crs = \"+proj=eqearth +lon_0=-96\")\n\nLuego, asignaremos colores basándonos en la tendencia acumulada (abd_trend) utilizando los mismos intervalos que se utilizan en el sitio web.\n\n# definir la legenda\nmax_trend &lt;- ceiling(max(abs(trends_circles$abd_trend)))\nlegend_breaks &lt;- seq(0, 40, by = 10)\nlegend_breaks[length(legend_breaks)] &lt;- max_trend\nlegend_breaks &lt;- c(-rev(legend_breaks), legend_breaks) |&gt; unique()\nlegend_labels &lt;- c(\"&lt;=-40\", -20, 0, 20, \"&gt;=40\")\nlegend_colors &lt;- ebirdst_palettes(length(legend_breaks) - 1, type = \"trends\")\n\n# asignar colores a los circulos\ntrends_circles &lt;- trends_circles |&gt; \n  mutate(color = cut(abd_trend, legend_breaks, labels = legend_colors) |&gt; \n           as.character())\n\nFinalmente podemos crear un mapa de tendencias para esta especie.\n\n# límites de natural earth\ncountries &lt;- ne_countries(returnclass = \"sf\", continent = \"South America\") |&gt; \n  st_geometry() |&gt; \n  st_transform(st_crs(trends_circles))\nstates &lt;- ne_states(iso_a2 = c(\"CL\", \"AR\", \"UR\", \"BR\")) |&gt; \n  st_geometry() |&gt; \n  st_transform(st_crs(trends_circles))\n\n# asignar la extensión del plot\nplot(st_geometry(trends_circles), border = NA, col = NA)\n# agregar basemap\nplot(countries, col = \"#cfcfcf\", border = \"#888888\", add = TRUE)\n# agregar trends\nplot(st_geometry(trends_circles),\n     col = trends_circles$color, border = NA,\n     axes = FALSE, bty = \"n\", reset = FALSE, add = TRUE)\n# agregar límites\nlines(vect(countries), col = \"#ffffff\", lwd = 3)\nlines(vect(states), col =  \"#ffffff\", lwd = 1.5, xpd = TRUE)\n\n# agregar leyenda con el paquete fields\nlabel_breaks &lt;- seq(0, 1, length.out = length(legend_breaks))\nimage.plot(zlim = c(0, 1), breaks = label_breaks, col = legend_colors,\n           smallplot = c(0.90, 0.93, 0.15, 0.85),\n           legend.only = TRUE,\n           axis.args = list(at = c(0, 0.25, 0.5, 0.75, 1), \n                            labels = legend_labels,\n                            col.axis = \"black\", fg = NA,\n                            cex.axis = 0.7, lwd.ticks = 0,\n                            line = -0.75),\n           legend.args = list(text = \"Tendencia de Abundancia [% cambio]\",\n                              side = 2, line = 0.25))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "ebirdst.html#raster",
    "href": "ebirdst.html#raster",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "5.4 Raster",
    "text": "5.4 Raster\nLas estimaciones de tendencias tabulares se pueden convertir fácilmente a formato raster para su uso con el paquete terra utilizando la función ‘rasterize_trends()’. Cualquiera de las columnas de tendencias se puede seleccionar utilizando el argumento ‘layers’ y convertir en capas en el objeto raster resultante.\n\n# Rasterizar la tendencia porcentual anual con límites de confianza (predeterminado).\nppy_raster &lt;- rasterize_trends(trends_golo)\nprint(ppy_raster)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 124, 111, 3  (nrow, ncol, nlyr)\n#&gt; resolution  : 26665, 26665  (x, y)\n#&gt; extent      : -7055793, -4095949, -6231601, -2925107  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; names       : abd_ppy, abd_ppy_lower, abd_ppy_upper \n#&gt; min values  :  -10.12,        -12.20,         -8.20 \n#&gt; max values  :    7.56,          6.82,          9.32\n\n# Rasterizar la estimación de la tendencia acumulada.\ntrends_raster &lt;- rasterize_trends(trends_golo, layers = \"abd_trend\")\nprint(trends_raster)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 124, 111, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 26665, 26665  (x, y)\n#&gt; extent      : -7055793, -4095949, -6231601, -2925107  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; name        : abd_trend \n#&gt; min value   :     -52.6 \n#&gt; max value   :      66.6\n\nEstos objetos ráster se pueden exportar a archivos GeoTIFF para su uso en un SIG como QGIS o ArcGIS con\n\nwriteRaster(trends_raster, filename = \"ebird-tendencias_golo_2022.tif\", overwrite = TRUE)\n\nA partir de los datos ráster se puede crear un mapa sencillo. Por ejemplo, crearemos un mapa con el porcentaje de cambio anual en la abundancia relativa de la golondrina chilena. Tenga en cuenta que este mapa es ligeramente diferente de los mapas de tendencias que aparecen en el sitio web Status and Trends, que muestran la tendencia acumulada en lugar de la tendencia anual.\n\n# definir los breaks y paletas similares a los del sitio web de estado y tendencias\nbreaks &lt;- seq(-4, 4)\nbreaks[1] &lt;- -Inf\nbreaks[length(breaks)] &lt;- Inf\npal &lt;- ebirdst_palettes(length(breaks) - 1, type = \"trends\")\n\n# hacer un mapa simple\nplot(ppy_raster[[\"abd_ppy\"]], \n     col = pal, breaks =  breaks,\n     main = \"Tendencia reproductiva Golondrina Chilena 2014-2021 [% cambio por año]\",\n     cex.main = 0.75,\n     axes = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "index.html#recursos-adicionales",
    "href": "index.html#recursos-adicionales",
    "title": "Curso ROC: Análisis de datos de eBird utilizando R",
    "section": "Recursos adicionales",
    "text": "Recursos adicionales\nEl equipo del Laboratorio de Ornitología de la Universidad de Cornell ha creado varios recursos (en inglés) explicando más detalladamente los contenidos que hemos cubierto en este curso. Si quieren más información pueden visitar:\n\neBird Best Practices\nViñetas del paquete ebirdst\nViñetas del paquete auk",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "ebirdst.html#recursos-adicionales",
    "href": "ebirdst.html#recursos-adicionales",
    "title": "4  Productos de Estados y Tendencias de eBird",
    "section": "8.1 Recursos adicionales",
    "text": "8.1 Recursos adicionales\nFinalemente pueden consultar los siguientes enlaces para más información sobre el uso de datos de eBird y los paquetes asociados.\n\neBird Best Practices\nViñetas del paquete ebirdst\nViñetas del paquete auk",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Productos de Estados y Tendencias de eBird</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-data",
    "href": "distabund.html#sec-encounter-data",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "4.1 Preparación de datos",
    "text": "4.1 Preparación de datos\nComencemos cargando los paquetes y datos necesarios. Si has completado los capítulos anteriores, ya deberías tener todos los datos necesarios para este capítulo. Sin embargo, es posible que quieras descargar el paquete de datos, y descomprímelo en el directorio de tu proyecto, para asegurarte de que estás trabajando exactamente con los mismos datos que se utilizaron en la creación de esta guía.\n\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(fields)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(lubridate)\nlibrary(mccf1)\nlibrary(ranger)\nlibrary(readr)\nlibrary(scam)\nlibrary(sf)\nlibrary(terra)\nlibrary(tidyr)\n\n# definir número aleatorio semilla para reproducibilidad\nset.seed(1)\n\n# variables ambientales: cobertura de suelo y altitud\nenv_vars &lt;- read_csv(\"data/environmental-variables_checklists_jun_us-ga.csv\")\n\n# datos de eBird rellenados con ceros combinados con datos ambientales\nchecklists &lt;- read_csv(\"data/checklists-zf_woothr_jun_us-ga.csv\") |&gt; \n  inner_join(env_vars, by = \"checklist_id\")\n\n# cuadrícula de predicción\npred_grid &lt;- read_csv(\"data/environmental-variables_prediction-grid_us-ga.csv\")\n# plantilla ráster para la cuadrícula\nr &lt;- rast(\"data/prediction-grid_us-ga.tif\")\n# obtener el sistema de referencia de coordenadas para la cuadrícula de predicción\ncrs &lt;- st_crs(r)\n\n# cargar datos GIS para la creación de mapas\nstudy_region &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_states\") |&gt; \n  filter(state_code == \"US-GA\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_land &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_land\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_country_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_state_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\n\nA continuación, siguiendo el enfoque descrito en el capítulo anterior, realizaremos una ronda de submuestreo espaciotemporal en los datos para reducir el sesgo.\n\n# muestrear de una lista por cada cuadrícula de 3 km x 3 km x 1 semana para cada año.\n# muestreo de detección/no detección de forma independiente\nchecklists_ss &lt;- grid_sample_stratified(checklists,\n                                        obs_column = \"species_observed\",\n                                        sample_by = \"type\")\n\nFinalmente, eliminaremos el 20% de las listas de verificación reservadas para pruebas y seleccionaremos únicamente las columnas que pretendemos utilizar como predictores para entrenar los modelos.\n\nchecklists_train &lt;- checklists_ss |&gt; \n  filter(type == \"train\") |&gt; \n  # seleccioanr solo las columnas a usar en el modelo\n  select(species_observed, observation_count,\n         year, day_of_year, hours_of_day,\n         effort_hours, effort_distance_km, effort_speed_kmph,\n         number_observers, \n         starts_with(\"pland_\"),\n         starts_with(\"ed_\"),\n         starts_with(\"elevation_\"))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-sss",
    "href": "distabund.html#sec-encounter-sss",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.3 Submuestreo espaciotemporal",
    "text": "3.3 Submuestreo espaciotemporal\nTal como discutimos en las clases previas, tres de los desafíos a los que nos enfrentamos al usar datos de eBird, son los sesgos espaciales, sesgos temporales, y el desequilibrio de clases. El sesgo espacial y temporal se refiere a la tendencia de las listas de eBird a distribuirse de forma no aleatoria en el espacio y el tiempo, mientras que el desequilibrio de clases es el fenómeno por el cual hay muchas más no detecciones que detecciones para la mayoría de las especies. Estos tres factores pueden afectar nuestra capacidad para realizar inferencias fiables a partir de estos datos. Afortunadamente, los tres se pueden abordar en gran medida mediante el submuestreo de los datos de eBird antes del modelado. En concreto, definimos una cuadrícula de 3 km × 3 km de igual área en toda la región de estudio y, a continuación, submuestreamos las detecciones y las no detecciones de forma independiente de la cuadrícula para garantizar que no perdamos demasiadas detecciones. Para abordar el sesgo temporal, muestrearemos una lista con detecciones y otra con no detecciones de cada celda de la cuadrícula para cada semana de cada año. Afortunadamente, el paquete ebirdst incluye la función grid_sample_stratified(), diseñada específicamente para realizar este tipo de muestreo en los datos de las listas de eBird.\nAntes de trabajar con datos reales, resulta instructivo observar un ejemplo sencillo para ver cómo funciona este proceso de submuestreo.\n\n# generar puntos aleatorios para una sola semana del año\npts &lt;- data.frame(longitude = runif(500, -0.1, 0.1),\n                  latitude = runif(500, -0.1, 0.1),\n                  day_of_year = sample(1:7, 500, replace = TRUE))\n\n# muestrea una lista por celda de la cuadrícula\n# por defecto el comando grid_sample() usa una cuadrícula a 3km x 3km x 1 semana\npts_ss &lt;- grid_sample(pts)\n\n# generar polígonos para las celdas de la cuadrícula\nggplot(pts) +\n  aes(x = longitude, y = latitude) +\n  geom_point(size = 0.5) +\n  geom_point(data = pts_ss, col = \"red\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nEn el gráfico anterior, el conjunto completo de puntos se muestra en negro y los puntos submuestreados en rojo. Ahora apliquemos el mismo método para submuestrear las listas reales de eBird; sin embargo, ahora submuestreamos temporalmente además de espacialmente, y muestreamos las detecciones y no detecciones por separado. Divideremos los datos en conjuntos de entrenamiento y prueba en una proporción de 80/20. Usando el argumento sample_by de grid_sample_stratified(), podemos muestrear de forma independiente de los conjuntos de entrenamiento y prueba para eliminar el sesgo de ambos.\n\n# muestrea de una lista por cada cuadrícula de 3 km x 3 km x 1 semana para cada año\n# detección/no detección de muestras de forma independiente\nchecklists_ss &lt;- grid_sample_stratified(checklists_env,\n                                        obs_column = \"species_observed\",\n                                        sample_by = \"type\")\n\n\n\n\n\n\n\nEjercicio\n\n\n\nCompara el conjunto completo de listas de eBird con el conjunto de listas restantes después del submuestreo. ¿Cuál fue el cambio en el tamaño de la muestra y cómo afectó el submuestreo a la prevalencia de detecciones en comparación con las no detecciones?\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl submuestreo disminuyó el número total de listas en un factor de aproximadamente 2.3, pero aumentó la prevalencia de detecciones de 10.9% a 14.2%.\n\n# datos originales\nnrow(checklists_env)\n#&gt; [1] 47254\ncount(checklists_env, species_observed) |&gt; \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   species_observed     n percent\n#&gt;   &lt;lgl&gt;            &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1 FALSE            42115   0.891\n#&gt; 2 TRUE              5139   0.109\n\n# después de muestrear\nnrow(checklists_ss)\n#&gt; [1] 20439\ncount(checklists_ss, species_observed) |&gt; \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   species_observed     n percent\n#&gt;   &lt;lgl&gt;            &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1 FALSE            17544   0.858\n#&gt; 2 TRUE              2895   0.142\n\n\n\n\nEste aumento en la frecuencia de detecciones ayudará al modelo de random forest a distinguir dónde se observan las aves; sin embargo, como resultado de este aumento, la tasa de encuentros estimada, basada en estos datos submuestreados, será mayor que la tasa de encuentros real. Al examinar los resultados de los modelos, es importante recordar que modificamos la frecuencia de detecciones en esta etapa. Ahora veamos cómo afecta el submuestreo a la distribución espacial de las observaciones de entrenamiento.\n\n# convertir listas en características espaciales\nall_pts &lt;- checklists_env |&gt;  \n  filter(type == \"train\") |&gt; \n  st_as_sf(coords = c(\"longitude\",\"latitude\"), crs = 4326) |&gt;\n  st_transform(crs = crs) |&gt; \n  select(species_observed)\n\nss_pts &lt;- checklists_ss |&gt;  \n  filter(type == \"train\") |&gt; \n  st_as_sf(coords = c(\"longitude\",\"latitude\"), crs = 4326) |&gt;\n  st_transform(crs = crs) |&gt; \n  select(species_observed)\nboth_pts &lt;- list(before_ss = all_pts, after_ss = ss_pts)\n\n# mapear\np &lt;- par(mfrow = c(1, 2))\nfor (i in seq_along(both_pts)) {\n  par(mar = c(0.25, 0.25, 0.25, 0.25))\n  # configurar área del plot\n  plot(st_geometry(both_pts[[i]]), col = NA)\n  # datos GIS contextuales \n  plot(ne_land, col = \"#dddddd\", border = \"#888888\", lwd = 0.5, add = TRUE)\n  plot(study_region, col = \"#cccccc\", border = NA, add = TRUE)\n  plot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\n  plot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\n  # observaciones de eBird\n  # no observado\n  plot(st_geometry(both_pts[[i]]),\n       pch = 19, cex = 0.1, col = alpha(\"#555555\", 0.25),\n       add = TRUE)\n  # observado\n  plot(filter(both_pts[[i]], species_observed) |&gt; st_geometry(),\n       pch = 19, cex = 0.3, col = alpha(\"#4daf4a\", 0.5),\n       add = TRUE)\n  # leyendas\n  legend(\"bottomright\", bty = \"n\",\n         col = c(\"#555555\", \"#4daf4a\"),\n         legend = c(\"No-detección\", \"Detección\"),\n         pch = 19)\n  box()\n  par(new = TRUE, mar = c(0, 0, 3, 0))\n  if (names(both_pts)[i] == \"before_ss\") {\n    title(\"Registros del Zorzal de Swainson \\nAntes del subsampleo\")\n  } else {\n    title(\"Después del subsampleo\")\n  }\n}\npar(p)\n\n\n\n\n\n\n\n\nPara el Zorzal de Swainson, submuestrear las detecciones y no detecciones de forma independiente es suficiente para abordar el desequilibrio de clases. Puede evaluar el impacto de este desequilibrio analizando las tasas de prevalencia y examinando si los modelos predicen correctamente con los datos de validación. Para especies extremadamente raras, podría ser conveniente conservar todas las detecciones o incluso sobremuestrearlas [@robinsonCorrectingBiasDistribution2018]. Al hacerlo, tenga en cuenta que algunas detecciones de especies no serán independientes, lo que podría provocar un sobreajuste de los datos. En general, al considerar el número de detecciones y la tasa de prevalencia, es importante tener en cuenta tanto la ecología y la detectabilidad de la especie en cuestión como el comportamiento de los observadores hacia ella.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-rf",
    "href": "distabund.html#sec-encounter-rf",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.4 Random forests",
    "text": "3.4 Random forests\nAhora utilizaremos un modelo de random forest para relacionar la detección/no detección del zorzal de Swainson con las variables ambientales calculadas, teniendo en cuenta también la variación en la detectabilidad mediante la inclusión de un conjunto de covariables de esfuerzo. En esta etapa, filtramos los datos para quedarnos únicamente con el conjunto de entrenamiento, reservando el conjunto de prueba para evaluar el rendimiento predictivo posteriormente.\n\nchecklists_train &lt;- checklists_ss |&gt; \n  filter(type == \"train\") |&gt; \n  # seleccionar únicamente las columnas que se utilizarán en el modelo.\n  select(species_observed,\n         year, day_of_year, hours_of_day,\n         effort_hours, effort_distance_km, effort_speed_kmph,\n         number_observers, \n         starts_with(\"pland_\"),\n         starts_with(\"ed_\"),\n         starts_with(\"elevation_\"))\n\nAunque logramos abordar parcialmente el problema del desequilibrio de clases mediante submuestreo, las detecciones aún representan solo 14.2% de las observaciones, y para las especies raras este número será aún menor. La mayoría de los algoritmos de clasificación buscan minimizar la tasa de error general, lo que resulta en un rendimiento predictivo deficiente para las clases raras. Para abordar este problema, utilizaremos un enfoque de random forest balanceado, una modificación del algoritmo tradicional de random forest diseñada para manejar datos desequilibrados. En este enfoque, cada uno de los árboles que componen el random forest se genera utilizando una muestra aleatoria de los datos, elegida de manera que haya el mismo número de detecciones (la clase rara) y no detecciones (la clase común). Para utilizar este enfoque, necesitaremos calcular la proporción de detecciones en el conjunto de datos.\n\ndetection_freq &lt;- mean(checklists_train$species_observed)\n\nExisten varios paquetes para entrenar random forests en R; sin embargo, utilizaremos ranger (https://github.com/imbs-hl/ranger), una implementación muy rápida con todas las características necesarias. Para ajustar un random forest balanceado, usamos el parámetro sample.fraction para indicarle a ranger que genere cada árbol a partir de una muestra aleatoria de los datos con igual número de detecciones y no detecciones. Especificar esto puede resultar complejo, ya que debemos indicarle a ranger la proporción del conjunto de datos total que se muestreará para las no detecciones y las detecciones. Si esta proporción es igual a la proporción de la clase menos frecuente (las detecciones), entonces ranger muestreará de toda la clase menos frecuente, pero de un subconjunto de igual tamaño de las no detecciones más comunes. Usamos replace = TRUE para asegurarnos de que se trate de una muestra bootstrap (https://en.wikipedia.org/wiki/Bootstrapping_(statistics)). También pediremos a ranger que prediga probabilidades, en lugar de simplemente devolver la clase más probable, con probability = TRUE.\n\n# ranger requiere una respuesta factor para hacer clasificación \ner_model &lt;- ranger(formula =  as.factor(species_observed) ~ ., \n                   data = checklists_train,\n                   importance = \"impurity\",\n                   probability = TRUE,\n                   replace = TRUE, \n                   sample.fraction = c(detection_freq, detection_freq))\n\n\n3.4.1 Calibración\nPor diversas razones, las probabilidades predichas por los modelos no siempre coinciden con las frecuencias de detección observadas. Por ejemplo, cabría esperar que, al considerar todos los sitios con una probabilidad de encuentro estimada de 0,2, se registrara la especie en el 20 % de ellos. Sin embargo, estas probabilidades no siempre coinciden. Esto se evidencia claramente en nuestro ejemplo, ya que hemos aumentado deliberadamente la prevalencia de registros de detección en los datos mediante el proceso de submuestreo espaciotemporal. Podemos generar un modelo de calibración para las predicciones, el cual puede ser una herramienta de diagnóstico útil para comprender dichas predicciones y, en algunos casos, puede utilizarse para realinearlas con las observaciones. Para obtener información sobre la calibración en modelos de distribución de especies, consulte Vaughan y Ormerod [-@vaughanContinuingChallengesTesting2005] y para referencias más fundamentales sobre calibración, consulte Platt [-@plattProbabilisticOutputsSupport1999], Murphy [-@murphyNewVectorPartition1973] y Niculescu-Mizil y Caruana [-@niculescu-mizilPredictingGoodProbabilities2005].\nPara entrenar un modelo de calibración para nuestras predicciones, predecimos la tasa de encuentros para cada lista en el conjunto de entrenamiento y luego ajustamos un Modelo Aditivo Generalizado (GAM) binomial con la tasa de encuentros observada real como respuesta y la tasa de encuentros predicha como variable predictora. Mientras que los Modelos Lineales Generalizados (GLM) ajustan una relación lineal entre una respuesta y los predictores, los GAM permiten relaciones no lineales. Si bien los GAM ofrecen cierto grado de flexibilidad, en algunas situaciones pueden sobreajustarse y proporcionar calibraciones poco realistas e inútiles. Tenemos una fuerte expectativa a priori de que los valores reales más altos también se asociarán con tasas de encuentros estimadas más altas. Para mantener la clasificación de las predicciones, es importante respetar este orden y, para ello, utilizaremos un GAM restringido a ser solo creciente. Para ajustar el GAM, utilizaremos el paquete de R scam (https://CRAN.R-project.org/package=scam), de modo que la forma se pueda restringir a ser monótonamente creciente. Tenga en cuenta que las predicciones de ranger están en forma de matriz de probabilidades para cada clase, y lo que queremos es la probabilidad de detecciones, que es la segunda columna de esta matriz.\n\n# tasa de encuentro prevista basada en muestras fuera de la bolsa\ner_pred &lt;- er_model$predictions[, 2]\n# detecciones observadas, convertida de nuevo desde el factor\ndet_obs &lt;- as.integer(checklists_train$species_observed)\n# construir un data frame para entrenar el modelo SCAM\nobs_pred &lt;- data.frame(obs = det_obs, pred = er_pred)\n\n# entrenar modelo de calibración\ncalibration_model &lt;- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n\nPara utilizar el modelo de calibración como herramienta de diagnóstico, agruparemos las tasas de encuentro previstas en intervalos y, a continuación, calcularemos la media de las tasas de encuentro previstas y observadas dentro de cada intervalo. Esto se puede comparar con las predicciones del modelo de calibración.\n\n# Agrupe la tasa de encuentros prevista en intervalos de ancho 0,02\n# luego, calcular las tasas medias de encuentros observadas en cada intervalo.\ner_breaks &lt;- seq(0, 1, by = 0.02)\nmean_er &lt;- obs_pred |&gt;\n  mutate(er_bin = cut(pred, breaks = er_breaks, include.lowest = TRUE)) |&gt;\n  group_by(er_bin) |&gt;\n  summarise(n_checklists = n(),\n            pred = mean(pred), \n            obs = mean(obs),\n            .groups = \"drop\")\n\n# hacer prediccioens del modelo de calibración\ncalibration_curve &lt;- data.frame(pred = er_breaks)\ncal_pred &lt;- predict(calibration_model, calibration_curve, type = \"response\")\ncalibration_curve$calibrated &lt;- cal_pred\n\n# Comparación de las tasas medias de encuentros agrupadas con el modelo de calibración\nggplot(calibration_curve) +\n  aes(x = pred, y = calibrated) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  geom_line(color = \"blue\") +\n  geom_point(data = mean_er, \n             aes(x = pred, y = obs),\n             size = 2, alpha = 0.6,\n             show.legend = FALSE) +\n  labs(x = \"Tasa de encuentro estimada\",\n       y = \"Tasa de encuentro observada\",\n       title = \"Modelo de calibración\") +\n  coord_equal(xlim = c(0, 1), ylim = c(0, 1))\n\n\n\n\n\n\n\n\nEn este gráfico se observa claramente que las tasas de encuentro estimadas son, en su mayoría, mucho mayores que las tasas de encuentro observadas (todos los puntos se sitúan por debajo de la línea discontinua \\(x = y\\)). Por lo tanto, vemos que el modelo no está bien calibrado. Sin embargo, los puntos muestran que la clasificación relativa de las predicciones es, en general, correcta: los sitios con una tasa de encuentro estimada mayor suelen presentar tasas de encuentro observadas mayores.\nDe esto hemos aprendido que el modelo distingue bien los sitios con tasas altas de aquellos con tasas bajas. Para quienes estén familiarizados con el uso del área bajo la curva (AUC) para evaluar la calidad de los modelos de distribución de especies, la gráfica indica que el modelo debería tener un valor AUC alto. Sin embargo, el modelo no estima con precisión las tasas de encuentro.\nSi se requieren tasas de encuentro precisas y el modelo de calibración es robusto (ajuste preciso de los puntos a la línea en la figura anterior), entonces se puede usar para calibrar las estimaciones del modelo de random forest, ajustándolas para que coincidan mejor con las tasas de encuentro observadas. El modelo de random forest calibrado es la combinación del modelo de random forest original seguido del modelo de calibración.\nSi utiliza este modelo para calibrar sus estimaciones, tenga en cuenta que la curva de calibración puede generar probabilidades mayores que 1 y menores que 0, por lo que al aplicar la calibración también debemos restringir las predicciones al intervalo entre 0 y 1. Es posible realizar una regresión logística para la calibración con el fin de eliminar estas predicciones menores que 0 o mayores que 1; sin embargo, hemos comprobado que el GAM con restricción gaussiana es más estable que el GAM con restricción logística.\n\n\n3.4.2 Umbralización\nEl modelo de random forest genera estimaciones continuas de la tasa de encuentro entre 0 y 1. Sin embargo, para muchas aplicaciones, como la evaluación del rendimiento del modelo, será necesario reclasificar esta probabilidad continua a una estimación binaria de presencia/ausencia. Esta reclasificación se realiza estableciendo un umbral por encima del cual se predice la presencia de la especie. El umbral se elige normalmente para maximizar una métrica de rendimiento como el estadístico Kappa o el área bajo la curva ROC. No obstante, para datos con clases desequilibradas, como los de eBird, donde las no detecciones son mucho más frecuentes, muchas de estas métricas pueden inflar el rendimiento al sobreponderar la clase más común [@caoMCCF1CurvePerformance2020]. Para mitigar estos problemas, sugerimos un método de establecimiento de umbrales mediante la curva MCC-F1 curve. Este método grafica el coeficiente de correlación de Matthews (MCC) frente al F1 Score para un rango de umbrales posibles y, posteriormente, selecciona el umbral donde la curva se aproxima más al punto de rendimiento óptimo. El paquete mccf1 de R implementa este método.\n\n# cálculo de mcc y fscore para varios umbrales\nmcc_f1 &lt;- mccf1(\n  # detección/no detección observadas\n  response = obs_pred$obs,\n  # tasa de encuentros predicha por random forest\n  predictor = obs_pred$pred)\n\n# identificar el mejor umbral\nmcc_f1_summary &lt;- summary(mcc_f1)\n#&gt;  mccf1_metric best_threshold\n#&gt;         0.401          0.534\nthreshold &lt;- mcc_f1_summary$best_threshold[1]\n\n\n\n\n\n\n\nTip\n\n\n\nEste umbral define esencialmente el límite de distribución de la especie: se predice que las áreas donde la tasa de encuentros está por debajo del umbral están fuera de la distribución del Zorzal de Swainson y se predice que las áreas donde la tasa de encuentros está por encima del umbral están dentro de su distribución.\n\n\n\n\n3.4.3 Evaluación\nPara evaluar la calidad del modelo de random forest calibrado, validaremos su capacidad para predecir los patrones de detección observados utilizando datos de validación independientes (es decir, el conjunto de datos de prueba del 20 %). Utilizaremos diversas métricas de rendimiento predictivo (MRP) para comparar las predicciones con las observaciones reales. La mayoría de las métricas miden la capacidad del modelo para predecir correctamente la detección/no detección binaria, incluyendo: sensibilidad, especificidad, AUC de precisión-recuperación, F1 score, and MCC. Error cuadrático medio (MSE) aplicado a las estimaciones de la tasa de encuentros calibradas.\nPara garantizar que el sesgo en el conjunto de datos de prueba no afecte a las métricas de rendimiento predictivo, es importante que apliquemos un muestreo de cuadrícula espaciotemporal a los datos de prueba del mismo modo que lo hicimos con los datos de entrenamiento. Ya realizamos este muestreo de cuadrícula anteriormente cuando creamos el data frame checklist_ss, así que utilizamos ese data frame aquí para calcular los PPM..\n\n# obtener el set de prueba retenido fuera del entrenamiento\nchecklists_test &lt;- filter(checklists_ss, type == \"test\") |&gt; \n  mutate(species_observed = as.integer(species_observed))\n\n# predecir para probar los datos usando el modelo random forest\npred_er &lt;- predict(er_model, data = checklists_test, type = \"response\")\n# extraer probabilidad de detección \npred_er &lt;- pred_er$predictions[, 2]\n# convertir predicciones a binario (presencia/ausencia) usando el umbral\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# calibrar\npred_calibrated &lt;- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") |&gt; \n  as.numeric()\n# restringir las probabilidades a 0-1\npred_calibrated[pred_calibrated &lt; 0] &lt;- 0\npred_calibrated[pred_calibrated &gt; 1] &lt;- 1\n# combinar observaciones y estimaciones\nobs_pred_test &lt;- data.frame(id = seq_along(pred_calibrated),\n                            # detección/no detección real\n                            obs = as.integer(checklists_test$species_observed),\n                            # detección binaria/predicción de detección\n                            pred_binary = pred_binary,\n                            # tasa de encuentro calibrada\n                            pred_calibrated = pred_calibrated)\n\n# error cuadrático medio (mse)\nmse &lt;- mean((obs_pred_test$obs - obs_pred_test$pred_calibrated)^2, na.rm = TRUE)\n\n# AUC de recuperación de precisión\nem &lt;- precrec::evalmod(scores = obs_pred_test$pred_binary, \n                       labels = obs_pred_test$obs)\npr_auc &lt;- precrec::auc(em) |&gt; \n  filter(curvetypes == \"PRC\") |&gt; \n  pull(aucs)\n\n# Calcular métricas para la predicción binaria: sensibilidad, especificidad.\npa_metrics &lt;- obs_pred_test |&gt; \n  select(id, obs, pred_binary) |&gt; \n  PresenceAbsence::presence.absence.accuracy(na.rm = TRUE, st.dev = FALSE)\n\n# mcc y f1\nmcc_f1 &lt;- calculate_mcc_f1(obs_pred_test$obs, obs_pred_test$pred_binary)\n\n# combinar ppm\nppms &lt;- data.frame(\n  mse = mse,\n  sensitivity = pa_metrics$sensitivity,\n  specificity = pa_metrics$specificity,\n  pr_auc = pr_auc,\n  mcc = mcc_f1$mcc,\n  f1 = mcc_f1$f1\n)\nknitr::kable(pivot_longer(ppms, everything()), digits = 3)\n\n\n\n\nname\nvalue\n\n\n\n\nmse\n0.089\n\n\nsensitivity\n0.684\n\n\nspecificity\n0.820\n\n\npr_auc\n0.303\n\n\nmcc\n0.390\n\n\nf1\n0.468\n\n\n\n\n\nUn aspecto importante a tener en cuenta al analizar los datos de eBird es su marcado desequilibrio, con muchas más no detecciones que detecciones. Esto repercute en la interpretación de las métricas de rendimiento predictivo que incorporan la tasa de verdaderos negativos. Por consiguiente, resulta más informativo observar el área bajo la curva (AUC) de precisión-recuperación (PR) que el área bajo la curva ROC (AUC-ROC), ya que ni la precisión ni la recuperación incorporan la tasa de verdaderos negativos. Cada métrica proporciona información sobre distintos aspectos del ajuste del modelo y, al variar de 0 a 1, ofrece una forma relativamente estandarizada de comparar el ajuste del modelo entre especies, regiones y estaciones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-habitat",
    "href": "distabund.html#sec-encounter-habitat",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.5 Asociaciones de hábitat",
    "text": "3.5 Asociaciones de hábitat\nA partir del modelo de random forest, podemos obtener dos fuentes importantes de información sobre la relación entre la detección del Zorzal de Swainson y las características de su entorno local. En primer lugar, la importancia del predictor es una medida del poder predictivo de cada variable utilizada como predictor en el modelo, y se calcula como resultado del ajuste de un modelo de random forest. En segundo lugar, la dependencia parcial estima el efecto marginal de un predictor manteniendo constantes todos los demás predictores.\n\n3.5.1 Importancia del predictor\nDurante el entrenamiento de un modelo de random forests, se eliminan algunas variables en cada nodo de los árboles que lo componen. La importancia del predictor se basa en la disminución promedio de la precisión del modelo cuando se omite un predictor determinado. Técnicamente, se trata de un índice de Gini promedio, pero, en esencia, valores mayores indican que el predictor es más importante para el modelo.\n\n# extraer importancia de los predictores del objeto del modelo random forest\npred_imp &lt;- er_model$variable.importance\npred_imp &lt;- data.frame(predictor = names(pred_imp), \n                       importance = pred_imp) |&gt; \n  arrange(desc(importance))\n# graficar la importancia de los 20 principales predictores\nggplot(head(pred_imp, 20)) + \n  aes(x = reorder(predictor, importance), y = importance) +\n  geom_col() +\n  geom_hline(yintercept = 0, linewidth = 2, colour = \"#555555\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  coord_flip() +\n  labs(x = NULL, \n       y = \"Importancia del predictor (Índice Gini)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        panel.grid.major.x = element_line(colour = \"#cccccc\", linewidth = 0.5))\n\n\n\n\n\n\n\n\nLos predictores más importantes de detección/no detección suelen ser variables de esfuerzo. De hecho, este es el caso: la duración de la lista, la distancia recorrida y la hora de inicio (hours_of_day) figuran entre los 5 predictores principales. Esto no es sorprendente: salir a la hora adecuada y dedicar más esfuerzo a la búsqueda aumenta la probabilidad de detectar al Zorzal de Swainson. En cuanto a las variables de hábitat, ambas variables de altitud tienen una alta importancia, y las principales variables de hábitat corresponden a bosques caducifolios de hoja ancha y sabana arbolada. Cabe señalar, sin embargo, que la alta importancia no indica la dirección de la relación con la detección; para ello, será necesario analizar los gráficos de dependencia parcial.\n\n\n3.5.2 Dependencia parcial\nLos gráficos de dependencia parcial muestran el efecto marginal de un predictor dado sobre la tasa de encuentros, promediada entre los demás predictores. Estos gráficos se generan prediciendo la tasa de encuentros en una secuencia regular de puntos a lo largo de todo el rango de valores de un predictor dado. Para cada valor del predictor, se realizan predicciones de la tasa de encuentros para una submuestra aleatoria del conjunto de datos de entrenamiento, manteniendo fijo el predictor principal y sin modificar los demás. Las predicciones de la tasa de encuentros se promedian entre todas las listas del conjunto de datos de entrenamiento, lo que proporciona una estimación de la tasa de encuentros promedio para un valor específico del predictor principal. Este es un proceso laborioso, ¡pero a continuación proporcionamos una función que lo simplifica enormemente! Esta función acepta los siguientes argumentos:\n\npredictor: El nombre del predictor al que calcularemos la dependencia parcial\ner_model: el objeto del modelo de tasa de encuentro\nmodel: objeto del modelo de la tasa de encuentro\ndata: los datos originales utilizados para entrenar el modelo\nx_res: la resolución de la grilla sobre la cual calcular la dependencia parcial, ej: el número de puntos entre los valores mínimos y máximos de la variable predictora de la cual calcular la dependencia parcial\nn: número de puntos para sub-samplear de los datos de entrenamiento\n\n\n# función para calcular la dependencia parcial para un único predictor\ncalculate_pd &lt;- function(predictor, er_model, calibration_model,\n                         data, x_res = 25, n = 1000) {\n  # crear una cuadrícula de predicción utilizando cuantiles\n  x_grid &lt;- quantile(data[[predictor]],\n                     probs = seq(from = 0, to = 1, length = x_res),\n                     na.rm = TRUE)\n  # remover duplicados\n  x_grid &lt;- x_grid[!duplicated(signif(x_grid, 8))]\n  x_grid &lt;- unname(unique(x_grid))\n  grid &lt;- data.frame(predictor = predictor, x = x_grid)\n  names(grid) &lt;- c(\"predictor\", predictor)\n  \n  # datos de entrenamiento de la submuestra\n  n &lt;- min(n, nrow(data))\n  data &lt;- data[sample(seq.int(nrow(data)), size = n, replace = FALSE), ]\n  \n  # eliminar el predictor focal de los datos\n  data &lt;- data[names(data) != predictor]\n  grid &lt;- merge(grid, data, all = TRUE)\n  \n  # predecir tasa de encuentro\n  p &lt;- predict(er_model, data = grid)\n  \n  # summarise\n  pd &lt;- grid[, c(\"predictor\", predictor)]\n  names(pd) &lt;- c(\"predictor\", \"x\")\n  pd$encounter_rate &lt;- p$predictions[, 2]\n  pd &lt;- dplyr::group_by(pd, predictor, x)\n  pd &lt;- dplyr::summarise(pd,\n                         encounter_rate = mean(encounter_rate, na.rm = TRUE),\n                         .groups = \"drop\")\n  \n  # calibrar\n  pd$encounter_rate &lt;- predict(calibration_model, \n                               newdata = data.frame(pred = pd$encounter_rate), \n                               type = \"response\")\n  pd$encounter_rate &lt;- as.numeric(pd$encounter_rate)\n  # restringir a 0-1\n  pd$encounter_rate[pd$encounter_rate &lt; 0] &lt;- 0\n  pd$encounter_rate[pd$encounter_rate &gt; 1] &lt;- 1\n\n  return(pd)\n}\n\nAhora utilizaremos esta función para calcular la dependencia parcial de los 6 predictores principales.\n\n# calcular la dependencia parcial para cada uno de los 6 predictores principales.\npd &lt;- NULL\nfor (predictor in head(pred_imp$predictor)) {\n  pd &lt;- calculate_pd(predictor, \n                     er_model = er_model, \n                     calibration_model = calibration_model,\n                     data = checklists_train) |&gt; \n    bind_rows(pd)\n}\nhead(pd)\n#&gt; # A tibble: 6 × 3\n#&gt;   predictor                         x encounter_rate\n#&gt;   &lt;chr&gt;                         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1 pland_c04_deciduous_broadleaf  0            0.0973\n#&gt; 2 pland_c04_deciduous_broadleaf  2.33         0.101 \n#&gt; 3 pland_c04_deciduous_broadleaf  4.08         0.103 \n#&gt; 4 pland_c04_deciduous_broadleaf  4.88         0.103 \n#&gt; 5 pland_c04_deciduous_broadleaf  6.98         0.104 \n#&gt; 6 pland_c04_deciduous_broadleaf  9.30         0.105\n\n# graficar dependencia parcial\nggplot(pd) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ factor(predictor, levels = rev(unique(predictor))), \n             ncol = 2, scales = \"free\") +\n  labs(x = NULL, y = \"Tasa de encuentro\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))\n\n\n\n\n\n\n\n\nAquí se observan diversas respuestas interesantes. Como se aprecia en el gráfico anterior, la frecuencia de avistamiento del Zorzal de Swainson alcanza su punto máximo temprano por la mañana, cuando es más probable que esté cantando, para luego disminuir rápidamente al mediodía y aumentar ligeramente al atardecer. Otros predictores muestran una relación de aumento más gradual con la frecuencia de avistamiento; por ejemplo, a mayor presencia de bosque caducifolio en el paisaje, mayor es la frecuencia de avistamiento.\nEl modelo de random forest presenta varias interacciones que no se muestran en estos gráficos de dependencia parcial. Al interpretarlos, conviene tener en cuenta que probablemente existan efectos de interacción más complejos subyacentes a estos gráficos individuales.\n\n\n\n\n\n\nEjercicio\n\n\n\nExamina los datos de importancia de los predictores para identificar la siguiente variable de cobertura terrestre más importante después de pland_c04_deciduous_broadleaf. Elabore un gráfico de dependencia parcial para esta variable.\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nAl observar el data frame de importancia de los predictores, podemos identificar que pland_c08_woody_savanna es la siguiente variable de cobertura terrestre porcentual más importante.\n\n# calcular dependencia parcial \npd_woody_savanna &lt;- calculate_pd(\"pland_c08_woody_savanna\", \n                                 er_model = er_model, \n                                 calibration_model = calibration_model,\n                                 data = checklists_train)\n\n# graficar dependencia parcial\nggplot(pd_woody_savanna) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  labs(x = NULL, y = \"Tasa de encuentro\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-predict",
    "href": "distabund.html#sec-encounter-predict",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.6 Predicción",
    "text": "3.6 Predicción\nAcá usaremos variables ambientales resumidas en una cuadrícula regular de puntos en toda el área de estudio, puedes usar MODIS, Landsat, BioClim, etc… Hay diversas fuentes de información para esto. En esta sección, haremos predicciones de la tasa de encuentro en estos puntos.\n\n3.6.1 Variables de esfuerzo estandarizadas\nLa cuadrícula de predicción solo incluye valores para las variables ambientales, por lo que para realizar predicciones necesitaremos añadir variables de esfuerzo. Haremos predicciones para una lista estándar de eBird: un conteo de aves en un recorrido de 2 km durante 1 hora, en el momento óptimo para la detección de esta especie. Finalmente, realizaremos estas predicciones para el 15 de junio de 2023, la mitad de nuestro periodo de observación de junio para el último año del que disponemos de datos de eBird.\nPara encontrar la hora del día con la mayor probabilidad de detección, podemos buscar el peak en la gráfica de dependencia parcial. La única limitación de este método es que es importante centrarnos en las horas del día con suficientes datos para realizar predicciones. En particular, se observa una tendencia creciente en la detectabilidad con horarios de inicio más tempranos y pocas listas de verificación a altas horas de la noche, lo que puede provocar que el modelo extrapole erróneamente esa tendencia y muestre la mayor detectabilidad durante la noche. Comencemos analizando una gráfica para ver si esto ocurre en este caso.\n\n# determinar la hora peak del día a partir de la dependencia parcial\npd_time &lt;- calculate_pd(\"hours_of_day\",\n                        er_model = er_model, \n                        calibration_model = calibration_model,\n                        data = checklists_train) |&gt; \n  select(hours_of_day = x, encounter_rate)\n\n# histograma\ng_hist &lt;- ggplot(checklists_train) +\n  aes(x = hours_of_day) +\n  geom_histogram(binwidth = 1, center = 0.5, color = \"grey30\",\n                 fill = \"grey50\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 3)) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(x = \"Horas desde la medianoche\",\n       y = \"# de listas\",\n       title = \"Distribución de los horarios de inicio de las observaciones\")\n\n# gráfico de dependencia parcial\ng_pd &lt;- ggplot(pd_time) +\n  aes(x = hours_of_day, y = encounter_rate) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0, 24, by = 3)) +\n  labs(x = \"Horas desde la medianoche\",\n       y = \"Tasa de encuentro\",\n       title = \"Dependencia parcial del tiempo de inicio de la observación\")\n\n# combinar\ngrid.arrange(g_hist, g_pd)\n\n\n\n\n\n\n\n\nLa mayor probabilidad de avistamientos se da temprano por la mañana, como es de esperar en un ave cantora como el Zorzal de Swainson. Sin embargo, se observa un comportamiento anómalo en los valores mínimo y máximo de hours_of_day, donde se produce una extrapolación debido a la escasez de datos. En general, eliminar los valores inicial y final, y luego seleccionar el valor de hours_of_day que maximiza la tasa de avistamientos, es un método fiable para evitar la extrapolación.\n\n# recortar los extremos de la dependencia parcial\npd_time_trimmed &lt;- pd_time[c(-1, -nrow(pd_time)), ]\n\n# identificar el momento que maximiza la tasa de encuentros\npd_time_trimmed &lt;- arrange(pd_time_trimmed, desc(encounter_rate))\nt_peak &lt;- pd_time_trimmed$hours_of_day[1]\nprint(t_peak)\n#&gt; [1] 6.67\n\nSegún este análisis, el mejor momento para detectar al Zorzal de Swainson es a las 6:40 AM. Usaremos este momento para hacer predicciones. Esto equivale a que muchos observadores de aves de eBird realicen un censo en diferentes celdas de la cuadrícula el 15 de junio a las 6:40 AM. También añadiremos las demás variables de esfuerzo al conjunto de datos de la cuadrícula de predicción en ese momento.\n\n# añadir covariables de esfuerzo a la cuadrícula de predicción\npred_grid_eff &lt;- pred_grid |&gt; \n  mutate(observation_date = ymd(\"2023-06-15\"),\n         year = year(observation_date),\n         day_of_year = yday(observation_date),\n         hours_of_day = t_peak,\n         effort_distance_km = 2,\n         effort_hours = 1,\n         effort_speed_kmph = 2,\n         number_observers = 1)\n\n\n\n3.6.2 Estimaciones del modelo\nUtilizando estas variables de esfuerzo estandarizadas, podemos realizar estimaciones en toda la superficie de predicción. Usaremos el modelo para estimar tanto la tasa de avistamiento como la detección/no detección binaria. La predicción binaria, basada en el umbral de optimización MCC-F1 que calculamos en Section 3.4.2, sirve como estimación del límite de distribución del zorzal de Swainson en Georgia en junio.\n\n# estimar tasa de encuentro\npred_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er &lt;- pred_er$predictions[, 2]\n# definir límite de rango\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# aplicar calibración\npred_er_cal &lt;- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") |&gt; \n  as.numeric()\n# restringir a 0-1\npred_er_cal[pred_er_cal &lt; 0] &lt;- 0\npred_er_cal[pred_er_cal &gt; 1] &lt;- 1\n# combinar predicciones con coordenadas de la cuadrícula de predicción\npredictions &lt;- data.frame(cell_id = pred_grid_eff$cell_id,\n                          x = pred_grid_eff$x,\n                          y = pred_grid_eff$y,\n                          in_range = pred_binary, \n                          encounter_rate = pred_er_cal)\n\nA continuación, convertiremos este marco de datos en características espaciales utilizando sf, y luego rasterizaremos los puntos utilizando la plantilla ráster de cuadrícula de predicción.\n\nr_pred &lt;- predictions |&gt; \n  # convertir a espaciales\n  st_as_sf(coords = c(\"x\", \"y\"), crs = crs) |&gt; \n  select(in_range, encounter_rate) |&gt; \n  # rasterizar\n  rasterize(r, field = c(\"in_range\", \"encounter_rate\"))\nprint(r_pred)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 171, 148, 2  (nrow, ncol, nlyr)\n#&gt; resolution  : 2991, 3005  (x, y)\n#&gt; extent      : -175612, 267066, -312494, 201374  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=laea +lat_0=33.2 +lon_0=-83.7 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; names       : in_range, encounter_rate \n#&gt; min values  :        0,            0.0 \n#&gt; max values  :        1,            0.7",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encounter-map",
    "href": "distabund.html#sec-encounter-map",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.7 Mapeo",
    "text": "3.7 Mapeo\nAhora viene lo divertido: ¡vamos a crear mapas de la distribución del Zorzal de Swainson en Georgia! Empezaremos con un mapa de distribución sencillo usando la capa in_range del ráster de predicciones que creamos. Aunque las predicciones de la tasa de encuentro ofrecen información más detallada, para algunas aplicaciones un mapa de distribución será más conveniente.\n\npar(mar = c(0.25, 0.25, 1.25, 0.25))\n# configurar el área del plot\nplot(study_region, \n     main = \"Rango del Zorzal de Swainson (Junio 2023)\",\n     col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# convertir predicción binaria a categórica\nr_range &lt;- as.factor(r_pred[[\"in_range\"]])\nplot(r_range, col = c(\"#e6e6e6\", \"forestgreen\"),\n     maxpixels = ncell(r_range),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n\n\n\n\n\n\n\nA continuación, elaboraremos un mapa de las predicciones de la tasa de encuentros.\n\npar(mar = c(4, 0.25, 0.25, 0.25))\n# configurar área del plot\nplot(study_region, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# definir quiebres de cuantiles\nbrks &lt;- global(r_pred[[\"encounter_rate\"]], fun = quantile, \n               probs = seq(0, 1, 0.1), na.rm = TRUE) |&gt; \n  as.numeric() |&gt; \n  unique()\n# etiquetar el valor más bajo, mediano y máximo\nlbls &lt;- round(c(0, median(brks), max(brks)), 2)\n# paleta de colores de Status & Trends\npal &lt;- ebirdst_palettes(length(brks) - 1)\nplot(r_pred[[\"encounter_rate\"]], \n     col = pal, breaks = brks, \n     maxpixels = ncell(r_pred),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# leyenda\npar(new = TRUE, mar = c(0, 0, 0, 0))\ntitle &lt;- \"Tasa de encuentro del Zorzal de Swainson (Junio 2023)\"\nimage.plot(zlim = c(0, 1), legend.only = TRUE, \n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.25, 0.75, 0.03, 0.06),\n           horizontal = TRUE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5,\n                            padj = -1.5),\n           legend.args = list(text = title,\n                              side = 3, col = \"black\",\n                              cex = 1, line = 0))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-abundance-hurdle",
    "href": "distabund.html#sec-abundance-hurdle",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "4.2 Modelo de obstáculos (hurdle)",
    "text": "4.2 Modelo de obstáculos (hurdle)\nPara este modelo de dos pasos con obstáculos, comenzaremos entrenando el mismo modelo de tasa de encuentros que en el capítulo anterior. Luego, seleccionaremos un subconjunto de la lista de verificación de eBird que incluya solo aquellas especies detectadas o cuya presencia fue predicha por el modelo de tasa de encuentros. Utilizaremos este subconjunto de datos para entrenar un segundo modelo de random forest para el conteo esperado. Finalmente, combinaremos los resultados de ambos pasos para obtener estimaciones de abundancia relativa.\n\n4.2.1 Paso 1: Tasa de encuentro\nEn el capítulo anterior explicamos el modelo de tasa de encuentros calibrado. Aquí repetimos el proceso de modelado de la tasa de encuentros de forma concisa.\n\n# calcular frecuencia de detección para el random forest \ndetection_freq &lt;- mean(checklists_train$species_observed)\n\n# entrenar un modelo de random forest para la tasa de encuentros\ntrain_er &lt;- select(checklists_train, -observation_count)\ner_model &lt;- ranger(formula =  as.factor(species_observed) ~ ., \n                   data = train_er,\n                   importance = \"impurity\",\n                   probability = TRUE,\n                   replace = TRUE,\n                   sample.fraction = c(detection_freq, detection_freq))\n\n# seleccionar el umbral de ocurrencia de optimización mcc-F1\nobs_pred &lt;- data.frame(obs = as.integer(train_er$species_observed), \n                       pred = er_model$predictions[, 2])\nmcc_f1 &lt;- mccf1(response = obs_pred$obs, predictor = obs_pred$pred)\nmcc_f1_summary &lt;- summary(mcc_f1)\nthreshold &lt;- mcc_f1_summary$best_threshold[1]\n\n# modelo de calibración\ncalibration_model &lt;- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n#&gt;  mccf1_metric best_threshold\n#&gt;         0.403          0.512\n\n\n\n4.2.2 Paso 2: Contar\nEn el segundo paso, entrenamos un modelo de random forest para estimar el número esperado de individuos en las listas de eBird donde la especie fue detectada o se predijo su detección mediante el modelo de tasa de encuentros. Para ello, comenzaremos seleccionando únicamente estas listas de eBird. Además, eliminaremos cualquier observación en la que el observador reportó la presencia del zorzal de Swainson, pero no indicó el número de individuos (codificado como “X” en la base de datos de eBird, pero convertido a NA en nuestro conjunto de datos).\n\n# adjuntar la tasa de encuentro prevista basada en muestras fuera de la bolsa.\ntrain_count &lt;- checklists_train\ntrain_count$pred_er &lt;- er_model$predictions[, 2]\n# muestrear para solo detecciones observadas o predichas\ntrain_count &lt;- train_count |&gt; \n  filter(!is.na(observation_count),\n         observation_count &gt; 0 | pred_er &gt; threshold) |&gt; \n  select(-species_observed, -pred_er)\n\nHemos observado que incluir la tasa de encuentros estimada como predictor en el modelo de conteo mejora el rendimiento predictivo. Por lo tanto, teniendo esto en cuenta, predecimos la tasa de encuentros para el conjunto de datos de entrenamiento y la añadimos como una columna adicional.\n\npredicted_er &lt;- predict(er_model, data = train_count, type = \"response\")\npredicted_er &lt;- predicted_er$predictions[, 2]\ntrain_count$predicted_er &lt;- predicted_er\n\nFinalmente, entrenamos un modelo de random forest para estimar el recuento. Este modelo es superficialmente muy similar al modelo de random forest para la tasa de encuentros; sin embargo, para el recuento utilizamos un random forest de regresión, mientras que para la tasa de encuentros utilizamos un random forest de clasificación balanceada.\n\ncount_model &lt;- ranger(formula = observation_count ~ .,\n                      data = train_count,\n                      importance = \"impurity\",\n                      replace = TRUE)\n\n\n\n4.2.3 Evaluación\nEn Evaluación del capítulo anterior calculamos un conjunto de métricas de rendimiento predictivo para el modelo de tasa de encuentros. Estas métricas también deben considerarse al modelar la abundancia relativa; sin embargo, no duplicaremos el cálculo de estas métricas aquí. En su lugar, calcularemos el coeficiente de correlación de rangos de Spearmantanto para el recuento como para la abundancia relativa, y el coeficiente de correlación de Pearson para el logaritmo del recuento y la abundancia relativa. Comenzaremos estimando la tasa de encuentros, el recuento y la abundancia relativa para el conjunto de datos de prueba muestreado en cuadrícula espaciotemporal.\n\n# obtener el conjunto de prueba reservado para el entrenamiento.\nchecklists_test &lt;- filter(checklists_ss, type == \"test\") |&gt; \n  mutate(species_observed = as.integer(species_observed)) |&gt; \n  filter(!is.na(observation_count))\n\n# estimar tasa de encuentro para los datos de prueba\npred_er &lt;- predict(er_model, data = checklists_test, type = \"response\")\n# extraer probabilidad de detección\npred_er &lt;- pred_er$predictions[, 2]\n# convertir a binario usando el umbral\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# calibrar\npred_calibrated &lt;- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") |&gt; \n  as.numeric()\n# restringir probabilidades a 0-1\npred_calibrated[pred_calibrated &lt; 0] &lt;- 0\npred_calibrated[pred_calibrated &gt; 1] &lt;- 1\n\n# añadir la tasa de encuentros requerida para las estimaciones de conteo\nchecklists_test$predicted_er &lt;- pred_er\n# estimar conteos\npred_count &lt;- predict(count_model, data = checklists_test, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# la abundancia relativa es el producto de la tasa de encuentro y el conteo\npred_abundance &lt;- pred_calibrated * pred_count\n\n# combinar observaciones y estimados\nobs_pred_test &lt;- data.frame(\n  id = seq_along(pred_abundance),\n  # detección/no detección real\n  obs_detected = as.integer(checklists_test$species_observed),\n  obs_count = checklists_test$observation_count,\n  # estimaciones del modelo\n  pred_binary = pred_binary,\n  pred_er = pred_calibrated,\n  pred_count = pred_count,\n  pred_abundance = pred_abundance\n)\n\nLas métricas de conteo miden el rendimiento dentro del rango, lo que significa que comparamos el conteo observado con el conteo estimado solo para aquellas listas donde el modelo predice la presencia de la especie. La abundancia relativa considera tanto la tasa de encuentro como el conteo, por lo que el rendimiento predictivo de la abundancia se basa en todas las listas de verificación.\n\n# muestrear solo aquellas listas donde ocurrió detección\ndetections_test &lt;- filter(obs_pred_test, obs_detected &gt; 0)\n\n# métricas de recuento, basadas únicamente en listas donde se detectó\ncount_spearman &lt;- cor(detections_test$pred_count, \n                      detections_test$obs_count,\n                      method = \"spearman\")\nlog_count_pearson &lt;- cor(log(detections_test$pred_count + 1),\n                         log(detections_test$obs_count + 1),\n                         method = \"pearson\")\n\n# métricas de abundancia\nabundance_spearman &lt;- cor(detections_test$pred_abundance, \n                          detections_test$obs_count,\n                          method = \"spearman\")\nlog_abundance_pearson &lt;- cor(log(detections_test$pred_abundance + 1),\n                             log(detections_test$obs_count + 1),\n                             method = \"pearson\")\n\n# combinar ppms\nppms &lt;- data.frame(\n  count_spearman = count_spearman,\n  log_count_pearson = log_count_pearson,\n  abundance_spearman = abundance_spearman,\n  log_abundance_pearson = log_abundance_pearson\n)\nknitr::kable(pivot_longer(ppms, everything()), digits = 3)\n\n\n\n\nname\nvalue\n\n\n\n\ncount_spearman\n0.283\n\n\nlog_count_pearson\n0.405\n\n\nabundance_spearman\n0.326\n\n\nlog_abundance_pearson\n0.458\n\n\n\n\n\nLas correlaciones de Spearman nos informan sobre la capacidad del modelo para estimar el orden de frecuencia y la abundancia relativa, aspectos en los que estos modelos suelen tener un mejor desempeño. Las correlaciones de Pearson nos brindan información sobre la capacidad del modelo para estimar frecuencias absolutas en escala logarítmica, una tarea que suele ser más difícil con los datos de eBird, especialmente para especies congregacionales que a menudo presentan frecuencias elevadas. Al igual que con las métricas de rendimiento de la tasa de encuentros, estas son útiles para comparar la calidad del modelo entre especies, regiones y estaciones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-abundance-predict",
    "href": "distabund.html#sec-abundance-predict",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "4.3 Predicción",
    "text": "4.3 Predicción\nTal como hicimos con la función predict para la tasa de avistamientos, podemos estimar la abundancia relativa en nuestra cuadrícula de predicción. Primero estimamos la tasa de avistamientos y el conteo, y luego los multiplicamos para obtener una estimación de la abundancia relativa. Comencemos agregando las variables de esfuerzo a la cuadrícula de predicción para una lista de verificación estándar de eBird en el momento óptimo del día para detectar al Zorzal de Swainson. Recordemos que, según la función predict-effort, determinamos que el momento óptimo del día para detectar al Zorzal de Swainson era alrededor de las 6:37 a. m.\n\npred_grid_eff &lt;- pred_grid |&gt; \n  mutate(observation_date = ymd(\"2023-06-15\"),\n         year = year(observation_date),\n         day_of_year = yday(observation_date),\n         # determinado como tiempo óptimo para la detección en el capítulo previo\n         hours_of_day = 6.6,\n         effort_distance_km = 2,\n         effort_hours = 1,\n         effort_speed_kmph = 2,\n         number_observers = 1)\n\nAhora podemos estimar la tasa de encuentros calibrada y el recuento para cada punto de la cuadrícula de predicción. También incluimos una estimación binaria del límite de distribución.\n\n# estimar tasa de encuentro\npred_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er &lt;- pred_er$predictions[, 2]\n# definir límite de rango\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# aplciar calibración\npred_er_cal &lt;- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") |&gt; \n  as.numeric()\n# restringir a 0-1\npred_er_cal[pred_er_cal &lt; 0] &lt;- 0\npred_er_cal[pred_er_cal &gt; 1] &lt;- 1\n\n# añadir tasa de encuentro predicha requerida para los estimados de conteo\npred_grid_eff$predicted_er &lt;- pred_er\n# conteos estimados\npred_count &lt;- predict(count_model, data = pred_grid_eff, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# combinar predicciones con coordenadas de la cuadrícula de predicción\npredictions &lt;- data.frame(cell_id = pred_grid_eff$cell_id,\n                          x = pred_grid_eff$x,\n                          y = pred_grid_eff$y,\n                          in_range = pred_binary, \n                          encounter_rate = pred_er_cal,\n                          count = pred_count)\n\nA continuación, agregamos una columna para la estimación de abundancia relativa (el producto de las estimaciones de tasa de encuentro y conteo) y convertimos estas estimaciones a formato ráster.\n\n# añadir estimados de abundancia relativa\npredictions$abundance &lt;- predictions$encounter_rate * predictions$count\n\n# rasterizar\nlayers &lt;- c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\")\nr_pred &lt;- predictions |&gt; \n  # convertir a espacial \n  st_as_sf(coords = c(\"x\", \"y\"), crs = crs) |&gt; \n  select(all_of(layers)) |&gt; \n  # rasterizar\n  rasterize(r, field = layers)\nprint(r_pred)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 171, 148, 4  (nrow, ncol, nlyr)\n#&gt; resolution  : 2991, 3005  (x, y)\n#&gt; extent      : -175612, 267066, -312494, 201374  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=laea +lat_0=33.2 +lon_0=-83.7 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; names       : in_range, encounter_rate, count, abundance \n#&gt; min values  :        0,          0.000, 0.079,      0.00 \n#&gt; max values  :        1,          0.641, 1.913,      1.13\n\nFinalmente, generaremos un mapa de abundancia relativa. Los valores que se muestran en este mapa representan el número esperado de Zorzales de Swainson avistados por un observador promedio de eBird que realice un conteo itinerante de 2 km durante 1 hora, comenzando aproximadamente a las 6:37 a. m. del 15 de junio de 2023. Dado que la detectabilidad no es perfecta, prevemos que la abundancia real de Zorzales de Swainson sea mayor que estos valores, pero sin estimar directamente la tasa de detección, es difícil precisar cuánto mayor.\nAntes de generar el mapa de abundancia relativa, lo multiplicaremos por la capa in_range, lo que producirá un mapa que mostrará una abundancia relativa de cero donde el modelo predice que no hay presencia de Zorzales de Swainson.\n\npar(mar = c(4, 0.25, 0.25, 0.25))\n# definir área del plot\nplot(study_region, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# definir quiebres de cuantiles, excluyendo los ceros\nbrks &lt;- ifel(r_pred[[\"abundance\"]] &gt; 0, r_pred[[\"abundance\"]], NA) |&gt; \n  global(fun = quantile, \n         probs = seq(0, 1, 0.1), na.rm = TRUE) |&gt; \n  as.numeric() |&gt; \n  unique()\n# etiquetar los valores mínimos, medios y máximos\nlbls &lt;- round(c(min(brks), median(brks), max(brks)), 2)\n# paleta de colores de Status & Trends \npal &lt;- ebirdst_palettes(length(brks) - 1)\nplot(r_pred[[\"abundance\"]], \n     col = c(\"#e6e6e6\", pal), breaks = c(0, brks), \n     maxpixels = ncell(r_pred),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# leyenda\npar(new = TRUE, mar = c(0, 0, 0, 0))\ntitle &lt;- \"Abundancia relativa Zorzal de Swainson (Junio 2023)\"\nimage.plot(zlim = c(0, 1), legend.only = TRUE, \n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.25, 0.75, 0.03, 0.06),\n           horizontal = TRUE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5,\n                            padj = -1.5),\n           legend.args = list(text = title,\n                              side = 3, col = \"black\",\n                              cex = 1, line = 0))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-encuenter-intro",
    "href": "distabund.html#sec-encuenter-intro",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "",
    "text": "3.1.1 Preparación de datos\nComencemos cargando los paquetes y datos necesarios. Te solicitamos descargar el paquete de datos, y descomprimirlo en el directorio de tu proyecto para asegurarte de trabajar con los mismos datos utilizados en la creación de esta clase.\n\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(fields)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(lubridate)\nlibrary(mccf1)\nlibrary(ranger)\nlibrary(readr)\nlibrary(scam)\nlibrary(sf)\nlibrary(terra)\nlibrary(tidyr)\n\n# fijar un número semilla para reproducibilidad\nset.seed(1)\n\n# Variables ambientales: cobertura de suelo y altitud\nenv_vars &lt;- read_csv(\"data/environmental-variables_checklists_jun_us-ga.csv\")\n\n# Datos de eBird rellenados con ceros combinados con datos ambientales\nchecklists_env &lt;- read_csv(\"data/checklists-zf_woothr_jun_us-ga.csv\") |&gt; \n  inner_join(env_vars, by = \"checklist_id\")\n\n# cuadrícula de predicción\npred_grid &lt;- read_csv(\"data/environmental-variables_prediction-grid_us-ga.csv\")\n# plantilla ráster para la cuadrícula\nr &lt;- rast(\"data/prediction-grid_us-ga.tif\")\n# obtener el sistema de referencia de coordenadas de la cuadrícula de predicción\ncrs &lt;- st_crs(r)\n\n# cargar datos GIS para la creación de mapas\nstudy_region &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_states\") |&gt; \n  filter(state_code == \"US-GA\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_land &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_land\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_country_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_state_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\n\n\n\n3.1.2 Submuestreo espaciotemporal\nTal como discutimos en las clases previas, tres de los desafíos a los que nos enfrentamos al usar datos de eBird, son los sesgos espaciales, sesgos temporales, y el desequilibrio de clases. El sesgo espacial y temporal se refiere a la tendencia de las listas de eBird a distribuirse de forma no aleatoria en el espacio y el tiempo, mientras que el desequilibrio de clases es el fenómeno por el cual hay muchas más no detecciones que detecciones para la mayoría de las especies. Estos tres factores pueden afectar nuestra capacidad para realizar inferencias fiables a partir de estos datos. Afortunadamente, los tres se pueden abordar en gran medida mediante el submuestreo de los datos de eBird antes del modelado. En concreto, definimos una cuadrícula de 3 km × 3 km de igual área en toda la región de estudio y, a continuación, submuestreamos las detecciones y las no detecciones de forma independiente de la cuadrícula para garantizar que no perdamos demasiadas detecciones. Para abordar el sesgo temporal, muestrearemos una lista con detecciones y otra con no detecciones de cada celda de la cuadrícula para cada semana de cada año. Afortunadamente, el paquete ebirdst incluye la función grid_sample_stratified(), diseñada específicamente para realizar este tipo de muestreo en los datos de las listas de eBird.\nAntes de trabajar con datos reales, resulta instructivo observar un ejemplo sencillo para ver cómo funciona este proceso de submuestreo.\n\n# generar puntos aleatorios para una sola semana del año\npts &lt;- data.frame(longitude = runif(500, -0.1, 0.1),\n                  latitude = runif(500, -0.1, 0.1),\n                  day_of_year = sample(1:7, 500, replace = TRUE))\n\n# muestrea una lista por celda de la cuadrícula\n# por defecto el comando grid_sample() usa una cuadrícula a 3km x 3km x 1 semana\npts_ss &lt;- grid_sample(pts)\n\n# generar polígonos para las celdas de la cuadrícula\nggplot(pts) +\n  aes(x = longitude, y = latitude) +\n  geom_point(size = 0.5) +\n  geom_point(data = pts_ss, col = \"red\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nEn el gráfico anterior, el conjunto completo de puntos se muestra en negro y los puntos submuestreados en rojo. Ahora apliquemos el mismo método para submuestrear las listas reales de eBird; sin embargo, ahora submuestreamos temporalmente además de espacialmente, y muestreamos las detecciones y no detecciones por separado. Divideremos los datos en conjuntos de entrenamiento y prueba en una proporción de 80/20. Usando el argumento sample_by de grid_sample_stratified(), podemos muestrear de forma independiente de los conjuntos de entrenamiento y prueba para eliminar el sesgo de ambos.\n\n# muestrea de una lista por cada cuadrícula de 3 km x 3 km x 1 semana para cada año\n# detección/no detección de muestras de forma independiente\nchecklists_ss &lt;- grid_sample_stratified(checklists_env,\n                                        obs_column = \"species_observed\",\n                                        sample_by = \"type\")\n\n\n\n\n\n\n\nEjercicio\n\n\n\nCompara el conjunto completo de listas de eBird con el conjunto de listas restantes después del submuestreo. ¿Cuál fue el cambio en el tamaño de la muestra y cómo afectó el submuestreo a la prevalencia de detecciones en comparación con las no detecciones?\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nEl submuestreo disminuyó el número total de listas en un factor de aproximadamente 2.3, pero aumentó la prevalencia de detecciones de 10.9% a 14.2%.\n\n# datos originales\nnrow(checklists_env)\n#&gt; [1] 47254\ncount(checklists_env, species_observed) |&gt; \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   species_observed     n percent\n#&gt;   &lt;lgl&gt;            &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1 FALSE            42115   0.891\n#&gt; 2 TRUE              5139   0.109\n\n# después de muestrear\nnrow(checklists_ss)\n#&gt; [1] 20439\ncount(checklists_ss, species_observed) |&gt; \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   species_observed     n percent\n#&gt;   &lt;lgl&gt;            &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1 FALSE            17544   0.858\n#&gt; 2 TRUE              2895   0.142\n\n\n\n\nEste aumento en la frecuencia de detecciones ayudará al modelo de random forest a distinguir dónde se observan las aves; sin embargo, como resultado de este aumento, la tasa de encuentros estimada, basada en estos datos submuestreados, será mayor que la tasa de encuentros real. Al examinar los resultados de los modelos, es importante recordar que modificamos la frecuencia de detecciones en esta etapa. Ahora veamos cómo afecta el submuestreo a la distribución espacial de las observaciones de entrenamiento.\n\n# convertir listas en características espaciales\nall_pts &lt;- checklists_env |&gt;  \n  filter(type == \"train\") |&gt; \n  st_as_sf(coords = c(\"longitude\",\"latitude\"), crs = 4326) |&gt;\n  st_transform(crs = crs) |&gt; \n  select(species_observed)\n\nss_pts &lt;- checklists_ss |&gt;  \n  filter(type == \"train\") |&gt; \n  st_as_sf(coords = c(\"longitude\",\"latitude\"), crs = 4326) |&gt;\n  st_transform(crs = crs) |&gt; \n  select(species_observed)\nboth_pts &lt;- list(before_ss = all_pts, after_ss = ss_pts)\n\n# mapear\np &lt;- par(mfrow = c(1, 2))\nfor (i in seq_along(both_pts)) {\n  par(mar = c(0.25, 0.25, 0.25, 0.25))\n  # configurar área del plot\n  plot(st_geometry(both_pts[[i]]), col = NA)\n  # datos GIS contextuales \n  plot(ne_land, col = \"#dddddd\", border = \"#888888\", lwd = 0.5, add = TRUE)\n  plot(study_region, col = \"#cccccc\", border = NA, add = TRUE)\n  plot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\n  plot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\n  # observaciones de eBird\n  # no observado\n  plot(st_geometry(both_pts[[i]]),\n       pch = 19, cex = 0.1, col = alpha(\"#555555\", 0.25),\n       add = TRUE)\n  # observado\n  plot(filter(both_pts[[i]], species_observed) |&gt; st_geometry(),\n       pch = 19, cex = 0.3, col = alpha(\"#4daf4a\", 0.5),\n       add = TRUE)\n  # leyendas\n  legend(\"bottomright\", bty = \"n\",\n         col = c(\"#555555\", \"#4daf4a\"),\n         legend = c(\"No-detección\", \"Detección\"),\n         pch = 19)\n  box()\n  par(new = TRUE, mar = c(0, 0, 3, 0))\n  if (names(both_pts)[i] == \"before_ss\") {\n    title(\"Registros del Zorzal de Swainson \\nAntes del subsampleo\")\n  } else {\n    title(\"Después del subsampleo\")\n  }\n}\npar(p)\n\n\n\n\n\n\n\n\nPara el Zorzal de Swainson, submuestrear las detecciones y no detecciones de forma independiente es suficiente para abordar el desequilibrio de clases. Puede evaluar el impacto de este desequilibrio analizando las tasas de prevalencia y examinando si los modelos predicen correctamente con los datos de validación. Para especies extremadamente raras, podría ser conveniente conservar todas las detecciones o incluso sobremuestrearlas [@robinsonCorrectingBiasDistribution2018]. Al hacerlo, tenga en cuenta que algunas detecciones de especies no serán independientes, lo que podría provocar un sobreajuste de los datos. En general, al considerar el número de detecciones y la tasa de prevalencia, es importante tener en cuenta tanto la ecología y la detectabilidad de la especie en cuestión como el comportamiento de los observadores hacia ella.\n\n\n3.1.3 Random forests\nAhora utilizaremos un modelo de random forest para relacionar la detección/no detección del zorzal de Swainson con las variables ambientales calculadas, teniendo en cuenta también la variación en la detectabilidad mediante la inclusión de un conjunto de covariables de esfuerzo. En esta etapa, filtramos los datos para quedarnos únicamente con el conjunto de entrenamiento, reservando el conjunto de prueba para evaluar el rendimiento predictivo posteriormente.\n\nchecklists_train &lt;- checklists_ss |&gt; \n  filter(type == \"train\") |&gt; \n  # seleccionar únicamente las columnas que se utilizarán en el modelo.\n  select(species_observed,\n         year, day_of_year, hours_of_day,\n         effort_hours, effort_distance_km, effort_speed_kmph,\n         number_observers, \n         starts_with(\"pland_\"),\n         starts_with(\"ed_\"),\n         starts_with(\"elevation_\"))\n\nAunque logramos abordar parcialmente el problema del desequilibrio de clases mediante submuestreo, las detecciones aún representan solo 14.2% de las observaciones, y para las especies raras este número será aún menor. La mayoría de los algoritmos de clasificación buscan minimizar la tasa de error general, lo que resulta en un rendimiento predictivo deficiente para las clases raras. Para abordar este problema, utilizaremos un enfoque de random forest balanceado, una modificación del algoritmo tradicional de random forest diseñada para manejar datos desequilibrados. En este enfoque, cada uno de los árboles que componen el random forest se genera utilizando una muestra aleatoria de los datos, elegida de manera que haya el mismo número de detecciones (la clase rara) y no detecciones (la clase común). Para utilizar este enfoque, necesitaremos calcular la proporción de detecciones en el conjunto de datos.\n\ndetection_freq &lt;- mean(checklists_train$species_observed)\n\nExisten varios paquetes para entrenar random forests en R; sin embargo, utilizaremos ranger (https://github.com/imbs-hl/ranger), una implementación muy rápida con todas las características necesarias. Para ajustar un random forest balanceado, usamos el parámetro sample.fraction para indicarle a ranger que genere cada árbol a partir de una muestra aleatoria de los datos con igual número de detecciones y no detecciones. Especificar esto puede resultar complejo, ya que debemos indicarle a ranger la proporción del conjunto de datos total que se muestreará para las no detecciones y las detecciones. Si esta proporción es igual a la proporción de la clase menos frecuente (las detecciones), entonces ranger muestreará de toda la clase menos frecuente, pero de un subconjunto de igual tamaño de las no detecciones más comunes. Usamos replace = TRUE para asegurarnos de que se trate de una muestra bootstrap (https://en.wikipedia.org/wiki/Bootstrapping_(statistics)). También pediremos a ranger que prediga probabilidades, en lugar de simplemente devolver la clase más probable, con probability = TRUE.\n\n# ranger requiere una respuesta factor para hacer clasificación \ner_model &lt;- ranger(formula =  as.factor(species_observed) ~ ., \n                   data = checklists_train,\n                   importance = \"impurity\",\n                   probability = TRUE,\n                   replace = TRUE, \n                   sample.fraction = c(detection_freq, detection_freq))\n\n\n\n3.1.4 Calibración\nPor diversas razones, las probabilidades predichas por los modelos no siempre coinciden con las frecuencias de detección observadas. Por ejemplo, cabría esperar que, al considerar todos los sitios con una probabilidad de encuentro estimada de 0,2, se registrara la especie en el 20 % de ellos. Sin embargo, estas probabilidades no siempre coinciden. Esto se evidencia claramente en nuestro ejemplo, ya que hemos aumentado deliberadamente la prevalencia de registros de detección en los datos mediante el proceso de submuestreo espaciotemporal. Podemos generar un modelo de calibración para las predicciones, el cual puede ser una herramienta de diagnóstico útil para comprender dichas predicciones y, en algunos casos, puede utilizarse para realinearlas con las observaciones. Para obtener información sobre la calibración en modelos de distribución de especies, consulte Vaughan y Ormerod [-@vaughanContinuingChallengesTesting2005] y para referencias más fundamentales sobre calibración, consulte Platt [-@plattProbabilisticOutputsSupport1999], Murphy [-@murphyNewVectorPartition1973] y Niculescu-Mizil y Caruana [-@niculescu-mizilPredictingGoodProbabilities2005].\nPara entrenar un modelo de calibración para nuestras predicciones, predecimos la tasa de encuentros para cada lista en el conjunto de entrenamiento y luego ajustamos un Modelo Aditivo Generalizado (GAM) binomial con la tasa de encuentros observada real como respuesta y la tasa de encuentros predicha como variable predictora. Mientras que los Modelos Lineales Generalizados (GLM) ajustan una relación lineal entre una respuesta y los predictores, los GAM permiten relaciones no lineales. Si bien los GAM ofrecen cierto grado de flexibilidad, en algunas situaciones pueden sobreajustarse y proporcionar calibraciones poco realistas e inútiles. Tenemos una fuerte expectativa a priori de que los valores reales más altos también se asociarán con tasas de encuentros estimadas más altas. Para mantener la clasificación de las predicciones, es importante respetar este orden y, para ello, utilizaremos un GAM restringido a ser solo creciente. Para ajustar el GAM, utilizaremos el paquete de R scam (https://CRAN.R-project.org/package=scam), de modo que la forma se pueda restringir a ser monótonamente creciente. Tenga en cuenta que las predicciones de ranger están en forma de matriz de probabilidades para cada clase, y lo que queremos es la probabilidad de detecciones, que es la segunda columna de esta matriz.\n\n# tasa de encuentro prevista basada en muestras fuera de la bolsa\ner_pred &lt;- er_model$predictions[, 2]\n# detecciones observadas, convertida de nuevo desde el factor\ndet_obs &lt;- as.integer(checklists_train$species_observed)\n# construir un data frame para entrenar el modelo SCAM\nobs_pred &lt;- data.frame(obs = det_obs, pred = er_pred)\n\n# entrenar modelo de calibración\ncalibration_model &lt;- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n\nPara utilizar el modelo de calibración como herramienta de diagnóstico, agruparemos las tasas de encuentro previstas en intervalos y, a continuación, calcularemos la media de las tasas de encuentro previstas y observadas dentro de cada intervalo. Esto se puede comparar con las predicciones del modelo de calibración.\n\n# Agrupe la tasa de encuentros prevista en intervalos de ancho 0,02\n# luego, calcular las tasas medias de encuentros observadas en cada intervalo.\ner_breaks &lt;- seq(0, 1, by = 0.02)\nmean_er &lt;- obs_pred |&gt;\n  mutate(er_bin = cut(pred, breaks = er_breaks, include.lowest = TRUE)) |&gt;\n  group_by(er_bin) |&gt;\n  summarise(n_checklists = n(),\n            pred = mean(pred), \n            obs = mean(obs),\n            .groups = \"drop\")\n\n# hacer prediccioens del modelo de calibración\ncalibration_curve &lt;- data.frame(pred = er_breaks)\ncal_pred &lt;- predict(calibration_model, calibration_curve, type = \"response\")\ncalibration_curve$calibrated &lt;- cal_pred\n\n# Comparación de las tasas medias de encuentros agrupadas con el modelo de calibración\nggplot(calibration_curve) +\n  aes(x = pred, y = calibrated) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  geom_line(color = \"blue\") +\n  geom_point(data = mean_er, \n             aes(x = pred, y = obs),\n             size = 2, alpha = 0.6,\n             show.legend = FALSE) +\n  labs(x = \"Tasa de encuentro estimada\",\n       y = \"Tasa de encuentro observada\",\n       title = \"Modelo de calibración\") +\n  coord_equal(xlim = c(0, 1), ylim = c(0, 1))\n\n\n\n\n\n\n\n\nEn este gráfico se observa claramente que las tasas de encuentro estimadas son, en su mayoría, mucho mayores que las tasas de encuentro observadas (todos los puntos se sitúan por debajo de la línea discontinua \\(x = y\\)). Por lo tanto, vemos que el modelo no está bien calibrado. Sin embargo, los puntos muestran que la clasificación relativa de las predicciones es, en general, correcta: los sitios con una tasa de encuentro estimada mayor suelen presentar tasas de encuentro observadas mayores.\nDe esto hemos aprendido que el modelo distingue bien los sitios con tasas altas de aquellos con tasas bajas. Para quienes estén familiarizados con el uso del área bajo la curva (AUC) para evaluar la calidad de los modelos de distribución de especies, la gráfica indica que el modelo debería tener un valor AUC alto. Sin embargo, el modelo no estima con precisión las tasas de encuentro.\nSi se requieren tasas de encuentro precisas y el modelo de calibración es robusto (ajuste preciso de los puntos a la línea en la figura anterior), entonces se puede usar para calibrar las estimaciones del modelo de random forest, ajustándolas para que coincidan mejor con las tasas de encuentro observadas. El modelo de random forest calibrado es la combinación del modelo de random forest original seguido del modelo de calibración.\nSi utiliza este modelo para calibrar sus estimaciones, tenga en cuenta que la curva de calibración puede generar probabilidades mayores que 1 y menores que 0, por lo que al aplicar la calibración también debemos restringir las predicciones al intervalo entre 0 y 1. Es posible realizar una regresión logística para la calibración con el fin de eliminar estas predicciones menores que 0 o mayores que 1; sin embargo, hemos comprobado que el GAM con restricción gaussiana es más estable que el GAM con restricción logística.\n\n\n3.1.5 Umbralización\nEl modelo de random forest genera estimaciones continuas de la tasa de encuentro entre 0 y 1. Sin embargo, para muchas aplicaciones, como la evaluación del rendimiento del modelo, será necesario reclasificar esta probabilidad continua a una estimación binaria de presencia/ausencia. Esta reclasificación se realiza estableciendo un umbral por encima del cual se predice la presencia de la especie. El umbral se elige normalmente para maximizar una métrica de rendimiento como el estadístico Kappa o el área bajo la curva ROC. No obstante, para datos con clases desequilibradas, como los de eBird, donde las no detecciones son mucho más frecuentes, muchas de estas métricas pueden inflar el rendimiento al sobreponderar la clase más común [@caoMCCF1CurvePerformance2020]. Para mitigar estos problemas, sugerimos un método de establecimiento de umbrales mediante la curva MCC-F1 curve. Este método grafica el coeficiente de correlación de Matthews (MCC) frente al F1 Score para un rango de umbrales posibles y, posteriormente, selecciona el umbral donde la curva se aproxima más al punto de rendimiento óptimo. El paquete mccf1 de R implementa este método.\n\n# cálculo de mcc y fscore para varios umbrales\nmcc_f1 &lt;- mccf1(\n  # detección/no detección observadas\n  response = obs_pred$obs,\n  # tasa de encuentros predicha por random forest\n  predictor = obs_pred$pred)\n\n# identificar el mejor umbral\nmcc_f1_summary &lt;- summary(mcc_f1)\n#&gt;  mccf1_metric best_threshold\n#&gt;         0.401          0.534\nthreshold &lt;- mcc_f1_summary$best_threshold[1]\n\n\n\n\n\n\n\nTip\n\n\n\nEste umbral define esencialmente el límite de distribución de la especie: se predice que las áreas donde la tasa de encuentros está por debajo del umbral están fuera de la distribución del Zorzal de Swainson y se predice que las áreas donde la tasa de encuentros está por encima del umbral están dentro de su distribución.\n\n\n\n\n3.1.6 Evaluación\nPara evaluar la calidad del modelo de random forest calibrado, validaremos su capacidad para predecir los patrones de detección observados utilizando datos de validación independientes (es decir, el conjunto de datos de prueba del 20 %). Utilizaremos diversas métricas de rendimiento predictivo (MRP) para comparar las predicciones con las observaciones reales. La mayoría de las métricas miden la capacidad del modelo para predecir correctamente la detección/no detección binaria, incluyendo: sensibilidad, especificidad, AUC de precisión-recuperación, F1 score, and MCC. Error cuadrático medio (MSE) aplicado a las estimaciones de la tasa de encuentros calibradas.\nPara garantizar que el sesgo en el conjunto de datos de prueba no afecte a las métricas de rendimiento predictivo, es importante que apliquemos un muestreo de cuadrícula espaciotemporal a los datos de prueba del mismo modo que lo hicimos con los datos de entrenamiento. Ya realizamos este muestreo de cuadrícula anteriormente cuando creamos el data frame checklist_ss, así que utilizamos ese data frame aquí para calcular los PPM..\n\n# obtener el set de prueba retenido fuera del entrenamiento\nchecklists_test &lt;- filter(checklists_ss, type == \"test\") |&gt; \n  mutate(species_observed = as.integer(species_observed))\n\n# predecir para probar los datos usando el modelo random forest\npred_er &lt;- predict(er_model, data = checklists_test, type = \"response\")\n# extraer probabilidad de detección \npred_er &lt;- pred_er$predictions[, 2]\n# convertir predicciones a binario (presencia/ausencia) usando el umbral\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# calibrar\npred_calibrated &lt;- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") |&gt; \n  as.numeric()\n# restringir las probabilidades a 0-1\npred_calibrated[pred_calibrated &lt; 0] &lt;- 0\npred_calibrated[pred_calibrated &gt; 1] &lt;- 1\n# combinar observaciones y estimaciones\nobs_pred_test &lt;- data.frame(id = seq_along(pred_calibrated),\n                            # detección/no detección real\n                            obs = as.integer(checklists_test$species_observed),\n                            # detección binaria/predicción de detección\n                            pred_binary = pred_binary,\n                            # tasa de encuentro calibrada\n                            pred_calibrated = pred_calibrated)\n\n# error cuadrático medio (mse)\nmse &lt;- mean((obs_pred_test$obs - obs_pred_test$pred_calibrated)^2, na.rm = TRUE)\n\n# AUC de recuperación de precisión\nem &lt;- precrec::evalmod(scores = obs_pred_test$pred_binary, \n                       labels = obs_pred_test$obs)\npr_auc &lt;- precrec::auc(em) |&gt; \n  filter(curvetypes == \"PRC\") |&gt; \n  pull(aucs)\n\n# Calcular métricas para la predicción binaria: sensibilidad, especificidad.\npa_metrics &lt;- obs_pred_test |&gt; \n  select(id, obs, pred_binary) |&gt; \n  PresenceAbsence::presence.absence.accuracy(na.rm = TRUE, st.dev = FALSE)\n\n# mcc y f1\nmcc_f1 &lt;- calculate_mcc_f1(obs_pred_test$obs, obs_pred_test$pred_binary)\n\n# combinar ppm\nppms &lt;- data.frame(\n  mse = mse,\n  sensitivity = pa_metrics$sensitivity,\n  specificity = pa_metrics$specificity,\n  pr_auc = pr_auc,\n  mcc = mcc_f1$mcc,\n  f1 = mcc_f1$f1\n)\nknitr::kable(pivot_longer(ppms, everything()), digits = 3)\n\n\n\n\nname\nvalue\n\n\n\n\nmse\n0.089\n\n\nsensitivity\n0.684\n\n\nspecificity\n0.820\n\n\npr_auc\n0.303\n\n\nmcc\n0.390\n\n\nf1\n0.468\n\n\n\n\n\nUn aspecto importante a tener en cuenta al analizar los datos de eBird es su marcado desequilibrio, con muchas más no detecciones que detecciones. Esto repercute en la interpretación de las métricas de rendimiento predictivo que incorporan la tasa de verdaderos negativos. Por consiguiente, resulta más informativo observar el área bajo la curva (AUC) de precisión-recuperación (PR) que el área bajo la curva ROC (AUC-ROC), ya que ni la precisión ni la recuperación incorporan la tasa de verdaderos negativos. Cada métrica proporciona información sobre distintos aspectos del ajuste del modelo y, al variar de 0 a 1, ofrece una forma relativamente estandarizada de comparar el ajuste del modelo entre especies, regiones y estaciones.\n\n\n3.1.7 Asociaciones de hábitat\nA partir del modelo de random forest, podemos obtener dos fuentes importantes de información sobre la relación entre la detección del Zorzal de Swainson y las características de su entorno local. En primer lugar, la importancia del predictor es una medida del poder predictivo de cada variable utilizada como predictor en el modelo, y se calcula como resultado del ajuste de un modelo de random forest. En segundo lugar, la dependencia parcial estima el efecto marginal de un predictor manteniendo constantes todos los demás predictores.\n\n\n3.1.8 Importancia del predictor\nDurante el entrenamiento de un modelo de random forests, se eliminan algunas variables en cada nodo de los árboles que lo componen. La importancia del predictor se basa en la disminución promedio de la precisión del modelo cuando se omite un predictor determinado. Técnicamente, se trata de un índice de Gini promedio, pero, en esencia, valores mayores indican que el predictor es más importante para el modelo.\n\n# extraer importancia de los predictores del objeto del modelo random forest\npred_imp &lt;- er_model$variable.importance\npred_imp &lt;- data.frame(predictor = names(pred_imp), \n                       importance = pred_imp) |&gt; \n  arrange(desc(importance))\n# graficar la importancia de los 20 principales predictores\nggplot(head(pred_imp, 20)) + \n  aes(x = reorder(predictor, importance), y = importance) +\n  geom_col() +\n  geom_hline(yintercept = 0, linewidth = 2, colour = \"#555555\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  coord_flip() +\n  labs(x = NULL, \n       y = \"Importancia del predictor (Índice Gini)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        panel.grid.major.x = element_line(colour = \"#cccccc\", linewidth = 0.5))\n\n\n\n\n\n\n\n\nLos predictores más importantes de detección/no detección suelen ser variables de esfuerzo. De hecho, este es el caso: la duración de la lista, la distancia recorrida y la hora de inicio (hours_of_day) figuran entre los 5 predictores principales. Esto no es sorprendente: salir a la hora adecuada y dedicar más esfuerzo a la búsqueda aumenta la probabilidad de detectar al Zorzal de Swainson. En cuanto a las variables de hábitat, ambas variables de altitud tienen una alta importancia, y las principales variables de hábitat corresponden a bosques caducifolios de hoja ancha y sabana arbolada. Cabe señalar, sin embargo, que la alta importancia no indica la dirección de la relación con la detección; para ello, será necesario analizar los gráficos de dependencia parcial.\n\n\n3.1.9 Dependencia parcial\nLos gráficos de dependencia parcial muestran el efecto marginal de un predictor dado sobre la tasa de encuentros, promediada entre los demás predictores. Estos gráficos se generan prediciendo la tasa de encuentros en una secuencia regular de puntos a lo largo de todo el rango de valores de un predictor dado. Para cada valor del predictor, se realizan predicciones de la tasa de encuentros para una submuestra aleatoria del conjunto de datos de entrenamiento, manteniendo fijo el predictor principal y sin modificar los demás. Las predicciones de la tasa de encuentros se promedian entre todas las listas del conjunto de datos de entrenamiento, lo que proporciona una estimación de la tasa de encuentros promedio para un valor específico del predictor principal. Este es un proceso laborioso, ¡pero a continuación proporcionamos una función que lo simplifica enormemente! Esta función acepta los siguientes argumentos:\n\npredictor: El nombre del predictor al que calcularemos la dependencia parcial\ner_model: el objeto del modelo de tasa de encuentro\nmodel: objeto del modelo de la tasa de encuentro\ndata: los datos originales utilizados para entrenar el modelo\nx_res: la resolución de la grilla sobre la cual calcular la dependencia parcial, ej: el número de puntos entre los valores mínimos y máximos de la variable predictora de la cual calcular la dependencia parcial\nn: número de puntos para sub-samplear de los datos de entrenamiento\n\n\n# función para calcular la dependencia parcial para un único predictor\ncalculate_pd &lt;- function(predictor, er_model, calibration_model,\n                         data, x_res = 25, n = 1000) {\n  # crear una cuadrícula de predicción utilizando cuantiles\n  x_grid &lt;- quantile(data[[predictor]],\n                     probs = seq(from = 0, to = 1, length = x_res),\n                     na.rm = TRUE)\n  # remover duplicados\n  x_grid &lt;- x_grid[!duplicated(signif(x_grid, 8))]\n  x_grid &lt;- unname(unique(x_grid))\n  grid &lt;- data.frame(predictor = predictor, x = x_grid)\n  names(grid) &lt;- c(\"predictor\", predictor)\n  \n  # datos de entrenamiento de la submuestra\n  n &lt;- min(n, nrow(data))\n  data &lt;- data[sample(seq.int(nrow(data)), size = n, replace = FALSE), ]\n  \n  # eliminar el predictor focal de los datos\n  data &lt;- data[names(data) != predictor]\n  grid &lt;- merge(grid, data, all = TRUE)\n  \n  # predecir tasa de encuentro\n  p &lt;- predict(er_model, data = grid)\n  \n  # summarise\n  pd &lt;- grid[, c(\"predictor\", predictor)]\n  names(pd) &lt;- c(\"predictor\", \"x\")\n  pd$encounter_rate &lt;- p$predictions[, 2]\n  pd &lt;- dplyr::group_by(pd, predictor, x)\n  pd &lt;- dplyr::summarise(pd,\n                         encounter_rate = mean(encounter_rate, na.rm = TRUE),\n                         .groups = \"drop\")\n  \n  # calibrar\n  pd$encounter_rate &lt;- predict(calibration_model, \n                               newdata = data.frame(pred = pd$encounter_rate), \n                               type = \"response\")\n  pd$encounter_rate &lt;- as.numeric(pd$encounter_rate)\n  # restringir a 0-1\n  pd$encounter_rate[pd$encounter_rate &lt; 0] &lt;- 0\n  pd$encounter_rate[pd$encounter_rate &gt; 1] &lt;- 1\n\n  return(pd)\n}\n\nAhora utilizaremos esta función para calcular la dependencia parcial de los 6 predictores principales.\n\n# calcular la dependencia parcial para cada uno de los 6 predictores principales.\npd &lt;- NULL\nfor (predictor in head(pred_imp$predictor)) {\n  pd &lt;- calculate_pd(predictor, \n                     er_model = er_model, \n                     calibration_model = calibration_model,\n                     data = checklists_train) |&gt; \n    bind_rows(pd)\n}\nhead(pd)\n#&gt; # A tibble: 6 × 3\n#&gt;   predictor                         x encounter_rate\n#&gt;   &lt;chr&gt;                         &lt;dbl&gt;          &lt;dbl&gt;\n#&gt; 1 pland_c04_deciduous_broadleaf  0            0.0973\n#&gt; 2 pland_c04_deciduous_broadleaf  2.33         0.101 \n#&gt; 3 pland_c04_deciduous_broadleaf  4.08         0.103 \n#&gt; 4 pland_c04_deciduous_broadleaf  4.88         0.103 \n#&gt; 5 pland_c04_deciduous_broadleaf  6.98         0.104 \n#&gt; 6 pland_c04_deciduous_broadleaf  9.30         0.105\n\n# graficar dependencia parcial\nggplot(pd) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ factor(predictor, levels = rev(unique(predictor))), \n             ncol = 2, scales = \"free\") +\n  labs(x = NULL, y = \"Tasa de encuentro\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))\n\n\n\n\n\n\n\n\nAquí se observan diversas respuestas interesantes. Como se aprecia en el gráfico anterior, la frecuencia de avistamiento del Zorzal de Swainson alcanza su punto máximo temprano por la mañana, cuando es más probable que esté cantando, para luego disminuir rápidamente al mediodía y aumentar ligeramente al atardecer. Otros predictores muestran una relación de aumento más gradual con la frecuencia de avistamiento; por ejemplo, a mayor presencia de bosque caducifolio en el paisaje, mayor es la frecuencia de avistamiento.\nEl modelo de random forest presenta varias interacciones que no se muestran en estos gráficos de dependencia parcial. Al interpretarlos, conviene tener en cuenta que probablemente existan efectos de interacción más complejos subyacentes a estos gráficos individuales.\n\n\n\n\n\n\nEjercicio\n\n\n\nExamina los datos de importancia de los predictores para identificar la siguiente variable de cobertura terrestre más importante después de pland_c04_deciduous_broadleaf. Elabore un gráfico de dependencia parcial para esta variable.\n\n\n\n\n\n\n\n\nSolución\n\n\n\n\n\nAl observar el data frame de importancia de los predictores, podemos identificar que pland_c08_woody_savanna es la siguiente variable de cobertura terrestre porcentual más importante.\n\n# calcular dependencia parcial \npd_woody_savanna &lt;- calculate_pd(\"pland_c08_woody_savanna\", \n                                 er_model = er_model, \n                                 calibration_model = calibration_model,\n                                 data = checklists_train)\n\n# graficar dependencia parcial\nggplot(pd_woody_savanna) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  labs(x = NULL, y = \"Tasa de encuentro\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.10 Predicción\nAcá usaremos variables ambientales resumidas en una cuadrícula regular de puntos en toda el área de estudio, puedes usar MODIS, Landsat, BioClim, etc… Hay diversas fuentes de información para esto. En esta sección, haremos predicciones de la tasa de encuentro en estos puntos.\n\n\n3.1.11 Variables de esfuerzo estandarizadas\nLa cuadrícula de predicción solo incluye valores para las variables ambientales, por lo que para realizar predicciones necesitaremos añadir variables de esfuerzo. Haremos predicciones para una lista estándar de eBird: un conteo de aves en un recorrido de 2 km durante 1 hora, en el momento óptimo para la detección de esta especie. Finalmente, realizaremos estas predicciones para el 15 de junio de 2023, la mitad de nuestro periodo de observación de junio para el último año del que disponemos de datos de eBird.\nPara encontrar la hora del día con la mayor probabilidad de detección, podemos buscar el peak en la gráfica de dependencia parcial. La única limitación de este método es que es importante centrarnos en las horas del día con suficientes datos para realizar predicciones. En particular, se observa una tendencia creciente en la detectabilidad con horarios de inicio más tempranos y pocas listas de verificación a altas horas de la noche, lo que puede provocar que el modelo extrapole erróneamente esa tendencia y muestre la mayor detectabilidad durante la noche. Comencemos analizando una gráfica para ver si esto ocurre en este caso.\n\n# determinar la hora peak del día a partir de la dependencia parcial\npd_time &lt;- calculate_pd(\"hours_of_day\",\n                        er_model = er_model, \n                        calibration_model = calibration_model,\n                        data = checklists_train) |&gt; \n  select(hours_of_day = x, encounter_rate)\n\n# histograma\ng_hist &lt;- ggplot(checklists_train) +\n  aes(x = hours_of_day) +\n  geom_histogram(binwidth = 1, center = 0.5, color = \"grey30\",\n                 fill = \"grey50\") +\n  scale_x_continuous(breaks = seq(0, 24, by = 3)) +\n  scale_y_continuous(labels = scales::comma) +\n  labs(x = \"Horas desde la medianoche\",\n       y = \"# de listas\",\n       title = \"Distribución de los horarios de inicio de las observaciones\")\n\n# gráfico de dependencia parcial\ng_pd &lt;- ggplot(pd_time) +\n  aes(x = hours_of_day, y = encounter_rate) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0, 24, by = 3)) +\n  labs(x = \"Horas desde la medianoche\",\n       y = \"Tasa de encuentro\",\n       title = \"Dependencia parcial del tiempo de inicio de la observación\")\n\n# combinar\ngrid.arrange(g_hist, g_pd)\n\n\n\n\n\n\n\n\nLa mayor probabilidad de avistamientos se da temprano por la mañana, como es de esperar en un ave cantora como el Zorzal de Swainson. Sin embargo, se observa un comportamiento anómalo en los valores mínimo y máximo de hours_of_day, donde se produce una extrapolación debido a la escasez de datos. En general, eliminar los valores inicial y final, y luego seleccionar el valor de hours_of_day que maximiza la tasa de avistamientos, es un método fiable para evitar la extrapolación.\n\n# recortar los extremos de la dependencia parcial\npd_time_trimmed &lt;- pd_time[c(-1, -nrow(pd_time)), ]\n\n# identificar el momento que maximiza la tasa de encuentros\npd_time_trimmed &lt;- arrange(pd_time_trimmed, desc(encounter_rate))\nt_peak &lt;- pd_time_trimmed$hours_of_day[1]\nprint(t_peak)\n#&gt; [1] 6.67\n\nSegún este análisis, el mejor momento para detectar al Zorzal de Swainson es a las 6:40 AM. Usaremos este momento para hacer predicciones. Esto equivale a que muchos observadores de aves de eBird realicen un censo en diferentes celdas de la cuadrícula el 15 de junio a las 6:40 AM. También añadiremos las demás variables de esfuerzo al conjunto de datos de la cuadrícula de predicción en ese momento.\n\n# añadir covariables de esfuerzo a la cuadrícula de predicción\npred_grid_eff &lt;- pred_grid |&gt; \n  mutate(observation_date = ymd(\"2023-06-15\"),\n         year = year(observation_date),\n         day_of_year = yday(observation_date),\n         hours_of_day = t_peak,\n         effort_distance_km = 2,\n         effort_hours = 1,\n         effort_speed_kmph = 2,\n         number_observers = 1)\n\n\n\n3.1.12 Estimaciones del modelo\nUtilizando estas variables de esfuerzo estandarizadas, podemos realizar estimaciones en toda la superficie de predicción. Usaremos el modelo para estimar tanto la tasa de avistamiento como la detección/no detección binaria. La predicción binaria, basada en el umbral de optimización MCC-F1 que calculamos en Section 3.1.5, sirve como estimación del límite de distribución del zorzal de Swainson en Georgia en junio.\n\n# estimar tasa de encuentro\npred_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er &lt;- pred_er$predictions[, 2]\n# definir límite de rango\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# aplicar calibración\npred_er_cal &lt;- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") |&gt; \n  as.numeric()\n# restringir a 0-1\npred_er_cal[pred_er_cal &lt; 0] &lt;- 0\npred_er_cal[pred_er_cal &gt; 1] &lt;- 1\n# combinar predicciones con coordenadas de la cuadrícula de predicción\npredictions &lt;- data.frame(cell_id = pred_grid_eff$cell_id,\n                          x = pred_grid_eff$x,\n                          y = pred_grid_eff$y,\n                          in_range = pred_binary, \n                          encounter_rate = pred_er_cal)\n\nA continuación, convertiremos este marco de datos en características espaciales utilizando sf, y luego rasterizaremos los puntos utilizando la plantilla ráster de cuadrícula de predicción.\n\nr_pred &lt;- predictions |&gt; \n  # convertir a espaciales\n  st_as_sf(coords = c(\"x\", \"y\"), crs = crs) |&gt; \n  select(in_range, encounter_rate) |&gt; \n  # rasterizar\n  rasterize(r, field = c(\"in_range\", \"encounter_rate\"))\nprint(r_pred)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 171, 148, 2  (nrow, ncol, nlyr)\n#&gt; resolution  : 2991, 3005  (x, y)\n#&gt; extent      : -175612, 267066, -312494, 201374  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=laea +lat_0=33.2 +lon_0=-83.7 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; names       : in_range, encounter_rate \n#&gt; min values  :        0,            0.0 \n#&gt; max values  :        1,            0.7\n\n\n\n3.1.13 Mapeo\nAhora viene lo divertido: ¡vamos a crear mapas de la distribución del Zorzal de Swainson en Georgia! Empezaremos con un mapa de distribución sencillo usando la capa in_range del ráster de predicciones que creamos. Aunque las predicciones de la tasa de encuentro ofrecen información más detallada, para algunas aplicaciones un mapa de distribución será más conveniente.\n\npar(mar = c(0.25, 0.25, 1.25, 0.25))\n# configurar el área del plot\nplot(study_region, \n     main = \"Rango del Zorzal de Swainson (Junio 2023)\",\n     col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# convertir predicción binaria a categórica\nr_range &lt;- as.factor(r_pred[[\"in_range\"]])\nplot(r_range, col = c(\"#e6e6e6\", \"forestgreen\"),\n     maxpixels = ncell(r_range),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n\n\n\n\n\n\n\nA continuación, elaboraremos un mapa de las predicciones de la tasa de encuentros.\n\npar(mar = c(4, 0.25, 0.25, 0.25))\n# configurar área del plot\nplot(study_region, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# definir quiebres de cuantiles\nbrks &lt;- global(r_pred[[\"encounter_rate\"]], fun = quantile, \n               probs = seq(0, 1, 0.1), na.rm = TRUE) |&gt; \n  as.numeric() |&gt; \n  unique()\n# etiquetar el valor más bajo, mediano y máximo\nlbls &lt;- round(c(0, median(brks), max(brks)), 2)\n# paleta de colores de Status & Trends\npal &lt;- ebirdst_palettes(length(brks) - 1)\nplot(r_pred[[\"encounter_rate\"]], \n     col = pal, breaks = brks, \n     maxpixels = ncell(r_pred),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# leyenda\npar(new = TRUE, mar = c(0, 0, 0, 0))\ntitle &lt;- \"Tasa de encuentro del Zorzal de Swainson (Junio 2023)\"\nimage.plot(zlim = c(0, 1), legend.only = TRUE, \n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.25, 0.75, 0.03, 0.06),\n           horizontal = TRUE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5,\n                            padj = -1.5),\n           legend.args = list(text = title,\n                              side = 3, col = \"black\",\n                              cex = 1, line = 0))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  },
  {
    "objectID": "distabund.html#sec-abundance",
    "href": "distabund.html#sec-abundance",
    "title": "3  Modelamiento de tasa de encuentro y abundancia relativa",
    "section": "3.2 Abundancia relativa",
    "text": "3.2 Abundancia relativa\nEl capítulo anterior se enfocó en modelar la tasa de encuentro, la probabilidad de detectar una especie en una lista eBird estándar. Sin embargo, además de registrar las especies observadas, la mayoría de los usuarios de eBird también especifican cuántos individuos de cada especie observaron. Por lo tanto, en este capítulo, aprovecharemos estos conteos para modelar una medida relativa de la abundancia de las especies.\nPara motivar este capítulo, nos centraremos en el objetivo específico de estimar un mapa de abundancia relativa. Este tipo de mapa nos ayudará a identificar áreas con mayor o menor abundancia. La métrica que utilizaremos para estimar la abundancia es el número esperado de individuos observados en una lista de verificación estandarizada de eBird. Al igual que el modelo de tasa de encuentro, el modelo de abundancia que presentamos en esta sección tiene en cuenta la variación en las tasas de detección, pero no estima directamente la probabilidad absoluta de detección. Por esta razón, las estimaciones de abundancia que realizamos solo pueden interpretarse como una medida de abundancia relativa; un índice del número de individuos de la especie presentes en el área de búsqueda. Para ajustarnos a la terminología común en la literatura, nos referimos a esto como una estimación de la abundancia relativa.\nEl modelo de abundancia relativa que presentamos aquí es similar al modelo de tasa de encuentros del Capítulo anterior y constituye una extensión natural del mismo. En particular, utilizamos un modelo de dos etapas con umbral, siguiendo a Keyser et al. [-@keyserSnowCoverDynamics2023]. En la primera etapa, estimamos la tasa de encuentros utilizando el mismo método que en el Capítulo anterior. En la segunda etapa, estimamos el número esperado de individuos en las listas de eBird donde se detectó la especie. Finalmente, multiplicamos la tasa de encuentros por la mediana del número de individuos para obtener una estimación de la abundancia relativa. Utilizamos random forest en ambas etapas del modelo de umbrales.\n\n3.2.1 Preparación de datos\nComencemos cargando los paquetes y datos necesarios. Si has completado los capítulos anteriores, ya deberías tener todos los datos necesarios para este capítulo. Sin embargo, es posible que quieras descargar el paquete de datos, y descomprímelo en el directorio de tu proyecto, para asegurarte de que estás trabajando exactamente con los mismos datos que se utilizaron en la creación de esta guía.\n\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(fields)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(lubridate)\nlibrary(mccf1)\nlibrary(ranger)\nlibrary(readr)\nlibrary(scam)\nlibrary(sf)\nlibrary(terra)\nlibrary(tidyr)\n\n# definir número aleatorio semilla para reproducibilidad\nset.seed(1)\n\n# variables ambientales: cobertura de suelo y altitud\nenv_vars &lt;- read_csv(\"data/environmental-variables_checklists_jun_us-ga.csv\")\n\n# datos de eBird rellenados con ceros combinados con datos ambientales\nchecklists &lt;- read_csv(\"data/checklists-zf_woothr_jun_us-ga.csv\") |&gt; \n  inner_join(env_vars, by = \"checklist_id\")\n\n# cuadrícula de predicción\npred_grid &lt;- read_csv(\"data/environmental-variables_prediction-grid_us-ga.csv\")\n# plantilla ráster para la cuadrícula\nr &lt;- rast(\"data/prediction-grid_us-ga.tif\")\n# obtener el sistema de referencia de coordenadas para la cuadrícula de predicción\ncrs &lt;- st_crs(r)\n\n# cargar datos GIS para la creación de mapas\nstudy_region &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_states\") |&gt; \n  filter(state_code == \"US-GA\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_land &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_land\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_country_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\nne_state_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") |&gt; \n  st_transform(crs = crs) |&gt; \n  st_geometry()\n\nA continuación, siguiendo el enfoque descrito en el capítulo anterior, realizaremos una ronda de submuestreo espaciotemporal en los datos para reducir el sesgo.\n\n# muestrear de una lista por cada cuadrícula de 3 km x 3 km x 1 semana para cada año.\n# muestreo de detección/no detección de forma independiente\nchecklists_ss &lt;- grid_sample_stratified(checklists,\n                                        obs_column = \"species_observed\",\n                                        sample_by = \"type\")\n\nFinalmente, eliminaremos el 20% de las listas de verificación reservadas para pruebas y seleccionaremos únicamente las columnas que pretendemos utilizar como predictores para entrenar los modelos.\n\nchecklists_train &lt;- checklists_ss |&gt; \n  filter(type == \"train\") |&gt; \n  # seleccioanr solo las columnas a usar en el modelo\n  select(species_observed, observation_count,\n         year, day_of_year, hours_of_day,\n         effort_hours, effort_distance_km, effort_speed_kmph,\n         number_observers, \n         starts_with(\"pland_\"),\n         starts_with(\"ed_\"),\n         starts_with(\"elevation_\"))\n\n\n\n3.2.2 Modelo de obstáculos (hurdle)\nPara este modelo de dos pasos con obstáculos, comenzaremos entrenando el mismo modelo de tasa de encuentros que en el capítulo anterior. Luego, seleccionaremos un subconjunto de la lista de verificación de eBird que incluya solo aquellas especies detectadas o cuya presencia fue predicha por el modelo de tasa de encuentros. Utilizaremos este subconjunto de datos para entrenar un segundo modelo de random forest para el conteo esperado. Finalmente, combinaremos los resultados de ambos pasos para obtener estimaciones de abundancia relativa.\n\n\n3.2.3 Paso 1: Tasa de encuentro\nEn el capítulo anterior explicamos el modelo de tasa de encuentros calibrado. Aquí repetimos el proceso de modelado de la tasa de encuentros de forma concisa.\n\n# calcular frecuencia de detección para el random forest \ndetection_freq &lt;- mean(checklists_train$species_observed)\n\n# entrenar un modelo de random forest para la tasa de encuentros\ntrain_er &lt;- select(checklists_train, -observation_count)\ner_model &lt;- ranger(formula =  as.factor(species_observed) ~ ., \n                   data = train_er,\n                   importance = \"impurity\",\n                   probability = TRUE,\n                   replace = TRUE,\n                   sample.fraction = c(detection_freq, detection_freq))\n\n# seleccionar el umbral de ocurrencia de optimización mcc-F1\nobs_pred &lt;- data.frame(obs = as.integer(train_er$species_observed), \n                       pred = er_model$predictions[, 2])\nmcc_f1 &lt;- mccf1(response = obs_pred$obs, predictor = obs_pred$pred)\nmcc_f1_summary &lt;- summary(mcc_f1)\nthreshold &lt;- mcc_f1_summary$best_threshold[1]\n\n# modelo de calibración\ncalibration_model &lt;- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n#&gt;  mccf1_metric best_threshold\n#&gt;         0.403          0.512\n\n\n\n3.2.4 Paso 2: Contar\nEn el segundo paso, entrenamos un modelo de random forest para estimar el número esperado de individuos en las listas de eBird donde la especie fue detectada o se predijo su detección mediante el modelo de tasa de encuentros. Para ello, comenzaremos seleccionando únicamente estas listas de eBird. Además, eliminaremos cualquier observación en la que el observador reportó la presencia del zorzal de Swainson, pero no indicó el número de individuos (codificado como “X” en la base de datos de eBird, pero convertido a NA en nuestro conjunto de datos).\n\n# adjuntar la tasa de encuentro prevista basada en muestras fuera de la bolsa.\ntrain_count &lt;- checklists_train\ntrain_count$pred_er &lt;- er_model$predictions[, 2]\n# muestrear para solo detecciones observadas o predichas\ntrain_count &lt;- train_count |&gt; \n  filter(!is.na(observation_count),\n         observation_count &gt; 0 | pred_er &gt; threshold) |&gt; \n  select(-species_observed, -pred_er)\n\nHemos observado que incluir la tasa de encuentros estimada como predictor en el modelo de conteo mejora el rendimiento predictivo. Por lo tanto, teniendo esto en cuenta, predecimos la tasa de encuentros para el conjunto de datos de entrenamiento y la añadimos como una columna adicional.\n\npredicted_er &lt;- predict(er_model, data = train_count, type = \"response\")\npredicted_er &lt;- predicted_er$predictions[, 2]\ntrain_count$predicted_er &lt;- predicted_er\n\nFinalmente, entrenamos un modelo de random forest para estimar el recuento. Este modelo es superficialmente muy similar al modelo de random forest para la tasa de encuentros; sin embargo, para el recuento utilizamos un random forest de regresión, mientras que para la tasa de encuentros utilizamos un random forest de clasificación balanceada.\n\ncount_model &lt;- ranger(formula = observation_count ~ .,\n                      data = train_count,\n                      importance = \"impurity\",\n                      replace = TRUE)\n\n\n\n3.2.5 Evaluación\nEn Evaluación del capítulo anterior calculamos un conjunto de métricas de rendimiento predictivo para el modelo de tasa de encuentros. Estas métricas también deben considerarse al modelar la abundancia relativa; sin embargo, no duplicaremos el cálculo de estas métricas aquí. En su lugar, calcularemos el coeficiente de correlación de rangos de Spearmantanto para el recuento como para la abundancia relativa, y el coeficiente de correlación de Pearson para el logaritmo del recuento y la abundancia relativa. Comenzaremos estimando la tasa de encuentros, el recuento y la abundancia relativa para el conjunto de datos de prueba muestreado en cuadrícula espaciotemporal.\n\n# obtener el conjunto de prueba reservado para el entrenamiento.\nchecklists_test &lt;- filter(checklists_ss, type == \"test\") |&gt; \n  mutate(species_observed = as.integer(species_observed)) |&gt; \n  filter(!is.na(observation_count))\n\n# estimar tasa de encuentro para los datos de prueba\npred_er &lt;- predict(er_model, data = checklists_test, type = \"response\")\n# extraer probabilidad de detección\npred_er &lt;- pred_er$predictions[, 2]\n# convertir a binario usando el umbral\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# calibrar\npred_calibrated &lt;- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") |&gt; \n  as.numeric()\n# restringir probabilidades a 0-1\npred_calibrated[pred_calibrated &lt; 0] &lt;- 0\npred_calibrated[pred_calibrated &gt; 1] &lt;- 1\n\n# añadir la tasa de encuentros requerida para las estimaciones de conteo\nchecklists_test$predicted_er &lt;- pred_er\n# estimar conteos\npred_count &lt;- predict(count_model, data = checklists_test, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# la abundancia relativa es el producto de la tasa de encuentro y el conteo\npred_abundance &lt;- pred_calibrated * pred_count\n\n# combinar observaciones y estimados\nobs_pred_test &lt;- data.frame(\n  id = seq_along(pred_abundance),\n  # detección/no detección real\n  obs_detected = as.integer(checklists_test$species_observed),\n  obs_count = checklists_test$observation_count,\n  # estimaciones del modelo\n  pred_binary = pred_binary,\n  pred_er = pred_calibrated,\n  pred_count = pred_count,\n  pred_abundance = pred_abundance\n)\n\nLas métricas de conteo miden el rendimiento dentro del rango, lo que significa que comparamos el conteo observado con el conteo estimado solo para aquellas listas donde el modelo predice la presencia de la especie. La abundancia relativa considera tanto la tasa de encuentro como el conteo, por lo que el rendimiento predictivo de la abundancia se basa en todas las listas de verificación.\n\n# muestrear solo aquellas listas donde ocurrió detección\ndetections_test &lt;- filter(obs_pred_test, obs_detected &gt; 0)\n\n# métricas de recuento, basadas únicamente en listas donde se detectó\ncount_spearman &lt;- cor(detections_test$pred_count, \n                      detections_test$obs_count,\n                      method = \"spearman\")\nlog_count_pearson &lt;- cor(log(detections_test$pred_count + 1),\n                         log(detections_test$obs_count + 1),\n                         method = \"pearson\")\n\n# métricas de abundancia\nabundance_spearman &lt;- cor(detections_test$pred_abundance, \n                          detections_test$obs_count,\n                          method = \"spearman\")\nlog_abundance_pearson &lt;- cor(log(detections_test$pred_abundance + 1),\n                             log(detections_test$obs_count + 1),\n                             method = \"pearson\")\n\n# combinar ppms\nppms &lt;- data.frame(\n  count_spearman = count_spearman,\n  log_count_pearson = log_count_pearson,\n  abundance_spearman = abundance_spearman,\n  log_abundance_pearson = log_abundance_pearson\n)\nknitr::kable(pivot_longer(ppms, everything()), digits = 3)\n\n\n\n\nname\nvalue\n\n\n\n\ncount_spearman\n0.283\n\n\nlog_count_pearson\n0.405\n\n\nabundance_spearman\n0.326\n\n\nlog_abundance_pearson\n0.458\n\n\n\n\n\nLas correlaciones de Spearman nos informan sobre la capacidad del modelo para estimar el orden de frecuencia y la abundancia relativa, aspectos en los que estos modelos suelen tener un mejor desempeño. Las correlaciones de Pearson nos brindan información sobre la capacidad del modelo para estimar frecuencias absolutas en escala logarítmica, una tarea que suele ser más difícil con los datos de eBird, especialmente para especies congregacionales que a menudo presentan frecuencias elevadas. Al igual que con las métricas de rendimiento de la tasa de encuentros, estas son útiles para comparar la calidad del modelo entre especies, regiones y estaciones.\n\n\n3.2.6 Predicción\nTal como hicimos con la función predict para la tasa de avistamientos, podemos estimar la abundancia relativa en nuestra cuadrícula de predicción. Primero estimamos la tasa de avistamientos y el conteo, y luego los multiplicamos para obtener una estimación de la abundancia relativa. Comencemos agregando las variables de esfuerzo a la cuadrícula de predicción para una lista de verificación estándar de eBird en el momento óptimo del día para detectar al Zorzal de Swainson. Recordemos que, según la función predict-effort, determinamos que el momento óptimo del día para detectar al Zorzal de Swainson era alrededor de las 6:37 a. m.\n\npred_grid_eff &lt;- pred_grid |&gt; \n  mutate(observation_date = ymd(\"2023-06-15\"),\n         year = year(observation_date),\n         day_of_year = yday(observation_date),\n         # determinado como tiempo óptimo para la detección en el capítulo previo\n         hours_of_day = 6.6,\n         effort_distance_km = 2,\n         effort_hours = 1,\n         effort_speed_kmph = 2,\n         number_observers = 1)\n\nAhora podemos estimar la tasa de encuentros calibrada y el recuento para cada punto de la cuadrícula de predicción. También incluimos una estimación binaria del límite de distribución.\n\n# estimar tasa de encuentro\npred_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er &lt;- pred_er$predictions[, 2]\n# definir límite de rango\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# aplciar calibración\npred_er_cal &lt;- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") |&gt; \n  as.numeric()\n# restringir a 0-1\npred_er_cal[pred_er_cal &lt; 0] &lt;- 0\npred_er_cal[pred_er_cal &gt; 1] &lt;- 1\n\n# añadir tasa de encuentro predicha requerida para los estimados de conteo\npred_grid_eff$predicted_er &lt;- pred_er\n# conteos estimados\npred_count &lt;- predict(count_model, data = pred_grid_eff, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# combinar predicciones con coordenadas de la cuadrícula de predicción\npredictions &lt;- data.frame(cell_id = pred_grid_eff$cell_id,\n                          x = pred_grid_eff$x,\n                          y = pred_grid_eff$y,\n                          in_range = pred_binary, \n                          encounter_rate = pred_er_cal,\n                          count = pred_count)\n\nA continuación, agregamos una columna para la estimación de abundancia relativa (el producto de las estimaciones de tasa de encuentro y conteo) y convertimos estas estimaciones a formato ráster.\n\n# añadir estimados de abundancia relativa\npredictions$abundance &lt;- predictions$encounter_rate * predictions$count\n\n# rasterizar\nlayers &lt;- c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\")\nr_pred &lt;- predictions |&gt; \n  # convertir a espacial \n  st_as_sf(coords = c(\"x\", \"y\"), crs = crs) |&gt; \n  select(all_of(layers)) |&gt; \n  # rasterizar\n  rasterize(r, field = layers)\nprint(r_pred)\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 171, 148, 4  (nrow, ncol, nlyr)\n#&gt; resolution  : 2991, 3005  (x, y)\n#&gt; extent      : -175612, 267066, -312494, 201374  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=laea +lat_0=33.2 +lon_0=-83.7 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs \n#&gt; source(s)   : memory\n#&gt; names       : in_range, encounter_rate, count, abundance \n#&gt; min values  :        0,          0.000, 0.079,      0.00 \n#&gt; max values  :        1,          0.641, 1.913,      1.13\n\nFinalmente, generaremos un mapa de abundancia relativa. Los valores que se muestran en este mapa representan el número esperado de Zorzales de Swainson avistados por un observador promedio de eBird que realice un conteo itinerante de 2 km durante 1 hora, comenzando aproximadamente a las 6:37 a. m. del 15 de junio de 2023. Dado que la detectabilidad no es perfecta, prevemos que la abundancia real de Zorzales de Swainson sea mayor que estos valores, pero sin estimar directamente la tasa de detección, es difícil precisar cuánto mayor.\nAntes de generar el mapa de abundancia relativa, lo multiplicaremos por la capa in_range, lo que producirá un mapa que mostrará una abundancia relativa de cero donde el modelo predice que no hay presencia de Zorzales de Swainson.\n\npar(mar = c(4, 0.25, 0.25, 0.25))\n# definir área del plot\nplot(study_region, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# definir quiebres de cuantiles, excluyendo los ceros\nbrks &lt;- ifel(r_pred[[\"abundance\"]] &gt; 0, r_pred[[\"abundance\"]], NA) |&gt; \n  global(fun = quantile, \n         probs = seq(0, 1, 0.1), na.rm = TRUE) |&gt; \n  as.numeric() |&gt; \n  unique()\n# etiquetar los valores mínimos, medios y máximos\nlbls &lt;- round(c(min(brks), median(brks), max(brks)), 2)\n# paleta de colores de Status & Trends \npal &lt;- ebirdst_palettes(length(brks) - 1)\nplot(r_pred[[\"abundance\"]], \n     col = c(\"#e6e6e6\", pal), breaks = c(0, brks), \n     maxpixels = ncell(r_pred),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# bordes\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# leyenda\npar(new = TRUE, mar = c(0, 0, 0, 0))\ntitle &lt;- \"Abundancia relativa Zorzal de Swainson (Junio 2023)\"\nimage.plot(zlim = c(0, 1), legend.only = TRUE, \n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.25, 0.75, 0.03, 0.06),\n           horizontal = TRUE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5,\n                            padj = -1.5),\n           legend.args = list(text = title,\n                              side = 3, col = \"black\",\n                              cex = 1, line = 0))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelamiento de tasa de encuentro y abundancia relativa</span>"
    ]
  }
]